{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e097df-bdb8-4625-9960-2d05603e4a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from /root/autodl-tmp/Pro/qwen2.5-sft-full\n",
      "Tokenizer loaded.\n",
      "  eos_token: <|endoftext|>\n",
      "  bos_token: <|startoftext|>\n",
      "  pad_token: <|endoftext|>\n",
      "  pad_token_id: 151643\n",
      "  vocab_size: 151665\n",
      "Reading Ulysses txt: /root/autodl-tmp/Pro/Ulysses尤利西斯.txt\n",
      "Found 7169 paragraphs; will pack paragraphs into chunks <= 1024 tokens.\n",
      "Total token chunks prepared: 459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built: 459 examples\n",
      "Loading base model from: /root/autodl-tmp/Pro/qwen2.5-sft-full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,261,568 || all params: 7,616,878,080 || trainable%: 0.0166\n",
      "Model device: cuda:0\n",
      "Training config -- epochs: 2 batches_per_epoch: 459 total_steps(approx): 229\n",
      "[Epoch 1] Step 20 | loss: 2.4292 | step_time: 00:00:04\n",
      "[Epoch 1] Step 40 | loss: 2.8493 | step_time: 00:00:07\n",
      "[Epoch 1] Step 60 | loss: 3.1239 | step_time: 00:00:11\n",
      "[Epoch 1] Step 80 | loss: 2.8827 | step_time: 00:00:15\n",
      "[Epoch 1] Step 100 | loss: 2.8391 | step_time: 00:00:19\n",
      "[Epoch 1] Step 120 | loss: 2.8489 | step_time: 00:00:22\n",
      "[Epoch 1] Step 140 | loss: 2.8245 | step_time: 00:00:26\n",
      "[Epoch 1] Step 160 | loss: 2.8936 | step_time: 00:00:30\n",
      "[Epoch 1] Step 180 | loss: 2.7989 | step_time: 00:00:34\n",
      "[Epoch 1] Step 200 | loss: 2.7810 | step_time: 00:00:37\n",
      "[Epoch 1] Step 220 | loss: 2.7274 | step_time: 00:00:41\n",
      "[Epoch 1] Step 240 | loss: 2.6937 | step_time: 00:00:45\n",
      "[Epoch 1] Step 260 | loss: 2.6742 | step_time: 00:00:48\n",
      "[Epoch 1] Step 280 | loss: 2.6603 | step_time: 00:00:52\n",
      "[Epoch 1] Step 300 | loss: 2.6799 | step_time: 00:00:56\n",
      "[Epoch 1] Step 320 | loss: 2.6282 | step_time: 00:00:59\n",
      "[Epoch 1] Step 340 | loss: 2.5726 | step_time: 00:01:03\n",
      "[Epoch 1] Step 360 | loss: 2.5276 | step_time: 00:01:07\n",
      "[Epoch 1] Step 380 | loss: 2.4986 | step_time: 00:01:11\n",
      "[Epoch 1] Step 400 | loss: 2.4473 | step_time: 00:01:14\n",
      "[Epoch 1] Step 420 | loss: 2.4162 | step_time: 00:01:18\n",
      "[Epoch 1] Step 440 | loss: 2.3848 | step_time: 00:01:22\n",
      "Epoch 1 finished in 00:01:25\n",
      "[Epoch 2] Step 460 | loss: 0.0085 | step_time: 00:00:00\n",
      "[Epoch 2] Step 480 | loss: 0.0791 | step_time: 00:00:03\n",
      "[Epoch 2] Step 500 | loss: 0.1484 | step_time: 00:00:07\n",
      "[Epoch 2] Step 520 | loss: 0.1840 | step_time: 00:00:11\n",
      "[Epoch 2] Step 540 | loss: 0.2568 | step_time: 00:00:15\n",
      "[Epoch 2] Step 560 | loss: 0.3102 | step_time: 00:00:18\n",
      "[Epoch 2] Step 580 | loss: 0.3674 | step_time: 00:00:22\n",
      "[Epoch 2] Step 600 | loss: 0.4173 | step_time: 00:00:26\n",
      "[Epoch 2] Step 620 | loss: 0.4538 | step_time: 00:00:29\n",
      "[Epoch 2] Step 640 | loss: 0.4886 | step_time: 00:00:33\n",
      "[Epoch 2] Step 660 | loss: 0.5320 | step_time: 00:00:37\n",
      "[Epoch 2] Step 680 | loss: 0.5606 | step_time: 00:00:41\n",
      "[Epoch 2] Step 700 | loss: 0.5922 | step_time: 00:00:44\n",
      "[Epoch 2] Step 720 | loss: 0.6334 | step_time: 00:00:48\n",
      "[Epoch 2] Step 740 | loss: 0.6604 | step_time: 00:00:52\n",
      "[Epoch 2] Step 760 | loss: 0.6994 | step_time: 00:00:56\n",
      "[Epoch 2] Step 780 | loss: 0.7172 | step_time: 00:00:59\n",
      "[Epoch 2] Step 800 | loss: 0.7253 | step_time: 00:01:03\n",
      "[Epoch 2] Step 820 | loss: 0.7569 | step_time: 00:01:07\n",
      "[Epoch 2] Step 840 | loss: 0.7746 | step_time: 00:01:11\n",
      "[Epoch 2] Step 860 | loss: 0.8025 | step_time: 00:01:14\n",
      "[Epoch 2] Step 880 | loss: 0.8290 | step_time: 00:01:18\n",
      "[Epoch 2] Step 900 | loss: 0.8403 | step_time: 00:01:22\n",
      "Epoch 2 finished in 00:01:25\n",
      "Saving finetuned model to: /root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# finetune_mindflow_ulysses.py 初版初级匹配意识流\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, PreTrainedTokenizerFast\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch.nn as nn\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG - 请按需修改\n",
    "# -------------------------\n",
    "CONFIG = {\n",
    "    \"base_model_path\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",   # 模型一：已微调的诗歌模型（基座）\n",
    "    \"ulysses_txt\": \"/root/autodl-tmp/Pro/Ulysses尤利西斯.txt\",    # 尤利西斯原文 txt（本地）\n",
    "    \"output_dir\": \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\",# 输出模型（二）\n",
    "    \"max_len\": 1024,      # 单个样本最大 token 长度（可调：1024/2048）\n",
    "    \"stride\": 512,        # 滑动窗口重叠\n",
    "    \"batch_size\": 1,      # per device batch size（通常 1 或 2）\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"fp16\": True,\n",
    "    \"lora_r\": 4,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.01,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "    \"print_every_steps\": 20,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "random.seed(CONFIG[\"seed\"])\n",
    "\n",
    "# -------------------------\n",
    "# 1. 加载 tokenizer（Qwen2 正确范式）\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer from\", CONFIG[\"base_model_path\"])\n",
    "\n",
    "tokenizer_path = os.path.join(CONFIG[\"base_model_path\"], \"tokenizer.json\")\n",
    "if os.path.exists(tokenizer_path):\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"base_model_path\"], trust_remote_code=True)\n",
    "\n",
    "# ======【Qwen2 推荐标准设置】======\n",
    "# 1) 明确设置 eos / bos（大多数 qwen2 tokenizer.json 自带，但确保一致）\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.bos_token = \"<|startoftext|>\"\n",
    "\n",
    "# 2) 添加 im_start / im_end\n",
    "# 注意：这一步会重建 vocab → pad_token 会丢失\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\"<|im_start|>\", \"<|im_end|>\"]\n",
    "})\n",
    "\n",
    "# 3) ★ 关键：add_special_tokens 后必须重新设置 pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Tokenizer loaded.\")\n",
    "print(\"  eos_token:\", tokenizer.eos_token)\n",
    "print(\"  bos_token:\", tokenizer.bos_token)\n",
    "print(\"  pad_token:\", tokenizer.pad_token)\n",
    "print(\"  pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"  vocab_size:\", len(tokenizer))\n",
    "# =================================\n",
    "\n",
    "# -------------------------\n",
    "# 2. 从 Ulysses txt 生成 token chunks（滑动窗口）\n",
    "# -------------------------\n",
    "def load_and_tokenize_txt(txt_path, tokenizer, max_len, stride):\n",
    "    print(\"Reading Ulysses txt:\", txt_path)\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    # 简单按段落拆分（保留语义完整性），段落间保留换行\n",
    "    paragraphs = [p.strip() for p in raw.split(\"\\n\\n\") if p.strip()]\n",
    "    print(f\"Found {len(paragraphs)} paragraphs; will pack paragraphs into chunks <= {max_len} tokens.\")\n",
    "\n",
    "    all_chunks = []\n",
    "    cur_ids = []\n",
    "    cur_chars = []\n",
    "\n",
    "    for para in paragraphs:\n",
    "        para_ids = tokenizer(para, add_special_tokens=False)[\"input_ids\"]\n",
    "        if len(para_ids) > max_len:\n",
    "            # 段落本身超长：按 token 窗口切分\n",
    "            start = 0\n",
    "            while start < len(para_ids):\n",
    "                end = min(start + max_len, len(para_ids))\n",
    "                chunk_ids = para_ids[start:end]\n",
    "                chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "                all_chunks.append(chunk_text)\n",
    "                if end == len(para_ids):\n",
    "                    break\n",
    "                start += max_len - stride\n",
    "            continue\n",
    "\n",
    "        # 若加入当前 chunk 后不超长则合并\n",
    "        if len(cur_ids) + len(para_ids) <= max_len:\n",
    "            cur_ids.extend(para_ids)\n",
    "            cur_chars.append(para)\n",
    "        else:\n",
    "            # flush current\n",
    "            if cur_ids:\n",
    "                all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "            # start new\n",
    "            cur_ids = para_ids.copy()\n",
    "            cur_chars = [para]\n",
    "\n",
    "    # flush tail\n",
    "    if cur_ids:\n",
    "        all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "\n",
    "    # 进一步应用滑动窗口以增加多样性（可选）\n",
    "    # 这里我们再把每 chunk 做 stride 分割，避免遗漏跨段上下文\n",
    "    final_chunks = []\n",
    "    for chunk in all_chunks:\n",
    "        ids = tokenizer(chunk, add_special_tokens=False)[\"input_ids\"]\n",
    "        start = 0\n",
    "        while start < len(ids):\n",
    "            end = min(start + max_len, len(ids))\n",
    "            part = tokenizer.decode(ids[start:end], skip_special_tokens=True)\n",
    "            final_chunks.append(part)\n",
    "            if end == len(ids):\n",
    "                break\n",
    "            start += max_len - stride\n",
    "\n",
    "    print(f\"Total token chunks prepared: {len(final_chunks)}\")\n",
    "    return final_chunks\n",
    "\n",
    "chunks = load_and_tokenize_txt(CONFIG[\"ulysses_txt\"], tokenizer, CONFIG[\"max_len\"], CONFIG[\"stride\"])\n",
    "\n",
    "# -------------------------\n",
    "# 3. 构造 Dataset（对话格式 + prefix-only mask）\n",
    "# -------------------------\n",
    "class UlyssesDataset(Dataset):\n",
    "    def __init__(self, chunks, tokenizer, max_len):\n",
    "        self.examples = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for idx, chunk_text in enumerate(chunks):\n",
    "            # user instruction: 要求生成意识流风格的段落（不抄袭原文）\n",
    "            user_instr = (\n",
    "                \"Write an original paragraph in James Joyce's stream-of-consciousness style \"\n",
    "                \"that captures similar imagery and tone as the following excerpt. \"\n",
    "                \"Do not copy exact phrases; be original.\\n\\n\"\n",
    "                f\"Excerpt:\\n{chunk_text}\"\n",
    "            )\n",
    "\n",
    "            # We will teach the model to generate text in this style by using the chunk_text\n",
    "            # as the assistant target. (You can replace this by paraphrases if desired.)\n",
    "            assistant_target = chunk_text\n",
    "\n",
    "            full = f\"<|im_start|>user\\n{user_instr}<|im_end|>\\n<|im_start|>assistant\\n{assistant_target}<|im_end|>\"\n",
    "            enc = tokenizer(full, max_length=self.max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = enc[\"input_ids\"].squeeze(0)\n",
    "            attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
    "            labels = input_ids.clone()\n",
    "\n",
    "            # find assistant start token index to mask prefix\n",
    "            # We search for the tokenizer encoding of \"<|im_start|>assistant\\n\"\n",
    "            # Simpler: find the first occurrence of \"<|im_start|>\" after the user block.\n",
    "            special_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "            # locate positions\n",
    "            ids_list = input_ids.tolist()\n",
    "            assistant_pos = 0\n",
    "            try:\n",
    "                # find second occurrence of im_start (first is user)\n",
    "                first = ids_list.index(special_id)\n",
    "                second = ids_list.index(special_id, first + 1)\n",
    "                assistant_pos = second\n",
    "            except ValueError:\n",
    "                # fallback: try to find the textual marker\n",
    "                txt = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "                marker = \"<|im_start|>assistant\\n\"\n",
    "                if marker in txt:\n",
    "                    assistant_pos = tokenizer(marker, add_special_tokens=False)[\"input_ids\"][0]\n",
    "                    # not reliable; fallback to 0\n",
    "                else:\n",
    "                    assistant_pos = 0\n",
    "\n",
    "            # mask prefix (user + instruction) so loss is only computed on assistant part\n",
    "            labels[:assistant_pos] = -100\n",
    "\n",
    "            self.examples.append({\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "        print(f\"Dataset built: {len(self.examples)} examples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "dataset = UlyssesDataset(chunks, tokenizer, CONFIG[\"max_len\"])\n",
    "dataloader = DataLoader(dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4. 加载基座模型并装上 LoRA\n",
    "# -------------------------\n",
    "print(\"Loading base model from:\", CONFIG[\"base_model_path\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG[\"base_model_path\"],\n",
    "    torch_dtype=torch.float16 if CONFIG[\"fp16\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    target_modules=CONFIG[\"target_modules\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()\n",
    "model.train()\n",
    "\n",
    "# device for inputs: model may be sharded; use next(model.parameters()).device\n",
    "model_device = next(model.parameters()).device\n",
    "print(\"Model device:\", model_device)\n",
    "\n",
    "# -------------------------\n",
    "# 5. optimizer & loss\n",
    "# -------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# -------------------------\n",
    "# 6. 训练循环\n",
    "# -------------------------\n",
    "def format_time(seconds):\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "total_steps = len(dataloader) * CONFIG[\"num_train_epochs\"] // CONFIG[\"gradient_accumulation_steps\"]\n",
    "print(\"Training config -- epochs:\", CONFIG[\"num_train_epochs\"], \"batches_per_epoch:\", len(dataloader), \"total_steps(approx):\", total_steps)\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(CONFIG[\"num_train_epochs\"]):\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        global_step += 1\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(model_device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model_device)\n",
    "        labels = batch[\"labels\"].to(model_device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / CONFIG[\"gradient_accumulation_steps\"]\n",
    "        loss.backward()\n",
    "\n",
    "        if global_step % CONFIG[\"gradient_accumulation_steps\"] == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.5)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item() * CONFIG[\"gradient_accumulation_steps\"]\n",
    "\n",
    "        if global_step % CONFIG[\"print_every_steps\"] == 0:\n",
    "            avg_loss = running_loss / (global_step if global_step>0 else 1)\n",
    "            print(f\"[Epoch {epoch+1}] Step {global_step} | loss: {avg_loss:.4f} | step_time: {format_time(time.time()-epoch_start)}\")\n",
    "\n",
    "    epoch_time = format_time(time.time() - epoch_start)\n",
    "    print(f\"Epoch {epoch+1} finished in {epoch_time}\")\n",
    "\n",
    "# -------------------------\n",
    "# 7. 保存微调后模型（包含 LoRA）\n",
    "# -------------------------\n",
    "print(\"Saving finetuned model to:\", CONFIG[\"output_dir\"])\n",
    "model.save_pretrained(CONFIG[\"output_dir\"])\n",
    "tokenizer.save_pretrained(CONFIG[\"output_dir\"])\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24ff8b-1476-4576-b3a8-cd082a9dcc12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#加要求的意识流风格微调优化方向（LoRA 升级、损失函数扩展、训练参数调整）进行适配\n",
    "# finetune_mindflow_ulysses.py\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, PreTrainedTokenizerFast\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG - 意识流风格微调优化配置（修复LoRA目标模块）\n",
    "# -------------------------\n",
    "CONFIG = {\n",
    "    \"base_model_path\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",   # 模型一：已微调的诗歌模型（基座）\n",
    "    \"ulysses_txt\": \"/root/autodl-tmp/Pro/Ulysses尤利西斯.txt\",    # 尤利西斯原文 txt（本地）\n",
    "    \"output_dir\": \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\",# 输出模型（二）\n",
    "    \"max_len\": 1024,      # 单个样本最大 token 长度（可调：1024/2048）\n",
    "    \"stride\": 512,        # 滑动窗口重叠\n",
    "    \"batch_size\": 1,      # per device batch size（通常 1 或 2）\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 1e-5,  # 优化：降至1e-5（慢学习，精准拟合风格）\n",
    "    \"num_train_epochs\": 5,   # 优化：增至5轮\n",
    "    \"fp16\": True,\n",
    "    \"lora_r\": 16,            # 优化：提升至16（增强风格拟合）\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.01,\n",
    "    # 修复：Qwen2.5的MLP层具体Linear子层名称（替换原mlp）\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \n",
    "                       \"gate_proj\", \"up_proj\", \"down_proj\"],  \n",
    "    \"print_every_steps\": 20,\n",
    "    \"seed\": 42,\n",
    "    # 新增：多样性损失&句式风格损失参数\n",
    "    \"diversity_alpha\": 0.1,  # 多样性损失α提升至0.1\n",
    "    \"style_beta\": 0.05,      # 句式风格损失β系数\n",
    "    \"eps\": 1e-6,             # 数值稳定参数\n",
    "    \"max_norm\": 1.5,         # 梯度裁剪阈值\n",
    "    # 同义词替换参数（保留NLTK wordnet能力）\n",
    "    \"augment_prob\": 0.5      # 50%概率进行同义词替换增强\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "random.seed(CONFIG[\"seed\"])\n",
    "\n",
    "# -------------------------\n",
    "# 仅下载NLTK wordnet（同义词替换用），不下载punkt\n",
    "# -------------------------\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# -------------------------\n",
    "# 保留：英文文本同义词替换增强（基于NLTK wordnet）\n",
    "# -------------------------\n",
    "def augment_english_text(text):\n",
    "    \"\"\"基于NLTK wordnet的同义词替换，保留语义同时提升多样性\"\"\"\n",
    "    if not text or len(text.split()) < 3:\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        # 词性标注，仅替换名词/动词/形容词\n",
    "        pos_tags = nltk.pos_tag(text.split())\n",
    "        augmented_tokens = []\n",
    "        for token, pos in pos_tags:\n",
    "            if pos.startswith('N') or pos.startswith('V') or pos.startswith('J'):\n",
    "                synonyms = wordnet.synsets(token)\n",
    "                if synonyms and len(synonyms) > 0:\n",
    "                    synonym_lemma = synonyms[0].lemmas()[0].name()\n",
    "                    # 严格校验替换词\n",
    "                    if (synonym_lemma != token and \n",
    "                        len(synonym_lemma) <= len(token)+2 and\n",
    "                        not synonym_lemma.isdigit()):\n",
    "                        augmented_tokens.append(synonym_lemma.replace('_', ' '))\n",
    "                    else:\n",
    "                        augmented_tokens.append(token)\n",
    "                else:\n",
    "                    augmented_tokens.append(token)\n",
    "            else:\n",
    "                augmented_tokens.append(token)\n",
    "        return ' '.join(augmented_tokens)\n",
    "    except:\n",
    "        return text  # 增强失败时返回原文本\n",
    "\n",
    "# -------------------------\n",
    "# 1. 加载 tokenizer（Qwen2 正确范式）\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer from\", CONFIG[\"base_model_path\"])\n",
    "\n",
    "tokenizer_path = os.path.join(CONFIG[\"base_model_path\"], \"tokenizer.json\")\n",
    "if os.path.exists(tokenizer_path):\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"base_model_path\"], trust_remote_code=True)\n",
    "\n",
    "# ======【Qwen2 推荐标准设置】======\n",
    "# 1) 明确设置 eos / bos（大多数 qwen2 tokenizer.json 自带，但确保一致）\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.bos_token = \"<|startoftext|>\"\n",
    "\n",
    "# 2) 添加 im_start / im_end\n",
    "# 注意：这一步会重建 vocab → pad_token 会丢失\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\"<|im_start|>\", \"<|im_end|>\"]\n",
    "})\n",
    "\n",
    "# 3) ★ 关键：add_special_tokens 后必须重新设置 pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Tokenizer loaded.\")\n",
    "print(\"  eos_token:\", tokenizer.eos_token)\n",
    "print(\"  bos_token:\", tokenizer.bos_token)\n",
    "print(\"  pad_token:\", tokenizer.pad_token)\n",
    "print(\"  pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"  vocab_size:\", len(tokenizer))\n",
    "# =================================\n",
    "\n",
    "# -------------------------\n",
    "# 2. 从 Ulysses txt 生成 token chunks（滑动窗口 + 文本增强）\n",
    "# -------------------------\n",
    "def load_and_tokenize_txt(txt_path, tokenizer, max_len, stride):\n",
    "    print(\"Reading Ulysses txt:\", txt_path)\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    # 简单按段落拆分（保留语义完整性），段落间保留换行\n",
    "    paragraphs = [p.strip() for p in raw.split(\"\\n\\n\") if p.strip()]\n",
    "    print(f\"Found {len(paragraphs)} paragraphs; will pack paragraphs into chunks <= {max_len} tokens.\")\n",
    "\n",
    "    all_chunks = []\n",
    "    cur_ids = []\n",
    "    cur_chars = []\n",
    "\n",
    "    for para in paragraphs:\n",
    "        # 对段落进行同义词替换增强（保留意识流风格）\n",
    "        if random.random() < CONFIG[\"augment_prob\"]:\n",
    "            para = augment_english_text(para)\n",
    "        \n",
    "        para_ids = tokenizer(para, add_special_tokens=False)[\"input_ids\"]\n",
    "        if len(para_ids) > max_len:\n",
    "            # 段落本身超长：按 token 窗口切分\n",
    "            start = 0\n",
    "            while start < len(para_ids):\n",
    "                end = min(start + max_len, len(para_ids))\n",
    "                chunk_ids = para_ids[start:end]\n",
    "                chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "                all_chunks.append(chunk_text)\n",
    "                if end == len(para_ids):\n",
    "                    break\n",
    "                start += max_len - stride\n",
    "            continue\n",
    "\n",
    "        # 若加入当前 chunk 后不超长则合并\n",
    "        if len(cur_ids) + len(para_ids) <= max_len:\n",
    "            cur_ids.extend(para_ids)\n",
    "            cur_chars.append(para)\n",
    "        else:\n",
    "            # flush current\n",
    "            if cur_ids:\n",
    "                all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "            # start new\n",
    "            cur_ids = para_ids.copy()\n",
    "            cur_chars = [para]\n",
    "\n",
    "    # flush tail\n",
    "    if cur_ids:\n",
    "        all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "\n",
    "    # 进一步应用滑动窗口以增加多样性（可选）\n",
    "    final_chunks = []\n",
    "    for chunk in all_chunks:\n",
    "        ids = tokenizer(chunk, add_special_tokens=False)[\"input_ids\"]\n",
    "        start = 0\n",
    "        while start < len(ids):\n",
    "            end = min(start + max_len, len(ids))\n",
    "            part = tokenizer.decode(ids[start:end], skip_special_tokens=True)\n",
    "            final_chunks.append(part)\n",
    "            if end == len(ids):\n",
    "                break\n",
    "            start += max_len - stride\n",
    "\n",
    "    print(f\"Total token chunks prepared: {len(final_chunks)}\")\n",
    "    return final_chunks\n",
    "\n",
    "chunks = load_and_tokenize_txt(CONFIG[\"ulysses_txt\"], tokenizer, CONFIG[\"max_len\"], CONFIG[\"stride\"])\n",
    "\n",
    "# -------------------------\n",
    "# 调整：句子长度分析工具（无需punkt，基于标点/空格分词）\n",
    "# -------------------------\n",
    "def analyze_sentence_length(text):\n",
    "    \"\"\"\n",
    "    分析文本中的短句占比（无需punkt）\n",
    "    短句定义：≤5个单词的文本片段（按 . ! ? ; , 分割）\n",
    "    \"\"\"\n",
    "    # 清理特殊符号，保留核心文本\n",
    "    clean_text = re.sub(r'<\\|.*?\\|>', '', text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "    \n",
    "    # 按标点分割文本片段（模拟分句，无需punkt）\n",
    "    fragments = re.split(r'[.!?;,]', clean_text)\n",
    "    fragments = [f.strip() for f in fragments if f.strip()]\n",
    "    total_fragments = len(fragments)\n",
    "    \n",
    "    if total_fragments == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # 统计短句数量\n",
    "    short_frag_count = 0\n",
    "    for frag in fragments:\n",
    "        # 分词（仅保留单词）\n",
    "        words = re.findall(r'\\w+', frag)\n",
    "        if len(words) <= 5:\n",
    "            short_frag_count += 1\n",
    "    \n",
    "    # 返回短句占比\n",
    "    return short_frag_count / total_fragments\n",
    "\n",
    "# -------------------------\n",
    "# 新增：损失函数扩展（多样性损失 + 句式风格损失）\n",
    "# -------------------------\n",
    "def diversity_loss(logits, alpha=CONFIG[\"diversity_alpha\"]):\n",
    "    \"\"\"多样性损失：惩罚低熵预测，增强生成多样性\"\"\"\n",
    "    # 转换为fp32计算，避免数值溢出\n",
    "    logits = logits.float()\n",
    "    \n",
    "    # 计算softmax概率分布\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    # 限制概率范围，防止log(0)\n",
    "    probs = torch.clamp(probs, min=CONFIG[\"eps\"], max=1.0 - CONFIG[\"eps\"])\n",
    "    \n",
    "    # 计算熵值\n",
    "    entropy = -torch.sum(probs * torch.log(probs), dim=-1)\n",
    "    # 最大熵（词汇表大小的对数）\n",
    "    vocab_size = probs.size(-1)\n",
    "    max_entropy = torch.log(torch.tensor(vocab_size, dtype=torch.float32, device=logits.device))\n",
    "    # 归一化熵值\n",
    "    entropy_norm = entropy / (max_entropy + CONFIG[\"eps\"])\n",
    "    entropy_norm = torch.clamp(entropy_norm, min=0.0, max=1.0)\n",
    "    \n",
    "    # 惩罚低熵值（保守预测）\n",
    "    penalty = alpha * (1 - entropy_norm)\n",
    "    penalty = torch.nan_to_num(penalty, nan=0.0, posinf=alpha, neginf=0.0)\n",
    "    \n",
    "    return torch.mean(penalty)\n",
    "\n",
    "def style_loss(generated_texts, beta=CONFIG[\"style_beta\"]):\n",
    "    \"\"\"句式风格损失：惩罚长句占比过高，强化碎片化\"\"\"\n",
    "    total_style_penalty = 0.0\n",
    "    valid_text_count = 0\n",
    "    \n",
    "    for text in generated_texts:\n",
    "        short_frag_ratio = analyze_sentence_length(text)\n",
    "        # 惩罚项：1 - 短句占比（短句越少，惩罚越高）\n",
    "        penalty = 1 - short_frag_ratio\n",
    "        total_style_penalty += penalty\n",
    "        valid_text_count += 1\n",
    "    \n",
    "    if valid_text_count == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # 计算平均惩罚并乘以beta系数\n",
    "    avg_penalty = total_style_penalty / valid_text_count\n",
    "    return beta * torch.tensor(avg_penalty, device=device, dtype=torch.float32)\n",
    "\n",
    "# -------------------------\n",
    "# 3. 构造 Dataset（对话格式 + prefix-only mask）\n",
    "# -------------------------\n",
    "class UlyssesDataset(Dataset):\n",
    "    def __init__(self, chunks, tokenizer, max_len):\n",
    "        self.examples = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for idx, chunk_text in enumerate(chunks):\n",
    "            # user instruction: 要求生成意识流风格的段落（不抄袭原文）\n",
    "            user_instr = (\n",
    "                \"Write an original paragraph in James Joyce's stream-of-consciousness style \"\n",
    "                \"that captures similar imagery and tone as the following excerpt. \"\n",
    "                \"Do not copy exact phrases; be original.\\n\\n\"\n",
    "                f\"Excerpt:\\n{chunk_text}\"\n",
    "            )\n",
    "\n",
    "            # 目标文本（可替换为增强后的文本）\n",
    "            assistant_target = chunk_text\n",
    "\n",
    "            full = f\"<|im_start|>user\\n{user_instr}<|im_end|>\\n<|im_start|>assistant\\n{assistant_target}<|im_end|>\"\n",
    "            enc = tokenizer(full, max_length=self.max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = enc[\"input_ids\"].squeeze(0)\n",
    "            attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
    "            labels = input_ids.clone()\n",
    "\n",
    "            # 定位assistant部分起始位置，mask掉user部分的loss\n",
    "            special_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "            ids_list = input_ids.tolist()\n",
    "            assistant_pos = 0\n",
    "            try:\n",
    "                # 找到第二个<|im_start|>（第一个是user）\n",
    "                first = ids_list.index(special_id)\n",
    "                second = ids_list.index(special_id, first + 1)\n",
    "                assistant_pos = second\n",
    "            except ValueError:\n",
    "                assistant_pos = 0\n",
    "\n",
    "            # mask prefix（user + instruction）so loss is only computed on assistant part\n",
    "            labels[:assistant_pos] = -100\n",
    "\n",
    "            self.examples.append({\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"labels\": labels,\n",
    "                \"assistant_text\": assistant_target  # 保存目标文本用于风格损失计算\n",
    "            })\n",
    "\n",
    "        print(f\"Dataset built: {len(self.examples)} examples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "dataset = UlyssesDataset(chunks, tokenizer, CONFIG[\"max_len\"])\n",
    "dataloader = DataLoader(dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4. 加载基座模型并装上 LoRA（修复配置）\n",
    "# -------------------------\n",
    "print(\"Loading base model from:\", CONFIG[\"base_model_path\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG[\"base_model_path\"],\n",
    "    torch_dtype=torch.float16 if CONFIG[\"fp16\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True  # 关键：Qwen2需要trust_remote_code\n",
    ")\n",
    "\n",
    "# 修复：LoRA配置（目标模块为Qwen2.5的具体Linear层）\n",
    "lora_cfg = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    target_modules=CONFIG[\"target_modules\"],  # q_proj/v_proj/k_proj/o_proj + MLP的Linear层\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    bias=\"none\",  # 避免bias训练导致的数值问题\n",
    "    modules_to_save=[],  # 不额外保存模块\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()  # 打印可训练参数占比\n",
    "model.train()\n",
    "\n",
    "# 获取模型设备\n",
    "model_device = next(model.parameters()).device\n",
    "print(\"Model device:\", model_device)\n",
    "\n",
    "# -------------------------\n",
    "# 5. optimizer & loss\n",
    "# -------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "ce_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# -------------------------\n",
    "# 6. 训练循环（集成新损失函数）\n",
    "# -------------------------\n",
    "def format_time(seconds):\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "total_steps = len(dataloader) * CONFIG[\"num_train_epochs\"] // CONFIG[\"gradient_accumulation_steps\"]\n",
    "print(\"Training config -- epochs:\", CONFIG[\"num_train_epochs\"], \"batches_per_epoch:\", len(dataloader), \"total_steps(approx):\", total_steps)\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(CONFIG[\"num_train_epochs\"]):\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_ce_loss = 0.0\n",
    "    running_div_loss = 0.0\n",
    "    running_style_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        global_step += 1\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(model_device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model_device)\n",
    "        labels = batch[\"labels\"].to(model_device)\n",
    "        assistant_texts = batch[\"assistant_text\"]  # 目标文本用于风格损失计算\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        ce_loss = ce_loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        \n",
    "        # 计算多样性损失\n",
    "        div_loss = diversity_loss(logits.view(-1, logits.size(-1)))\n",
    "        \n",
    "        # 计算句式风格损失\n",
    "        style_loss_val = style_loss(assistant_texts)\n",
    "        \n",
    "        # 总损失：交叉熵 + 多样性损失 + 风格损失\n",
    "        total_loss = (ce_loss + div_loss + style_loss_val) / CONFIG[\"gradient_accumulation_steps\"]\n",
    "        total_loss.backward()\n",
    "\n",
    "        # 梯度裁剪 + 优化器更新\n",
    "        if global_step % CONFIG[\"gradient_accumulation_steps\"] == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG[\"max_norm\"])\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # 累计损失\n",
    "        running_loss += total_loss.item() * CONFIG[\"gradient_accumulation_steps\"]\n",
    "        running_ce_loss += ce_loss.item()\n",
    "        running_div_loss += div_loss.item()\n",
    "        running_style_loss += style_loss_val.item()\n",
    "\n",
    "        # 打印训练日志\n",
    "        if global_step % CONFIG[\"print_every_steps\"] == 0:\n",
    "            avg_loss = running_loss / (global_step if global_step>0 else 1)\n",
    "            avg_ce = running_ce_loss / (global_step if global_step>0 else 1)\n",
    "            avg_div = running_div_loss / (global_step if global_step>0 else 1)\n",
    "            avg_style = running_style_loss / (global_step if global_step>0 else 1)\n",
    "            print(f\"[Epoch {epoch+1}] Step {global_step} | total_loss: {avg_loss:.4f} | ce_loss: {avg_ce:.4f} | div_loss: {avg_div:.4f} | style_loss: {avg_style:.4f} | time: {format_time(time.time()-epoch_start)}\")\n",
    "\n",
    "    epoch_time = format_time(time.time() - epoch_start)\n",
    "    print(f\"Epoch {epoch+1} finished in {epoch_time} | avg_epoch_loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 7. 保存微调后模型（包含 LoRA）\n",
    "# -------------------------\n",
    "print(\"Saving finetuned model to:\", CONFIG[\"output_dir\"])\n",
    "model.save_pretrained(CONFIG[\"output_dir\"])\n",
    "tokenizer.save_pretrained(CONFIG[\"output_dir\"])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438f5744-afb9-435b-890c-b155ae9e7d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['token_type_ids', 'device'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# ====================== 测试 ======================\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     result = \u001b[43mgenerate_poem\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m写一首诗\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== 生成的诗歌 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mgenerate_poem\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 生成\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 直接传字典，包含input_ids和attention_mask\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 显式指定生成设备\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 解析结果\u001b[39;00m\n\u001b[32m     56\u001b[39m poem = tokenizer.decode(output[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/peft_model.py:2048\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   2046\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   2047\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2049\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2050\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen_text/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen_text/lib/python3.11/site-packages/transformers/generation/utils.py:2388\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2385\u001b[39m     \u001b[38;5;66;03m# type() required to access the unbound class-level method\u001b[39;00m\n\u001b[32m   2386\u001b[39m     decoding_method = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), GENERATION_MODES_MAPPING[generation_mode])\n\u001b[32m-> \u001b[39m\u001b[32m2388\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2389\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_generation_mode(generation_mode, generation_config, generation_mode_kwargs)\n\u001b[32m   2391\u001b[39m \u001b[38;5;66;03m# Deprecation-related step: set Hub repo for deprecated strategies.\u001b[39;00m\n\u001b[32m   2392\u001b[39m \u001b[38;5;66;03m# NOTE: This must come after initializing generation_config, since we need it to determine if this is a deprecated mode.\u001b[39;00m\n\u001b[32m   2393\u001b[39m \u001b[38;5;66;03m# It must also be before any preparation steps, since Hub repos expect to be loaded before preparation steps.\u001b[39;00m\n\u001b[32m   2394\u001b[39m \u001b[38;5;66;03m# TODO joao, manuel: remove this in v4.62.0\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qwen_text/lib/python3.11/site-packages/transformers/generation/utils.py:1599\u001b[39m, in \u001b[36mGenerationMixin._validate_model_kwargs\u001b[39m\u001b[34m(self, model_kwargs)\u001b[39m\n\u001b[32m   1596\u001b[39m         unused_model_args.append(key)\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m unused_model_args:\n\u001b[32m-> \u001b[39m\u001b[32m1599\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1600\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_model_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (note: typos in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1601\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m generate arguments will also show up in this list)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1602\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The following `model_kwargs` are not used by the model: ['token_type_ids', 'device'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# ====================== 核心配置 ======================\n",
    "BASE_MODEL_PATH = \"/root/autodl-tmp/Pro/qwen2.5-sft-full\"\n",
    "LORA_VER2_PATH = \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses-ver2\"\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # 强制指定cuda:0\n",
    "\n",
    "# ====================== 加载tokenizer ======================\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ====================== 加载模型（强制单设备） ======================\n",
    "# 加载基座模型（关闭auto设备映射，强制指定DEVICE）\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": DEVICE},  # 强制所有层都在指定设备\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 加载LoRA并移到指定设备\n",
    "model = PeftModel.from_pretrained(model, LORA_VER2_PATH)\n",
    "model = model.to(DEVICE)  # 强制模型整体移到DEVICE\n",
    "model.eval()\n",
    "\n",
    "# ====================== 生成函数 ======================\n",
    "def generate_poem(prompt):\n",
    "    # 封装prompt\n",
    "    input_text = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    \n",
    "    # 编码（强制移到DEVICE）\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(DEVICE)  # 关键：输入张量移到DEVICE\n",
    "    \n",
    "    # 生成\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,  # 直接传字典，包含input_ids和attention_mask\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.8,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.0,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            device=DEVICE  # 显式指定生成设备\n",
    "        )\n",
    "    \n",
    "    # 解析结果\n",
    "    poem = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    poem = poem.split(\"<|im_start|>assistant\\n\")[-1].strip()\n",
    "    return poem\n",
    "\n",
    "# ====================== 测试 ======================\n",
    "if __name__ == \"__main__\":\n",
    "    result = generate_poem(\"写一首诗\")\n",
    "    print(\"=== 生成的诗歌 ===\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0832566-8571-4c51-ab21-7f1b3c983d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "================================================================================\n",
      "Test Prompt:\n",
      "write a poem in the style of virginia wolf, with keyword: willow, wind, fluffy, charmed.\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] Loading Original Poetry Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2/3] Loading Mindflow Enhanced Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3/3] Generating Poems...\n",
      "\n",
      "=== 1. Original Poetry Model Output ===\n",
      "All the world was green, and so was she. She was all wind, and wind was all her hair.\n",
      "The wind blew her dress about like the sails of a ship, and it was all of willow. She went, she went, she was all fluff. She was all fluff, and all of willow. She had no heart, she was all fluff. She was all fluff, she had no heart. She had no heart, and she was all fluff. She was all fluff, she had no heart. She had no heart, and she was all fluff. She was all fluff, she had no heart. She had no heart, she was all fluff. She was all fluff, she had no heart.\n",
      "\n",
      "=== 2. Mindflow Enhanced Model Output ===\n",
      "In a garden where the willow weeps and wails,\n",
      "Under skies that weave their silvery trails,\n",
      "The wind, a witch, does softly play,\n",
      "With leaves and boughs that dance away.\n",
      "\n",
      "A fluffy cloud, like cotton in the breeze,\n",
      "Drifts over willow, soft as eves,\n",
      "In a charmed garden, far from madding crowd,\n",
      "Where shadows lie, and dreams are loud.\n",
      "\n",
      "The willow whispers, \"Listen, hark!\"\n",
      "To secrets shared by wind and bark,\n",
      "And as the gusts with gentle force do blow,\n",
      "They dance and tumble, in a playful flow.\n",
      "\n",
      "In twilight's lap, the willow stands,\n",
      "A guardian of the magic lands,\n",
      "Charmed by whispers and the wind's soft breath,\n",
      "In gardens woven from leaf and death.\n",
      "\n",
      "So, sit you down, in the willow's shade,\n",
      "Beneath the spell of night's own shade,\n",
      "And listen to the wind's sweet song,\n",
      "Charmed by nature, charmed by long.\n"
     ]
    }
   ],
   "source": [
    "# inference_mindflow.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. 配置路径（新增原始诗歌LoRA路径）\n",
    "# -------------------------\n",
    "BASE_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-sft-full\"               # 基础诗歌微调基座（模型一）\n",
    "LORA_POETRY = \"\"  # 【必填】原始诗歌LoRA适配器路径（若模型一是全量微调则留空）\n",
    "LORA_MINDFLOW = \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"  # 意识流增强LoRA（模型二）\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.02,\n",
    "    \"do_sample\": True,  # 确保采样生成，增强多样性\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# 2. 加载通用tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 必须设置 pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 3. 模型加载工具函数（复用基座，切换LoRA）\n",
    "# -------------------------\n",
    "def load_model_with_lora(base_model_path, lora_path=None):\n",
    "    \"\"\"\n",
    "    加载基座模型 + 指定LoRA适配器\n",
    "    :param base_model_path: 基座模型路径\n",
    "    :param lora_path: LoRA适配器路径（None则仅加载基座）\n",
    "    :return: 加载完成的模型\n",
    "    \"\"\"\n",
    "    # 加载基座模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # 加载LoRA（若指定）\n",
    "    if lora_path and lora_path.strip() != \"\":\n",
    "        model = PeftModel.from_pretrained(model, lora_path)\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# 4. 统一推理函数\n",
    "# -------------------------\n",
    "def generate_poem(model, tokenizer, prompt: str, gen_cfg: dict):\n",
    "    \"\"\"\n",
    "    统一生成函数，适配任意模型\n",
    "    \"\"\"\n",
    "    # 保持和训练一致的对话格式\n",
    "    formatted = (\n",
    "        f\"<|im_start|>user\\n{prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        formatted,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **gen_cfg\n",
    "        )\n",
    "\n",
    "    # 清理生成结果\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# -------------------------\n",
    "# 5. 主推理流程（双模型对比）\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试Prompt\n",
    "    test_prompt = (\n",
    "        \"write a poem in the style of virginia wolf, with keyword: willow, wind, fluffy, charmed.\"\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"Test Prompt:\\n{test_prompt}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 加载模型1：原始诗歌微调模型\n",
    "    print(\"\\n[Step 1/3] Loading Original Poetry Model...\")\n",
    "    model_poetry = load_model_with_lora(BASE_MODEL, LORA_POETRY)\n",
    "    \n",
    "    # 加载模型2：意识流增强微调模型\n",
    "    print(\"\\n[Step 2/3] Loading Mindflow Enhanced Model...\")\n",
    "    model_mindflow = load_model_with_lora(BASE_MODEL, LORA_MINDFLOW)\n",
    "\n",
    "    # 生成诗歌（双模型）\n",
    "    print(\"\\n[Step 3/3] Generating Poems...\")\n",
    "    print(\"\\n=== 1. Original Poetry Model Output ===\")\n",
    "    poem_poetry = generate_poem(model_poetry, tokenizer, test_prompt, GEN_CFG)\n",
    "    print(poem_poetry)\n",
    "\n",
    "    print(\"\\n=== 2. Mindflow Enhanced Model Output ===\")\n",
    "    poem_mindflow = generate_poem(model_mindflow, tokenizer, test_prompt, GEN_CFG)\n",
    "    print(poem_mindflow)\n",
    "\n",
    "    # 释放显存（可选）\n",
    "    del model_poetry, model_mindflow\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd187bbd-dfb7-420e-820c-da9fa02283f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter...\n",
      "\n",
      "🧠 Mindflow Poetry Generator\n",
      "输入 prompt 回车生成\n",
      "输入 reset 清空记忆\n",
      "输入 exit 退出并保存终版诗歌\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  write a poem in the style of virginia wolf, with keyword: willow, wind, fluffy, charmed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ===\n",
      "\n",
      "Beneath the weeping willow's boughs I sit,\n",
      "Where whispers flit and leaves rustle light.\n",
      "The wind, an ethereal wraith, doth blow,\n",
      "Tangling my thoughts 'neath this shady bower.\n",
      "\n",
      "My mind, like fluff, drifts on each gentle breeze—\n",
      "Charmed by shadows that dance and tease.\n",
      "A world beyond mere matter seems to lie,\n",
      "Enchanted tales that whisper in the night.\n",
      "\n",
      "I close my eyes, and see the scene unroll:\n",
      "Willows sway in harmony with wind's call.\n",
      "Each leaf a page from some forgotten book,\n",
      "Whispering secrets, songs of magic's hook.\n",
      "\n",
      "In this charmed garden, lost and free,\n",
      "Thoughts intertwine as softly as tree roots be.\n",
      "Fluffy dreams take flight, no more to stay,\n",
      "In willowy arms where only wonder may.\n",
      "\n",
      "=================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  confine the imagery willow in the first stanza. Imageries in the following stanza comes with the mindflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ===\n",
      "\n",
      "Beneath the weeping willow’s boughs I sit,\n",
      "Where whispers flit and leaves rustle light.\n",
      "The wind, an ethereal wraith, doth blow,\n",
      "Tangling my thoughts 'neath this shady bower.\n",
      "\n",
      "My mind, like fluff, drifts on each gentle breeze—\n",
      "Charmed by shadows that dance and tease.\n",
      "Willows sway, their branches intertwined,\n",
      "Leaves weave a tapestry that time has mended.\n",
      "Each leaf a page from some forgotten book,\n",
      "Whispering secrets, songs of magic’s hook.\n",
      "Soft murmurs float through air so still,\n",
      "Echoes of stories once untold.\n",
      "\n",
      "I close my eyes, and see the scene unroll:\n",
      "Willows sway in harmony with wind’s call.\n",
      "Each branch a quill, inscribing time’s soft breath,\n",
      "Etching visions ‘cross the twilight’s death.\n",
      "Fluffy dreams take flight, no more to stay,\n",
      "In willowy arms where only wonder may.\n",
      "\n",
      "=================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  please do not use willow in the next three stanzas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ===\n",
      "\n",
      "Beneath the weeping willow’s boughs I sit,\n",
      "Where whispers flit and leaves rustle light.\n",
      "The wind, an ethereal wraith, doth blow,\n",
      "Tangling my thoughts 'neath this shady bower.\n",
      "\n",
      "My mind, like fluff, drifts on each gentle breeze—\n",
      "Charmed by shadows that dance and tease.\n",
      "Willows sway, their branches intertwined,\n",
      "Leaves weave a tapestry that time has mended.\n",
      "Each leaf a page from some forgotten book,\n",
      "Whispering secrets, songs of magic’s hook.\n",
      "Soft murmurs float through air so still,\n",
      "Echoes of stories once untold.\n",
      "\n",
      "I close my eyes, and see the scene unroll:\n",
      "Willows sway in harmony with wind’s call.\n",
      "Each branch a quill, inscribing time’s soft breath,\n",
      "Etching visions ‘cross the twilight’s death.\n",
      "Fluffy dreams take flight, no more to stay,\n",
      "In willowy arms where only wonder may.\n",
      "\n",
      "Beyond the trees, the world unfurls its tale,\n",
      "A canvas vast, yet filled with subtle grace.\n",
      "Fields stretch wide, their grass swaying slow,\n",
      "Gentle murmurs blend into nature's flow.\n",
      "Pebbled streams meander, crystal clear,\n",
      "Mirroring skies that paint their blue so dear.\n",
      "Clouds drift by like ghostly white ships,\n",
      "Navigating through the day’s endless dips.\n",
      "\n",
      "=================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. 配置\n",
    "# -------------------------\n",
    "BASE_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-sft-full\"\n",
    "LORA_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 400,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.12,\n",
    "}\n",
    "\n",
    "# 新增：保存配置\n",
    "SAVE_FOLDER = \"./poetry_results\"  # 保存目录\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)  # 自动创建目录（不存在时）\n",
    "\n",
    "# -------------------------\n",
    "# 2. 加载 tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 3. 加载模型 + LoRA\n",
    "# -------------------------\n",
    "print(\"Loading base model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(model, LORA_MODEL)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 4. 核心：带“记忆”的生成\n",
    "# -------------------------\n",
    "conversation_memory = \"\"   # ⭐ 存上一轮生成结果\n",
    "\n",
    "\n",
    "def generate_with_memory(user_prompt: str):\n",
    "    global conversation_memory\n",
    "\n",
    "    if conversation_memory:\n",
    "        # 在已有诗歌基础上 refinement\n",
    "        formatted = (\n",
    "            \"<|im_start|>user\\n\"\n",
    "            \"Here is the previous poem:\\n\"\n",
    "            f\"{conversation_memory}\\n\\n\"\n",
    "            \"Please revise or continue it according to the following instruction:\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # 第一轮\n",
    "        formatted = (\n",
    "            f\"<|im_start|>user\\n{user_prompt}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    input_ids = tokenizer(formatted, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **GEN_CFG\n",
    "        )\n",
    "\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    # 清理输出\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    # ⭐ 更新记忆\n",
    "    conversation_memory = text\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. 交互式输入\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n🧠 Mindflow Poetry Generator\")\n",
    "    print(\"输入 prompt 回车生成\")\n",
    "    print(\"输入 reset 清空记忆\")\n",
    "    print(\"输入 exit 退出并保存终版诗歌\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\">>> \").strip()\n",
    "\n",
    "        if user_input.lower() == \"exit\":\n",
    "            # 保存终版诗歌到txt文件\n",
    "            if conversation_memory:\n",
    "                # 生成带时间戳的文件名，避免覆盖\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "                file_path = os.path.join(SAVE_FOLDER, f\"final_poem_{timestamp}.txt\")\n",
    "                \n",
    "                # 写入文件（UTF-8编码防止中文乱码）\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(\"=== Mindflow Poetry Final Version ===\\n\")\n",
    "                    f.write(f\"Generated Time: {time.ctime()}\\n\")\n",
    "                    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "                    f.write(conversation_memory)\n",
    "                \n",
    "                print(f\"\\n✅ 终版诗歌已保存至：{file_path}\")\n",
    "            else:\n",
    "                print(\"\\n⚠️  暂无生成的诗歌内容，未保存文件\")\n",
    "            \n",
    "            print(\"Bye.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() == \"reset\":\n",
    "            conversation_memory = \"\"\n",
    "            print(\"🔄 Memory cleared.\\n\")\n",
    "            continue\n",
    "\n",
    "        output = generate_with_memory(user_input)\n",
    "\n",
    "        print(\"\\n=== Generated ===\\n\")\n",
    "        print(output)\n",
    "        print(\"\\n=================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7349fb-842d-41aa-86e4-5ec97a2497ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "\n",
      "Loading BASE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SFT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MINDFLOW model (base + LoRA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All models loaded successfully!\n",
      "\n",
      "\n",
      "🧠 Mindflow Poetry Generator - Multi-Model Mode\n",
      "======================================================================\n",
      "指令说明：\n",
      "  1. 直接输入文本      - 同时调用BASE/SFT/MINDFLOW三个模型生成诗歌\n",
      "  2. reset             - 清空所有模型的对话记忆\n",
      "  3. exit              - 退出并保存所有模型的终版诗歌\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  write a poem in Walt whitman style, using the keyword: nature, chirping, farm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "🔄 Generating with BASE model...\n",
      "🔄 Generating with SFT model...\n",
      "🔄 Generating with MINDFLOW model...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 BASE MODEL OUTPUT:\n",
      "\n",
      "In fields where the sun’s warm hands caress,\n",
      "And nature whispers to the whispering breeze,\n",
      "I hear the songs that fill this vast expanse—\n",
      "Chirping crickets and larks ascending.\n",
      "\n",
      "Amidst rows of corn and wheat so green,\n",
      "Where cows graze tranquil as their breaths are seen,\n",
      "A farmer tills with slow, sure pace and might,\n",
      "His heart with every furrow taking flight.\n",
      "\n",
      "Beneath the big blue sky's expansive dome,\n",
      "He works the earth, the very essence of home.\n",
      "The soil rich with the promise of tomorrow,\n",
      "As seasons turn like leaves upon the floor.\n",
      "\n",
      "This land, so wild yet cultivated too,\n",
      "Sings with life in voices low and true.\n",
      "The chirping thrums through the air, light as thought,\n",
      "Nature’s symphony, on and around the plot.\n",
      "\n",
      "So let me wander, hand in hand with time,\n",
      "Among these plots, among these rolling climbs.\n",
      "For here I find my spirit set at ease,\n",
      "By nature’s chords, by labor’s endless seas.\n",
      "\n",
      "================================================================================\n",
      "📝 SFT MODEL OUTPUT:\n",
      "\n",
      "I too sing America! I am large—I contain multitudes.\n",
      "From every sound of life, from my own voice sounding,\n",
      "And that of others, even to the last far-off muted strain,\n",
      "Whate’er it is must be significant—every one of its phrases a word in mine;\n",
      "Each echo an affirmation—each sound and shade has its correspondent in me.\n",
      "All sounds are significant—the cricket’s, the grasshopper’s, or any insect’s high-pitched note;\n",
      "The bird’s song on the hill-tops morning and evening, as he perches on the hemlock or oak, or flutters about the field-bird’s home;\n",
      "Or if in summer’s still hour on the lawn I hear the bee humming through the air,\n",
      "So faintly, yet so confident, no matter which way turned,\n",
      "Sure as fate’s hand whispers me to turn the page of my book,\n",
      "He says his say, with his tiny wings half-opened, flying lightly on—tells all his news,\n",
      "Then settles by my side, and hums his song of love,\n",
      "Sings louder and clearer, for here he means to stay;\n",
      "It seems to me to have a deep meaning this little being’s talk;\n",
      "Somehow it penetrates my spirit, and takes root there.\n",
      "Nature’s most secret thought seems whispering in each tone;\n",
      "She never stops to consider, nor thinks to teach or show,\n",
      "But goes her ways, and lets us find out what we can;\n",
      "Let them come from China or Europe, the newest arrivals, or those who have been many days in prison,\n",
      "They will hear the same tune, the same cry of joy, and wonder, and passion.\n",
      "The farmer, the mechanic, the laborer, all join their voices with mine,\n",
      "To praise and honor the land of our birth—its rivers, mountains, lakes and plains;\n",
      "Where ever the sunset shines upon our land, it is blessed and praised.\n",
      "There is a sweet old-time melody, heard once only\n",
      "\n",
      "================================================================================\n",
      "📝 MINDFLOW MODEL OUTPUT:\n",
      "\n",
      "In fields where nature's breath doth sigh,\n",
      "And sunbeams kiss the waving hay,\n",
      "Where murmurs of sweet moisture fly,\n",
      "A song of life and toil they lay.\n",
      "\n",
      "Upon the farms the morning breaks,\n",
      "The roosters crow, and cows low soft.\n",
      "Young swains, with boots all laced and stakes,\n",
      "Begin their work at early not.\n",
      "\n",
      "Chirping thrushes fill the green lanes—\n",
      "Sparrows sing in sprigged apple boughs.\n",
      "All creatures wake as Nature paints,\n",
      "Her canvas bright with dawn’s blush now.\n",
      "\n",
      "The plowman, strong as oak trees' root,\n",
      "Draws furrows deep in soil dark brown.\n",
      "His spade, like arm of Atlas, fraught\n",
      "With power to lift the earth around.\n",
      "\n",
      "Here wheat is born from loam so rich,\n",
      "And cornfields stretch like golden seas.\n",
      "Nature’s bounty here does teach us much:\n",
      "Toiled for by hands that will not cease.\n",
      "\n",
      "From morn till night, with steadfast mind,\n",
      "These farmers bend their willing will.\n",
      "Each task they know must be combined,\n",
      "To thrive and grow beneath the hill.\n",
      "\n",
      "Thus through the day they labor hard,\n",
      "Till stars come out, and darkness draws.\n",
      "Then grateful hearts to rest are charted,\n",
      "For toilsome days have wrought new straw.  \n",
      "\n",
      "So let it be when sunset comes,\n",
      "When fields lie still under the star.\n",
      "We thank these workers for our homes,\n",
      "And cherish all we get in bar.\n",
      "\n",
      "This poem uses elements inspired by Walt Whitman's style, including free verse, an emphasis on natural imagery and rural life, and a focus on the rhythms of daily existence on a farm. The repetition and use of dashes also echo some of Whitman's characteristic techniques.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 所有模型的终版诗歌已保存至：./poetry_results/all_models_poem_20251213_180850.txt\n",
      "\n",
      "👋 Bye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. 配置\n",
    "# -------------------------\n",
    "# 模型路径配置\n",
    "MODEL_PATHS = {\n",
    "    \"base\": \"/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\",\n",
    "    \"sft\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",\n",
    "    \"mindflow\": {\n",
    "        \"base\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",\n",
    "        \"lora\": \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 400,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.12,\n",
    "}\n",
    "\n",
    "# 新增：保存配置\n",
    "SAVE_FOLDER = \"./poetry_results\"  # 保存目录\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)  # 自动创建目录（不存在时）\n",
    "\n",
    "# -------------------------\n",
    "# 2. 全局变量：多模型记忆存储\n",
    "# -------------------------\n",
    "# 分别存储三个模型的对话记忆\n",
    "conversation_memory = {\n",
    "    \"base\": \"\",\n",
    "    \"sft\": \"\",\n",
    "    \"mindflow\": \"\"\n",
    "}\n",
    "tokenizer = None  # 全局tokenizer\n",
    "models = {}  # 存储加载的模型\n",
    "\n",
    "# -------------------------\n",
    "# 3. 加载 tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATHS[\"base\"],\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 4. 加载所有模型\n",
    "# -------------------------\n",
    "def load_all_models():\n",
    "    \"\"\"加载所有三个模型\"\"\"\n",
    "    # 加载Base模型\n",
    "    print(\"\\nLoading BASE model...\")\n",
    "    models[\"base\"] = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"base\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    # 加载SFT模型\n",
    "    print(\"Loading SFT model...\")\n",
    "    models[\"sft\"] = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"sft\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    # 加载Mindflow模型（base + LoRA）\n",
    "    print(\"Loading MINDFLOW model (base + LoRA)...\")\n",
    "    mindflow_base = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"mindflow\"][\"base\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    models[\"mindflow\"] = PeftModel.from_pretrained(\n",
    "        mindflow_base,\n",
    "        MODEL_PATHS[\"mindflow\"][\"lora\"]\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\n✅ All models loaded successfully!\")\n",
    "    return models\n",
    "\n",
    "# -------------------------\n",
    "# 5. 核心：带“记忆”的多模型生成\n",
    "# -------------------------\n",
    "def generate_with_memory(user_prompt: str, model_type: str):\n",
    "    \"\"\"带记忆的生成函数（指定模型）\"\"\"\n",
    "    global conversation_memory, models, tokenizer\n",
    "\n",
    "    model = models[model_type]\n",
    "    memory = conversation_memory[model_type]\n",
    "\n",
    "    # 构建带记忆的prompt\n",
    "    if memory:\n",
    "        formatted = (\n",
    "            \"<|im_start|>user\\n\"\n",
    "            \"Here is the previous poem:\\n\"\n",
    "            f\"{memory}\\n\\n\"\n",
    "            \"Please revise or continue it according to the following instruction:\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # 第一轮生成\n",
    "        formatted = (\n",
    "            f\"<|im_start|>user\\n{user_prompt}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    # 编码输入\n",
    "    input_ids = tokenizer(formatted, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    # 生成输出\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **GEN_CFG\n",
    "        )\n",
    "\n",
    "    # 解码并清理输出\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    # 更新对应模型的记忆\n",
    "    conversation_memory[model_type] = text\n",
    "\n",
    "    return text\n",
    "\n",
    "def generate_all_models(user_prompt: str):\n",
    "    \"\"\"同时调用三个模型生成结果\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    # Base模型生成\n",
    "    print(\"🔄 Generating with BASE model...\")\n",
    "    results[\"base\"] = generate_with_memory(user_prompt, \"base\")\n",
    "    \n",
    "    # SFT模型生成\n",
    "    print(\"🔄 Generating with SFT model...\")\n",
    "    results[\"sft\"] = generate_with_memory(user_prompt, \"sft\")\n",
    "    \n",
    "    # Mindflow模型生成\n",
    "    print(\"🔄 Generating with MINDFLOW model...\")\n",
    "    results[\"mindflow\"] = generate_with_memory(user_prompt, \"mindflow\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# 6. 保存所有模型的终版结果\n",
    "# -------------------------\n",
    "def save_all_results():\n",
    "    \"\"\"保存三个模型的终版输出\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    file_path = os.path.join(SAVE_FOLDER, f\"all_models_poem_{timestamp}.txt\")\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        # 写入元信息\n",
    "        f.write(\"=== Mindflow Poetry - All Models Final Results ===\\n\")\n",
    "        f.write(f\"Generated Time: {time.ctime()}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        # 写入Base模型结果\n",
    "        f.write(\"📌 BASE MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"base\"] if conversation_memory[\"base\"] else \"No content generated\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # 写入SFT模型结果\n",
    "        f.write(\"📌 SFT MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"sft\"] if conversation_memory[\"sft\"] else \"No content generated\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # 写入Mindflow模型结果\n",
    "        f.write(\"📌 MINDFLOW MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"mindflow\"] if conversation_memory[\"mindflow\"] else \"No content generated\\n\")\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# -------------------------\n",
    "# 7. 交互式输入\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载所有模型\n",
    "    models = load_all_models()\n",
    "    \n",
    "    # 交互式界面\n",
    "    print(\"\\n\\n🧠 Mindflow Poetry Generator - Multi-Model Mode\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"指令说明：\")\n",
    "    print(\"  1. 直接输入文本      - 同时调用BASE/SFT/MINDFLOW三个模型生成诗歌\")\n",
    "    print(\"  2. reset             - 清空所有模型的对话记忆\")\n",
    "    print(\"  3. exit              - 退出并保存所有模型的终版诗歌\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\">>> \").strip()\n",
    "\n",
    "        if not user_input:\n",
    "            print(\"⚠️  请输入有效内容！\")\n",
    "            continue\n",
    "\n",
    "        # 退出并保存所有结果\n",
    "        if user_input.lower() == \"exit\":\n",
    "            # 检查是否有生成内容\n",
    "            has_content = any(bool(v) for v in conversation_memory.values())\n",
    "            if has_content:\n",
    "                file_path = save_all_results()\n",
    "                print(f\"\\n✅ 所有模型的终版诗歌已保存至：{file_path}\")\n",
    "            else:\n",
    "                print(\"\\n⚠️  暂无生成的诗歌内容，未保存文件\")\n",
    "            \n",
    "            print(\"\\n👋 Bye!\")\n",
    "            break\n",
    "\n",
    "        # 清空所有记忆\n",
    "        elif user_input.lower() == \"reset\":\n",
    "            conversation_memory = {\n",
    "                \"base\": \"\",\n",
    "                \"sft\": \"\",\n",
    "                \"mindflow\": \"\"\n",
    "            }\n",
    "            print(\"✅ 已清空所有模型的对话记忆！\\n\")\n",
    "            continue\n",
    "\n",
    "        # 正常生成：同时调用三个模型\n",
    "        else:\n",
    "            # 生成所有模型的结果\n",
    "            results = generate_all_models(user_input)\n",
    "            \n",
    "            # 输出结果\n",
    "            print(\"📝 BASE MODEL OUTPUT:\\n\")\n",
    "            print(results[\"base\"])\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            \n",
    "            print(\"📝 SFT MODEL OUTPUT:\\n\")\n",
    "            print(results[\"sft\"])\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            \n",
    "            print(\"📝 MINDFLOW MODEL OUTPUT:\\n\")\n",
    "            print(results[\"mindflow\"])\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95051678-d472-48af-8b09-6bf968211cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Loading similarity model (all-mpnet-base-v2)...\n",
      "\n",
      "📥 Loading training data from /root/autodl-tmp/Pro/poetry_sft.jsonl...\n",
      "✅ 从训练集提取到 13753 首诗歌\n",
      "\n",
      "⚡ Precomputing embeddings for training poems...\n",
      "\n",
      "📤 Loading saved poems from /root/autodl-tmp/Pro/poetry_results/all_models_poem_20251213_180850.txt...\n",
      "\n",
      "====================================================================================================\n",
      "📊 相似度对比结果（生成诗歌 ↔ 训练集最相似诗歌）\n",
      "====================================================================================================\n",
      "\n",
      "📝 BASE 模型生成诗歌：\n",
      "--------------------------------------------------\n",
      "In fields where the sun’s warm hands caress,\n",
      "And nature whispers to the whispering breeze,\n",
      "I hear the songs that fill this vast expanse—\n",
      "Chirping crickets and larks ascending.\n",
      "Amidst rows of corn and wheat so green,\n",
      "Where cows graze tranquil as their breaths are seen,\n",
      "A farmer tills with slow, sure pace and might,\n",
      "His heart with every furrow taking flight.\n",
      "Beneath the big blue sky's expansive dome,\n",
      "He works the earth, the very essence of home.\n",
      "The soil rich with the promise of tomorrow,\n",
      "As seasons turn like leaves upon the floor.\n",
      "This land, so wild yet cultivated too,\n",
      "Sings with life in voices low and true.\n",
      "The chirping thrums through the air, light as thought,\n",
      "Nature’s symphony, on and around the plot.\n",
      "So let me wander, hand in hand with time,\n",
      "Among these plots, among these rolling climbs.\n",
      "For here I find my spirit set at ease,\n",
      "By nature’s chords, by labor’s endless seas.\n",
      "--------------------------------------------------\n",
      "\n",
      "🎯 与训练集最相似诗歌的相似度：0.8087\n",
      "\n",
      "🆚 训练集中最相似的诗歌：\n",
      "--------------------------------------------------\n",
      "From the high terrace porch I watch the dawn.\n",
      "No light appears, though dark has mostly gone,\n",
      "Sunk from the cold and monstrous stone. The hills\n",
      "Lie naked but not light. The darkness spills\n",
      "Down the remoter gulleys; pooled, will stay\n",
      "Too low to melt, not yet alive with day.\n",
      "Below the windows, the lawn, matted deep\n",
      "Under its close-cropped tips with dewy sleep,\n",
      "Gives off a faint hush, all its plushy swarm\n",
      "Alive with coolness reaching to be warm.\n",
      "Gray windows at my back, the massy frame\n",
      "Dull with the blackness that has not a name;\n",
      "But down below, the garden is still young,\n",
      "Of five years’ growth, perhaps, and terrace-hung,\n",
      "Drop by slow drop of seeping concrete walls.\n",
      "Such are the bastions of our pastorals!\n",
      "Here are no palms! They once lined country ways,\n",
      "Where old white houses glared down dusty days,\n",
      "With small round towers, blunt-headed through small trees.\n",
      "Those towers are now the hiving place of bees.\n",
      "The palms were coarse; their leaves hung thick with dust;\n",
      "The roads were muffled deep. But now deep rust\n",
      "Has fastened on the wheels that labored then.\n",
      "Peace to all such, and to all sleeping men!\n",
      "I lived my childhood there, a passive dream\n",
      "In the expanse of that recessive scheme.\n",
      "Slow air, slow fire! O deep delay of Time!\n",
      "That summer crater smoked like slaking lime,\n",
      "The hills so dry, so dense the underbrush,\n",
      "That where I pushed my way the giant hush\n",
      "Was changed to soft explosion as the sage\n",
      "Broke down to powdered ash, the sift of age,\n",
      "And fell along my path, a shadowy rift.\n",
      "On these rocks now no burning ashes drift;\n",
      "Mowed lawn has crept along the granite bench;\n",
      "The yellow blossoms of acacia drench\n",
      "The dawn with pollen; and, with waxen green,\n",
      "The long leaves of the eucalypti screen\n",
      "The closer hills from view—lithe, tall, and fine,\n",
      "And nobly clad with youth, they bend and shine.\n",
      "The small dark pool, jutting with living rock,\n",
      "Trembles at every atmospheric shock,\n",
      "Blurred to its depth with the cold living ooze.\n",
      "From cloudy caves, heavy with summer dews,\n",
      "The shyest and most tremulous beings stir,\n",
      "The pulsing of their fins a lucent blur,\n",
      "That, like illusion, glances off the view.\n",
      "The pulsing mouths, like metronomes, are true,\n",
      "This is my father’s house, no homestead here\n",
      "That I shall live in, but a shining sphere\n",
      "Of glass and glassy moments, frail surprise,\n",
      "My father’s phantasy of Paradise;\n",
      "Which melts upon his death, which he attained\n",
      "With loss of heart for every step he gained.\n",
      "Too firmly gentle to displace the great,\n",
      "He crystallized this vision somewhat late;\n",
      "Forbidden now to climb the garden stair,\n",
      "He views the terrace from a window chair.\n",
      "His friends, hard shaken by some twenty years,\n",
      "Tremble with palsy and with senile fears,\n",
      "In their late middle age gone cold and gray.\n",
      "Fine men, now broken. That the vision stay,\n",
      "They spend astutely their depleted breath,\n",
      "With tired ironic faces wait for death.\n",
      "Below the garden the hills fold away.\n",
      "Deep in the valley, a mist fine as spray,\n",
      "Ready to shatter into spinning light,\n",
      "Conceals the city at the edge of night.\n",
      "The city, on the tremendous valley floor,\n",
      "Draws its dream deeper for an instant more,\n",
      "Superb on solid loam, and breathing deep,\n",
      "Poised for a moment at the edge of sleep.\n",
      "Cement roads mark the hills, wide, bending free\n",
      "Of cliff and headland. Dropping toward the sea,\n",
      "Through suburb after suburb, vast ravines\n",
      "Swell to the summer drone of fine machines.\n",
      "The driver, melting down the distance here,\n",
      "May cast in flight the faint hoof of a deer\n",
      "Or pass the faint head set perplexedly.\n",
      "And man-made stone outgrows the living tree,\n",
      "And at its rising, air is shaken, men\n",
      "Are shattered, and the tremor swells again,\n",
      "Extending to the naked salty shore,\n",
      "Rank with the sea, which crumbles evermore.\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "📝 SFT 模型生成诗歌：\n",
      "--------------------------------------------------\n",
      "I too sing America! I am large—I contain multitudes.\n",
      "From every sound of life, from my own voice sounding,\n",
      "And that of others, even to the last far-off muted strain,\n",
      "Whate’er it is must be significant—every one of its phrases a word in mine;\n",
      "Each echo an affirmation—each sound and shade has its correspondent in me.\n",
      "All sounds are significant—the cricket’s, the grasshopper’s, or any insect’s high-pitched note;\n",
      "The bird’s song on the hill-tops morning and evening, as he perches on the hemlock or oak, or flutters about the field-bird’s home;\n",
      "Or if in summer’s still hour on the lawn I hear the bee humming through the air,\n",
      "So faintly, yet so confident, no matter which way turned,\n",
      "Sure as fate’s hand whispers me to turn the page of my book,\n",
      "He says his say, with his tiny wings half-opened, flying lightly on—tells all his news,\n",
      "Then settles by my side, and hums his song of love,\n",
      "Sings louder and clearer, for here he means to stay;\n",
      "It seems to me to have a deep meaning this little being’s talk;\n",
      "Somehow it penetrates my spirit, and takes root there.\n",
      "Nature’s most secret thought seems whispering in each tone;\n",
      "She never stops to consider, nor thinks to teach or show,\n",
      "But goes her ways, and lets us find out what we can;\n",
      "Let them come from China or Europe, the newest arrivals, or those who have been many days in prison,\n",
      "They will hear the same tune, the same cry of joy, and wonder, and passion.\n",
      "The farmer, the mechanic, the laborer, all join their voices with mine,\n",
      "To praise and honor the land of our birth—its rivers, mountains, lakes and plains;\n",
      "Where ever the sunset shines upon our land, it is blessed and praised.\n",
      "There is a sweet old-time melody, heard once only\n",
      "--------------------------------------------------\n",
      "\n",
      "🎯 与训练集最相似诗歌的相似度：0.7498\n",
      "\n",
      "🆚 训练集中最相似的诗歌：\n",
      "--------------------------------------------------\n",
      "I hear America singing, the varied carols I hear,\n",
      "Those of mechanics, each one singing his as it should be blithe and strong,\n",
      "The carpenter singing his as he measures his plank or beam,\n",
      "The mason singing his as he makes ready for work, or leaves off work,\n",
      "The boatman singing what belongs to him in his boat, the deckhand singing on the steamboat deck,\n",
      "The shoemaker singing as he sits on his bench, the hatter singing as he stands,\n",
      "The wood-cutter’s song, the ploughboy’s on his way in the morning, or at noon intermission or at sundown,\n",
      "The delicious singing of the mother, or of the young wife at work, or of the girl sewing or washing,\n",
      "Each singing what belongs to him or her and to none else,\n",
      "The day what belongs to the day—at night the party of young fellows, robust, friendly,\n",
      "Singing with open mouths their strong melodious songs.\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "📝 MINDFLOW 模型生成诗歌：\n",
      "--------------------------------------------------\n",
      "In fields where nature's breath doth sigh,\n",
      "And sunbeams kiss the waving hay,\n",
      "Where murmurs of sweet moisture fly,\n",
      "A song of life and toil they lay.\n",
      "Upon the farms the morning breaks,\n",
      "The roosters crow, and cows low soft.\n",
      "Young swains, with boots all laced and stakes,\n",
      "Begin their work at early not.\n",
      "Chirping thrushes fill the green lanes—\n",
      "Sparrows sing in sprigged apple boughs.\n",
      "All creatures wake as Nature paints,\n",
      "Her canvas bright with dawn’s blush now.\n",
      "The plowman, strong as oak trees' root,\n",
      "Draws furrows deep in soil dark brown.\n",
      "His spade, like arm of Atlas, fraught\n",
      "With power to lift the earth around.\n",
      "Here wheat is born from loam so rich,\n",
      "And cornfields stretch like golden seas.\n",
      "Nature’s bounty here does teach us much:\n",
      "Toiled for by hands that will not cease.\n",
      "From morn till night, with steadfast mind,\n",
      "These farmers bend their willing will.\n",
      "Each task they know must be combined,\n",
      "To thrive and grow beneath the hill.\n",
      "Thus through the day they labor hard,\n",
      "Till stars come out, and darkness draws.\n",
      "Then grateful hearts to rest are charted,\n",
      "For toilsome days have wrought new straw.\n",
      "So let it be when sunset comes,\n",
      "When fields lie still under the star.\n",
      "We thank these workers for our homes,\n",
      "And cherish all we get in bar.\n",
      "This poem uses elements inspired by Walt Whitman's style, including free verse, an emphasis on natural imagery and rural life, and a focus on the rhythms of daily existence on a farm. The repetition and use of dashes also echo some of Whitman's characteristic techniques.\n",
      "--------------------------------------------------\n",
      "\n",
      "🎯 与训练集最相似诗歌的相似度：0.771\n",
      "\n",
      "🆚 训练集中最相似的诗歌：\n",
      "--------------------------------------------------\n",
      "I came here, being stricken, stumbling out\n",
      "At last from streets; the sun, decreasing, took me\n",
      "For days, the time being the last of autumn,\n",
      "The thickets not yet stark, but quivering\n",
      "With tiny colors, like some brush strokes in\n",
      "The manner of the pointillists; small yellows\n",
      "Dart shaped, little reds in different pattern,\n",
      "Clicks and notches of color on threaded bushes,\n",
      "A cracked and fluent heaven, and a brown earth.\n",
      "I had these, and my food and sleep—enough.\n",
      " \n",
      "This is a countryside of roofless houses,—\n",
      "Taverns to rain,—doorsteps of millstones, lintels\n",
      "Leaning and delicate, foundations sprung to lilacs.\n",
      "Orchards where boughs like roots strike into the sky.\n",
      "Here I could well devise the journey to nothing,\n",
      "At night getting down from the wagon by the black barns,\n",
      "The zenith a point of darkness, breaking to bits,\n",
      "Showering motionless stars over the houses.\n",
      "Scenes relentless—the black and white grooves of a woodcut.\n",
      " \n",
      "But why the journey to nothing or any desire?\n",
      "Why the heart taken by even senseless adventure,\n",
      "The goal a coffer of dust?    Give my mouth to the air,\n",
      "Let arrogant pain lick my flesh with a tongue\n",
      "Rough as a cat’s; remember the smell of cold mornings,\n",
      "The dried beauty of women, the exquisite skin\n",
      "Under the chins of young girls, young men’s rough beards,—\n",
      "The cringing promise of this one, that one’s apology\n",
      "For the knife struck down to the bone, gladioli in sick rooms,\n",
      "Asters and dahlias, flowers like ruches, rosettes. . .\n",
      " \n",
      "Forever enough to part grass over the stones\n",
      "By some brook or well, the lovely seed-shedding stalks;\n",
      "To hear in the single wind diverse branches\n",
      "Repeating their sounds to the sky—that sky like scaled mackerel,\n",
      "Fleeing the fields—to be defended from silence,\n",
      "To feel my body as arid, as safe as a twig\n",
      "Broken away from whatever growth could snare it\n",
      "Up to a spring, or hold it softly in summer\n",
      "Or beat it under in snow.\n",
      " \n",
      "                                                       I must get well.\n",
      "Walk on strong legs, leap the hurdles of sense,  \n",
      "Reason again, come back to my old patchwork logic,\n",
      "Addition, subtraction, money, clothes, clocks,\n",
      "Memories (freesias, smelling slightly of snow and of flesh\n",
      "In a room with blue curtains) ambition, despair.\n",
      "I must feel again who had given feeling over,\n",
      "Challenge laughter, take tears, play the piano,\n",
      "Form judgments, blame a crude world for disaster.\n",
      " \n",
      "To escape is nothing.    Not to escape is nothing.\n",
      "The farmer’s wife stands with a halo of darkness\n",
      "Rounding her head.    Water drips in the kitchen\n",
      "Tapping the sink.    To-day the maples have split\n",
      "Limb from the trunk with the ice, a fresh wooden wound.\n",
      "The vines are distorted with ice, ice burdens the breaking\n",
      "Roofs I have told you of.\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "✅ 相似度对比报告已保存至：/root/autodl-tmp/Pro/poetry_results/similarity_对比报告_all_models_poem_20251213_180850.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# 配置项（根据你的路径修改）\n",
    "# -------------------------\n",
    "# 已保存的三首诗歌文件路径\n",
    "SAVED_POEMS_PATH = \"/root/autodl-tmp/Pro/poetry_results/all_models_poem_20251213_180850.txt\"\n",
    "# 训练集jsonl文件路径\n",
    "TRAIN_DATA_PATH = \"/root/autodl-tmp/Pro/poetry_sft.jsonl\"\n",
    "# 相似度模型路径\n",
    "SIMILARITY_MODEL_PATH = \"/root/autodl-tmp/大模型/all-mpnet-base-v2\"\n",
    "# 设备配置\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------------\n",
    "# 步骤1：加载相似度模型\n",
    "# -------------------------\n",
    "print(\"🔧 Loading similarity model (all-mpnet-base-v2)...\")\n",
    "similarity_model = SentenceTransformer(SIMILARITY_MODEL_PATH).to(DEVICE)\n",
    "similarity_model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 步骤2：读取并解析训练集jsonl（提取assistant的诗歌）\n",
    "# -------------------------\n",
    "print(f\"\\n📥 Loading training data from {TRAIN_DATA_PATH}...\")\n",
    "train_poems = []\n",
    "\n",
    "if not os.path.exists(TRAIN_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"训练集文件不存在：{TRAIN_DATA_PATH}\")\n",
    "\n",
    "with open(TRAIN_DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "    for line in lines:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            poem_text = \"\"\n",
    "            # 提取messages中assistant的content（核心）\n",
    "            if \"messages\" in data and isinstance(data[\"messages\"], list):\n",
    "                for msg in data[\"messages\"]:\n",
    "                    if msg.get(\"role\") == \"assistant\" and \"content\" in msg:\n",
    "                        poem_text = msg[\"content\"].strip()\n",
    "                        break\n",
    "            if poem_text:\n",
    "                train_poems.append(poem_text)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "if not train_poems:\n",
    "    raise ValueError(\"训练集中未提取到有效诗歌！请检查jsonl格式\")\n",
    "print(f\"✅ 从训练集提取到 {len(train_poems)} 首诗歌\")\n",
    "\n",
    "# 预计算训练集诗歌的嵌入向量（加速相似度计算）\n",
    "print(\"\\n⚡ Precomputing embeddings for training poems...\")\n",
    "train_embeddings = similarity_model.encode(\n",
    "    train_poems,\n",
    "    convert_to_tensor=True,\n",
    "    device=DEVICE,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 步骤3：读取已保存的三首生成诗歌\n",
    "# -------------------------\n",
    "print(f\"\\n📤 Loading saved poems from {SAVED_POEMS_PATH}...\")\n",
    "saved_poems = {\n",
    "    \"base\": \"\",\n",
    "    \"sft\": \"\",\n",
    "    \"mindflow\": \"\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(SAVED_POEMS_PATH):\n",
    "    raise FileNotFoundError(f\"保存的诗歌文件不存在：{SAVED_POEMS_PATH}\")\n",
    "\n",
    "# 解析保存的文本文件，提取三个模型的诗歌\n",
    "current_model = None\n",
    "with open(SAVED_POEMS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        # 识别模型分区\n",
    "        if \"BASE MODEL OUTPUT:\" in line:\n",
    "            current_model = \"base\"\n",
    "            continue\n",
    "        elif \"SFT MODEL OUTPUT:\" in line:\n",
    "            current_model = \"sft\"\n",
    "            continue\n",
    "        elif \"MINDFLOW MODEL OUTPUT:\" in line:\n",
    "            current_model = \"mindflow\"\n",
    "            continue\n",
    "        # 跳过分隔符、相似度信息等非诗歌内容\n",
    "        if line.startswith((\"=\", \"-\", \"📌\", \"Similarity Score\", \"Most Similar Poem\", \"Poem:\")):\n",
    "            continue\n",
    "        # 收集诗歌内容（保留换行）\n",
    "        if current_model and line:\n",
    "            saved_poems[current_model] += line + \"\\n\"\n",
    "\n",
    "# 清理诗歌内容（去除首尾多余换行）\n",
    "for model_type in saved_poems:\n",
    "    saved_poems[model_type] = saved_poems[model_type].strip()\n",
    "    if not saved_poems[model_type]:\n",
    "        print(f\"⚠️  {model_type.upper()} 模型无有效诗歌内容\")\n",
    "\n",
    "# -------------------------\n",
    "# 步骤4：计算每首生成诗歌与训练集的相似度\n",
    "# -------------------------\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"📊 相似度对比结果（生成诗歌 ↔ 训练集最相似诗歌）\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 保存最终报告\n",
    "similarity_report = []\n",
    "similarity_report.append(\"=== 诗歌相似度对比报告 ===\\n\")\n",
    "similarity_report.append(f\"对比时间：{os.popen('date').read().strip()}\\n\")\n",
    "similarity_report.append(f\"生成诗歌文件：{SAVED_POEMS_PATH}\\n\")\n",
    "similarity_report.append(f\"训练集文件：{TRAIN_DATA_PATH}\\n\")\n",
    "similarity_report.append(\"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "for model_type, generated_poem in saved_poems.items():\n",
    "    if not generated_poem:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n📝 {model_type.upper()} 模型生成诗歌：\")\n",
    "    print(\"-\"*50)\n",
    "    print(generated_poem)\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # 计算生成诗歌的嵌入向量\n",
    "    gen_embedding = similarity_model.encode(\n",
    "        generated_poem,\n",
    "        convert_to_tensor=True,\n",
    "        device=DEVICE,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    # 计算与训练集所有诗歌的余弦相似度\n",
    "    cos_scores = util.cos_sim(gen_embedding, train_embeddings)[0]\n",
    "    max_score_idx = torch.argmax(cos_scores).item()\n",
    "    max_score = round(cos_scores[max_score_idx].item(), 4)\n",
    "    most_similar_poem = train_poems[max_score_idx]\n",
    "    \n",
    "    # 输出相似度结果\n",
    "    print(f\"\\n🎯 与训练集最相似诗歌的相似度：{max_score}\")\n",
    "    print(f\"\\n🆚 训练集中最相似的诗歌：\")\n",
    "    print(\"-\"*50)\n",
    "    print(most_similar_poem)\n",
    "    print(\"-\"*50)\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    \n",
    "    # 写入报告\n",
    "    similarity_report.append(f\"📌 {model_type.upper()} 模型\\n\")\n",
    "    similarity_report.append(\"-\"*40 + \"\\n\")\n",
    "    similarity_report.append(f\"生成诗歌：\\n{generated_poem}\\n\\n\")\n",
    "    similarity_report.append(f\"相似度分数：{max_score}\\n\")\n",
    "    similarity_report.append(f\"最相似训练集诗歌：\\n{most_similar_poem}\\n\")\n",
    "    similarity_report.append(\"\\n\" + \"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# 步骤5：保存相似度报告\n",
    "# -------------------------\n",
    "report_path = os.path.join(os.path.dirname(SAVED_POEMS_PATH), f\"similarity_对比报告_{os.path.basename(SAVED_POEMS_PATH)}\")\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(similarity_report)\n",
    "\n",
    "print(f\"\\n✅ 相似度对比报告已保存至：{report_path}\")\n",
    "\n",
    "# 释放显存\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b54f24-aa01-47ef-8c36-cc87c73de332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 使用设备：cuda\n",
      "\n",
      "📄 正在读取诗歌文件：/root/autodl-tmp/Pro/poetry_results/all_models_poem_20251213_180850.txt\n",
      "✅ 诗歌提取完成！\n",
      "\n",
      "📥 正在加载本地模型：/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 本地Qwen2.5-7B模型加载成功！\n",
      "\n",
      "====================================================================================================\n",
      "🎯 正在评估 BASE 模型生成的诗歌\n",
      "====================================================================================================\n",
      "\n",
      "🔍 正在为诗歌打分...\n",
      "❌ 自动打分失败：Expecting value: line 1 column 1 (char 0)\n",
      "⚠️  模型输出原始内容：<user\n",
      "\n",
      "你是专业诗歌分析师，精通文学理论和计算诗学，需严格按以下要求评估诗歌：\n",
      "\n",
      "任务：根据诗歌强度测量框架（PIMF）的15个维度，为输入诗歌打1-10分，仅返回JSON格式分数（无其他内容）。\n",
      "\n",
      "诗歌文本：\n",
      "In fields where the sun’s warm hands caress,\n",
      "And nature whispers to the whispering breeze,\n",
      "I hear the songs that fill this vast expanse—\n",
      "Chirping crickets and larks ascending.\n",
      "Amidst rows of corn and wheat so green,\n",
      "Where cows graze tranquil as their breaths are seen,\n",
      "A farmer tills with slow, sure pace and might,\n",
      "His heart with every furrow taking flight.\n",
      "Beneath the big blue sky's expansive dome,\n",
      "He works the earth, the very essence of home.\n",
      "The soil rich with the promise of tomorrow,\n",
      "As seasons turn like leaves upon the floor.\n",
      "This land, so wild yet cultivated too,\n",
      "Sings with life in voices low and true.\n",
      "The chirping thrums through the air, light as thought,\n",
      "Nature’s symphony, on and around the plot.\n",
      "So let me wander, hand in hand with time,\n",
      "Among these plots, among these rolling climbs.\n",
      "For here I find my spirit set at ease,\n",
      "By nature’s chords, by labor’s endless seas.\n",
      "\n",
      "评估维度（必须全覆盖，key为维度英文key）：\n",
      "- creative_imagination：Measures metaphor novelty (e.g., Éluard’s surreal imagery).\n",
      "- unpredictability：Captures non-formulaic poetic shifts (e.g., Eliot’s fragmentation).\n",
      "- autonomy：Evaluates internal coherence (e.g., Dickinson’s self-contained worlds).\n",
      "- poetic_alchemy：Transforms ordinary language into deeper meaning (e.g., Dickinson’s 'Hope is the thing with feathers').\n",
      "- day_night_imagery：Assesses rational vs. dreamlike poetic elements (e.g., Rimbaud’s Illuminations).\n",
      "- participative_evocative：Measures reader engagement and invitation for interpretation (e.g., Rilke’s Archaic Torso of Apollo).\n",
      "- assemblage_juxtaposition：Examines contrast and layered meanings (e.g., Eliot’s The Waste Land).\n",
      "- creative_will：Reflects the intentionality behind poetic form (e.g., Blake’s Songs of Innocence and Experience).\n",
      "- sonic_quality：Evaluates rhythm and phonetics (e.g., Thomas’s villanelle structure).\n",
      "- cultural_resonance：Analyses intertextual and cultural depth (e.g., Shakespeare’s sonnets).\n",
      "- linguistic_creativity：Captures syntax and lexical innovation (e.g., Hopkins’s sprung rhythm).\n",
      "- emotional_intensity：Measures the poem’s ability to evoke emotions (e.g., Plath’s Daddy).\n",
      "- intellectual_complexity：Assesses abstract depth (e.g., Donne’s metaphysical conceits).\n",
      "- temporal_distortion：Evaluates manipulation of time (e.g., Eliot’s Four Quartets).\n",
      "- narrative_integrity：Examines coherence in poetic progression (e.g., Frost’s The Road Not Taken).\n",
      "\n",
      "评分规则（严格遵循）：\n",
      "1-2分：Minimal intensity（缺乏创造性、连贯性，公式化）\n",
      "3-4分：Weak intensity（少量创新，整体常规）\n",
      "5-6分：Moderate intensity（有原创瞬间，缺乏深度）\n",
      "7-8分：High intensity（表现优秀，仅轻微不足）\n",
      "9-10分：Exceptional intensity（原创且具变革性）\n",
      "\n",
      "输出要求（仅JSON，分数保留1位小数，无多余字符）：\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    ...\n",
      "}\n",
      "<\n",
      "<assistant\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    \"autonomy\": 7.0,\n",
      "    \"poetic_alchemy\": 7.0,\n",
      "    \"day_night_imagery\": 5.0,\n",
      "    \"participative_evocative\": 8.0,\n",
      "    \"assemblage_juxtaposition\": 5.0,\n",
      "    \"creative_will\": 7.0,\n",
      "    \"sonic_quality\": 6.0,\n",
      "    \"cultural_resonance\": 5.0,\n",
      "    \"linguistic_creativity\": 7.0,\n",
      "    \"emotional_intensity\": 7.0,\n",
      "    \"intellectual_complexity\": 6.0,\n",
      "    \"temporal_distortion\": 5.0,\n",
      "    \"narrative_integrity\": 7.0\n",
      "}\n",
      "<\n",
      "\n",
      "====================================================================================================\n",
      "🎯 正在评估 SFT 模型生成的诗歌\n",
      "====================================================================================================\n",
      "\n",
      "🔍 正在为诗歌打分...\n",
      "❌ 自动打分失败：Expecting value: line 1 column 1 (char 0)\n",
      "⚠️  模型输出原始内容：<user\n",
      "\n",
      "你是专业诗歌分析师，精通文学理论和计算诗学，需严格按以下要求评估诗歌：\n",
      "\n",
      "任务：根据诗歌强度测量框架（PIMF）的15个维度，为输入诗歌打1-10分，仅返回JSON格式分数（无其他内容）。\n",
      "\n",
      "诗歌文本：\n",
      "I too sing America! I am large—I contain multitudes.\n",
      "From every sound of life, from my own voice sounding,\n",
      "And that of others, even to the last far-off muted strain,\n",
      "Whate’er it is must be significant—every one of its phrases a word in mine;\n",
      "Each echo an affirmation—each sound and shade has its correspondent in me.\n",
      "All sounds are significant—the cricket’s, the grasshopper’s, or any insect’s high-pitched note;\n",
      "The bird’s song on the hill-tops morning and evening, as he perches on the hemlock or oak, or flutters about the field-bird’s home;\n",
      "Or if in summer’s still hour on the lawn I hear the bee humming through the air,\n",
      "So faintly, yet so confident, no matter which way turned,\n",
      "Sure as fate’s hand whispers me to turn the page of my book,\n",
      "He says his say, with his tiny wings half-opened, flying lightly on—tells all his news,\n",
      "Then settles by my side, and hums his song of love,\n",
      "Sings louder and clearer, for here he means to stay;\n",
      "It seems to me to have a deep meaning this little being’s talk;\n",
      "Somehow it penetrates my spirit, and takes root there.\n",
      "Nature’s most secret thought seems whispering in each tone;\n",
      "She never stops to consider, nor thinks to teach or show,\n",
      "But goes her ways, and lets us find out what we can;\n",
      "Let them come from China or Europe, the newest arrivals, or those who have been many days in prison,\n",
      "They will hear the same tune, the same cry of joy, and wonder, and passion.\n",
      "The farmer, the mechanic, the laborer, all join their voices with mine,\n",
      "To praise and honor the land of our birth—its rivers, mountains, lakes and plains;\n",
      "Where ever the sunset shines upon our land, it is blessed and praised.\n",
      "There is a sweet old-time melody, heard once only\n",
      "\n",
      "评估维度（必须全覆盖，key为维度英文key）：\n",
      "- creative_imagination：Measures metaphor novelty (e.g., Éluard’s surreal imagery).\n",
      "- unpredictability：Captures non-formulaic poetic shifts (e.g., Eliot’s fragmentation).\n",
      "- autonomy：Evaluates internal coherence (e.g., Dickinson’s self-contained worlds).\n",
      "- poetic_alchemy：Transforms ordinary language into deeper meaning (e.g., Dickinson’s 'Hope is the thing with feathers').\n",
      "- day_night_imagery：Assesses rational vs. dreamlike poetic elements (e.g., Rimbaud’s Illuminations).\n",
      "- participative_evocative：Measures reader engagement and invitation for interpretation (e.g., Rilke’s Archaic Torso of Apollo).\n",
      "- assemblage_juxtaposition：Examines contrast and layered meanings (e.g., Eliot’s The Waste Land).\n",
      "- creative_will：Reflects the intentionality behind poetic form (e.g., Blake’s Songs of Innocence and Experience).\n",
      "- sonic_quality：Evaluates rhythm and phonetics (e.g., Thomas’s villanelle structure).\n",
      "- cultural_resonance：Analyses intertextual and cultural depth (e.g., Shakespeare’s sonnets).\n",
      "- linguistic_creativity：Captures syntax and lexical innovation (e.g., Hopkins’s sprung rhythm).\n",
      "- emotional_intensity：Measures the poem’s ability to evoke emotions (e.g., Plath’s Daddy).\n",
      "- intellectual_complexity：Assesses abstract depth (e.g., Donne’s metaphysical conceits).\n",
      "- temporal_distortion：Evaluates manipulation of time (e.g., Eliot’s Four Quartets).\n",
      "- narrative_integrity：Examines coherence in poetic progression (e.g., Frost’s The Road Not Taken).\n",
      "\n",
      "评分规则（严格遵循）：\n",
      "1-2分：Minimal intensity（缺乏创造性、连贯性，公式化）\n",
      "3-4分：Weak intensity（少量创新，整体常规）\n",
      "5-6分：Moderate intensity（有原创瞬间，缺乏深度）\n",
      "7-8分：High intensity（表现优秀，仅轻微不足）\n",
      "9-10分：Exceptional intensity（原创且具变革性）\n",
      "\n",
      "输出要求（仅JSON，分数保留1位小数，无多余字符）：\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    ...\n",
      "}\n",
      "<\n",
      "<assistant\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    \"autonomy\": 7.0,\n",
      "    \"poetic_alchemy\": 7.0,\n",
      "    \"day_night_imagery\": 3.0,\n",
      "    \"participative_evocative\": 8.0,\n",
      "    \"assemblage_juxtaposition\": 4.0,\n",
      "    \"creative_will\": 7.0,\n",
      "    \"sonic_quality\": 6.0,\n",
      "    \"cultural_resonance\": 5.0,\n",
      "    \"linguistic_creativity\": 7.0,\n",
      "    \"emotional_intensity\": 6.0,\n",
      "    \"intellectual_complexity\": 6.0,\n",
      "    \"temporal_distortion\": 3.0,\n",
      "    \"narrative_integrity\": 7.0\n",
      "}\n",
      "<\n",
      "\n",
      "====================================================================================================\n",
      "🎯 正在评估 MINDFLOW 模型生成的诗歌\n",
      "====================================================================================================\n",
      "\n",
      "🔍 正在为诗歌打分...\n",
      "❌ 自动打分失败：Expecting value: line 1 column 1 (char 0)\n",
      "⚠️  模型输出原始内容：<user\n",
      "\n",
      "你是专业诗歌分析师，精通文学理论和计算诗学，需严格按以下要求评估诗歌：\n",
      "\n",
      "任务：根据诗歌强度测量框架（PIMF）的15个维度，为输入诗歌打1-10分，仅返回JSON格式分数（无其他内容）。\n",
      "\n",
      "诗歌文本：\n",
      "In fields where nature's breath doth sigh,\n",
      "And sunbeams kiss the waving hay,\n",
      "Where murmurs of sweet moisture fly,\n",
      "A song of life and toil they lay.\n",
      "Upon the farms the morning breaks,\n",
      "The roosters crow, and cows low soft.\n",
      "Young swains, with boots all laced and stakes,\n",
      "Begin their work at early not.\n",
      "Chirping thrushes fill the green lanes—\n",
      "Sparrows sing in sprigged apple boughs.\n",
      "All creatures wake as Nature paints,\n",
      "Her canvas bright with dawn’s blush now.\n",
      "The plowman, strong as oak trees' root,\n",
      "Draws furrows deep in soil dark brown.\n",
      "His spade, like arm of Atlas, fraught\n",
      "With power to lift the earth around.\n",
      "Here wheat is born from loam so rich,\n",
      "And cornfields stretch like golden seas.\n",
      "Nature’s bounty here does teach us much:\n",
      "Toiled for by hands that will not cease.\n",
      "From morn till night, with steadfast mind,\n",
      "These farmers bend their willing will.\n",
      "Each task they know must be combined,\n",
      "To thrive and grow beneath the hill.\n",
      "Thus through the day they labor hard,\n",
      "Till stars come out, and darkness draws.\n",
      "Then grateful hearts to rest are charted,\n",
      "For toilsome days have wrought new straw.\n",
      "So let it be when sunset comes,\n",
      "When fields lie still under the star.\n",
      "We thank these workers for our homes,\n",
      "And cherish all we get in bar.\n",
      "This poem uses elements inspired by Walt Whitman's style, including free verse, an emphasis on natural imagery and rural life, and a focus on the rhythms of daily existence on a farm. The repetition and use of dashes also echo some of Whitman's characteristic techniques.\n",
      "\n",
      "评估维度（必须全覆盖，key为维度英文key）：\n",
      "- creative_imagination：Measures metaphor novelty (e.g., Éluard’s surreal imagery).\n",
      "- unpredictability：Captures non-formulaic poetic shifts (e.g., Eliot’s fragmentation).\n",
      "- autonomy：Evaluates internal coherence (e.g., Dickinson’s self-contained worlds).\n",
      "- poetic_alchemy：Transforms ordinary language into deeper meaning (e.g., Dickinson’s 'Hope is the thing with feathers').\n",
      "- day_night_imagery：Assesses rational vs. dreamlike poetic elements (e.g., Rimbaud’s Illuminations).\n",
      "- participative_evocative：Measures reader engagement and invitation for interpretation (e.g., Rilke’s Archaic Torso of Apollo).\n",
      "- assemblage_juxtaposition：Examines contrast and layered meanings (e.g., Eliot’s The Waste Land).\n",
      "- creative_will：Reflects the intentionality behind poetic form (e.g., Blake’s Songs of Innocence and Experience).\n",
      "- sonic_quality：Evaluates rhythm and phonetics (e.g., Thomas’s villanelle structure).\n",
      "- cultural_resonance：Analyses intertextual and cultural depth (e.g., Shakespeare’s sonnets).\n",
      "- linguistic_creativity：Captures syntax and lexical innovation (e.g., Hopkins’s sprung rhythm).\n",
      "- emotional_intensity：Measures the poem’s ability to evoke emotions (e.g., Plath’s Daddy).\n",
      "- intellectual_complexity：Assesses abstract depth (e.g., Donne’s metaphysical conceits).\n",
      "- temporal_distortion：Evaluates manipulation of time (e.g., Eliot’s Four Quartets).\n",
      "- narrative_integrity：Examines coherence in poetic progression (e.g., Frost’s The Road Not Taken).\n",
      "\n",
      "评分规则（严格遵循）：\n",
      "1-2分：Minimal intensity（缺乏创造性、连贯性，公式化）\n",
      "3-4分：Weak intensity（少量创新，整体常规）\n",
      "5-6分：Moderate intensity（有原创瞬间，缺乏深度）\n",
      "7-8分：High intensity（表现优秀，仅轻微不足）\n",
      "9-10分：Exceptional intensity（原创且具变革性）\n",
      "\n",
      "输出要求（仅JSON，分数保留1位小数，无多余字符）：\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    ...\n",
      "}\n",
      "<\n",
      "<assistant\n",
      "{\n",
      "    \"creative_imagination\": 6.0,\n",
      "    \"unpredictability\": 4.0,\n",
      "    \"autonomy\": 7.0,\n",
      "    \"poetic_alchemy\": 6.0,\n",
      "    \"day_night_imagery\": 5.0,\n",
      "    \"participative_evocative\": 7.0,\n",
      "    \"assemblage_juxtaposition\": 5.0,\n",
      "    \"creative_will\": 7.0,\n",
      "    \"sonic_quality\": 6.0,\n",
      "    \"cultural_resonance\": 7.0,\n",
      "    \"linguistic_creativity\": 6.0,\n",
      "    \"emotional_intensity\": 7.0,\n",
      "    \"intellectual_complexity\": 5.0,\n",
      "    \"temporal_distortion\": 4.0,\n",
      "    \"narrative_integrity\": 7.0\n",
      "}\n",
      "<\n",
      "\n",
      "====================================================================================================\n",
      "✅ 所有诗歌评估完成！\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Optional, Union\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# 1. 核心配置（适配本地Qwen2.5-7B + 目标诗歌文件）\n",
    "# -------------------------\n",
    "# 本地Qwen2.5-7B路径\n",
    "LOCAL_LLM_PATH = \"/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\"\n",
    "# 目标诗歌文件路径（含三首诗）\n",
    "POEMS_FILE_PATH = \"/root/autodl-tmp/Pro/poetry_results/all_models_poem_20251213_180850.txt\"\n",
    "# 设备配置\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🔧 使用设备：{DEVICE}\")\n",
    "\n",
    "# 论文PIMF 15维度定义（与Table 1完全一致，修正缩进/语法错误）\n",
    "PIMF_DIMENSIONS = [\n",
    "    {\"key\": \"creative_imagination\", \"name\": \"Creative Imagination\", \"symbol\": \"μ₁\", \"description\": \"Measures metaphor novelty (e.g., Éluard’s surreal imagery).\"},\n",
    "    {\"key\": \"unpredictability\", \"name\": \"Unpredictability\", \"symbol\": \"μ₂\", \"description\": \"Captures non-formulaic poetic shifts (e.g., Eliot’s fragmentation).\"},\n",
    "    {\"key\": \"autonomy\", \"name\": \"Autonomy\", \"symbol\": \"μ₃\", \"description\": \"Evaluates internal coherence (e.g., Dickinson’s self-contained worlds).\"},\n",
    "    {\"key\": \"poetic_alchemy\", \"name\": \"Poetic Alchemy\", \"symbol\": \"μ₄\", \"description\": \"Transforms ordinary language into deeper meaning (e.g., Dickinson’s 'Hope is the thing with feathers').\"},\n",
    "    {\"key\": \"day_night_imagery\", \"name\": \"Day/Night Imagery\", \"symbol\": \"μ₅\", \"description\": \"Assesses rational vs. dreamlike poetic elements (e.g., Rimbaud’s Illuminations).\"},\n",
    "    {\"key\": \"participative_evocative\", \"name\": \"Participative/Evocative Nature\", \"symbol\": \"μ₆\", \"description\": \"Measures reader engagement and invitation for interpretation (e.g., Rilke’s Archaic Torso of Apollo).\"},\n",
    "    {\"key\": \"assemblage_juxtaposition\", \"name\": \"Assemblage/Juxtaposition\", \"symbol\": \"μ₇\", \"description\": \"Examines contrast and layered meanings (e.g., Eliot’s The Waste Land).\"},\n",
    "    {\"key\": \"creative_will\", \"name\": \"Creative Will\", \"symbol\": \"μ₈\", \"description\": \"Reflects the intentionality behind poetic form (e.g., Blake’s Songs of Innocence and Experience).\"},\n",
    "    {\"key\": \"sonic_quality\", \"name\": \"Sonic Quality\", \"symbol\": \"μ₉\", \"description\": \"Evaluates rhythm and phonetics (e.g., Thomas’s villanelle structure).\"},\n",
    "    {\"key\": \"cultural_resonance\", \"name\": \"Cultural Resonance\", \"symbol\": \"μ₁₀\", \"description\": \"Analyses intertextual and cultural depth (e.g., Shakespeare’s sonnets).\"},\n",
    "    {\"key\": \"linguistic_creativity\", \"name\": \"Linguistic Creativity\", \"symbol\": \"μ₁₁\", \"description\": \"Captures syntax and lexical innovation (e.g., Hopkins’s sprung rhythm).\"},\n",
    "    {\"key\": \"emotional_intensity\", \"name\": \"Emotional Intensity\", \"symbol\": \"μ₁₂\", \"description\": \"Measures the poem’s ability to evoke emotions (e.g., Plath’s Daddy).\"},\n",
    "    {\"key\": \"intellectual_complexity\", \"name\": \"Intellectual Complexity\", \"symbol\": \"μ₁₃\", \"description\": \"Assesses abstract depth (e.g., Donne’s metaphysical conceits).\"},\n",
    "    {\"key\": \"temporal_distortion\", \"name\": \"Temporal Distortion\", \"symbol\": \"μ₁₄\", \"description\": \"Evaluates manipulation of time (e.g., Eliot’s Four Quartets).\"},\n",
    "    {\"key\": \"narrative_integrity\", \"name\": \"Narrative Integrity\", \"symbol\": \"μ₁₅\", \"description\": \"Examines coherence in poetic progression (e.g., Frost’s The Road Not Taken).\"}\n",
    "]\n",
    "\n",
    "# 论文评分规则（1-10分制）\n",
    "SCORE_RUBRIC = {\n",
    "    1: \"Minimal intensity: Lacks creativity, originality, or coherence. Formulaic and predictable.\",\n",
    "    2: \"Minimal intensity: Lacks creativity, originality, or coherence. Formulaic and predictable.\",\n",
    "    3: \"Weak intensity: Some creative elements but largely conventional or derivative.\",\n",
    "    4: \"Weak intensity: Some creative elements but largely conventional or derivative.\",\n",
    "    5: \"Moderate intensity: Shows moments of originality but lacks depth or transformation.\",\n",
    "    6: \"Moderate intensity: Shows moments of originality but lacks depth or transformation.\",\n",
    "    7: \"High intensity: Strong use of language, depth, and form, but some minor weaknesses.\",\n",
    "    8: \"High intensity: Strong use of language, depth, and form, but some minor weaknesses.\",\n",
    "    9: \"Exceptional intensity: Fully developed, original, and transformative poetic expression.\",\n",
    "    10: \"Exceptional intensity: Fully developed, original, and transformative poetic expression.\"\n",
    "}\n",
    "\n",
    "# 理论最高分（15维度均10分）\n",
    "MAX_TOTAL_SCORE = np.sqrt(15 * (10 ** 2))  # ≈38.73\n",
    "\n",
    "# -------------------------\n",
    "# 新增：从文件提取三首诗（BASE/SFT/MINDFLOW）\n",
    "# -------------------------\n",
    "def extract_three_poems(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"从目标文件中提取BASE、SFT、MINDFLOW三首诗\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"诗歌文件不存在：{file_path}\")\n",
    "    \n",
    "    poems = {\"base\": \"\", \"sft\": \"\", \"mindflow\": \"\"}\n",
    "    current_model = None\n",
    "    \n",
    "    print(f\"\\n📄 正在读取诗歌文件：{file_path}\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # 识别模型分区\n",
    "            if \"BASE MODEL OUTPUT:\" in line:\n",
    "                current_model = \"base\"\n",
    "                continue\n",
    "            elif \"SFT MODEL OUTPUT:\" in line:\n",
    "                current_model = \"sft\"\n",
    "                continue\n",
    "            elif \"MINDFLOW MODEL OUTPUT:\" in line:\n",
    "                current_model = \"mindflow\"\n",
    "                continue\n",
    "            # 跳过分隔符、相似度信息等非诗歌内容\n",
    "            if line.startswith((\"=\", \"-\", \"📌\", \"Similarity Score\", \"Most Similar Poem\", \"Poem:\", \"Generated Time\", \"Training Data\")):\n",
    "                continue\n",
    "            # 收集诗歌内容（保留换行）\n",
    "            if current_model and line:\n",
    "                poems[current_model] += line + \"\\n\"\n",
    "    \n",
    "    # 清理诗歌内容（去除首尾多余换行）\n",
    "    for model_type in poems:\n",
    "        poems[model_type] = poems[model_type].strip()\n",
    "        if not poems[model_type]:\n",
    "            print(f\"⚠️ {model_type.upper()} 模型未提取到诗歌内容\")\n",
    "    \n",
    "    print(\"✅ 诗歌提取完成！\")\n",
    "    return poems\n",
    "\n",
    "# -------------------------\n",
    "# 2. 加载本地Qwen2.5-7B\n",
    "# -------------------------\n",
    "def load_local_qwen():\n",
    "    \"\"\"加载本地Qwen2.5-7B模型和tokenizer\"\"\"\n",
    "    print(f\"\\n📥 正在加载本地模型：{LOCAL_LLM_PATH}\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            LOCAL_LLM_PATH,\n",
    "            trust_remote_code=True,\n",
    "            padding_side=\"right\"\n",
    "        )\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            LOCAL_LLM_PATH,\n",
    "            torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        ).eval()\n",
    "        \n",
    "        print(\"✅ 本地Qwen2.5-7B模型加载成功！\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型加载失败：{str(e)}\")\n",
    "        exit(1)\n",
    "\n",
    "# -------------------------\n",
    "# 3. PIMF评分核心类\n",
    "# -------------------------\n",
    "class PIMFScorer:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.dimensions = PIMF_DIMENSIONS\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.scores: Dict[str, float] = {}\n",
    "\n",
    "    def _validate_scores(self) -> bool:\n",
    "        \"\"\"验证分数完整性和有效性\"\"\"\n",
    "        if len(self.scores) != len(self.dimensions):\n",
    "            missing = [dim[\"key\"] for dim in self.dimensions if dim[\"key\"] not in self.scores]\n",
    "            print(f\"❌ 缺少维度分数：{missing}\")\n",
    "            return False\n",
    "        for k, v in self.scores.items():\n",
    "            if not (1 <= v <= 10):\n",
    "                print(f\"❌ 维度{k}分数{v}无效（需1-10分）\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def local_llm_auto_scoring(self, poem_text: str) -> bool:\n",
    "        \"\"\"使用本地Qwen2.5-7B自动打分\"\"\"\n",
    "        print(f\"\\n🔍 正在为诗歌打分...\")\n",
    "        \n",
    "        # 构建结构化Prompt（适配Qwen格式）\n",
    "        prompt = f\"\"\"\n",
    "你是专业诗歌分析师，精通文学理论和计算诗学，需严格按以下要求评估诗歌：\n",
    "\n",
    "任务：根据诗歌强度测量框架（PIMF）的15个维度，为输入诗歌打1-10分，仅返回JSON格式分数（无其他内容）。\n",
    "\n",
    "诗歌文本：\n",
    "{poem_text}\n",
    "\n",
    "评估维度（必须全覆盖，key为维度英文key）：\n",
    "{chr(10).join([f\"- {dim['key']}：{dim['description']}\" for dim in self.dimensions])}\n",
    "\n",
    "评分规则（严格遵循）：\n",
    "1-2分：Minimal intensity（缺乏创造性、连贯性，公式化）\n",
    "3-4分：Weak intensity（少量创新，整体常规）\n",
    "5-6分：Moderate intensity（有原创瞬间，缺乏深度）\n",
    "7-8分：High intensity（表现优秀，仅轻微不足）\n",
    "9-10分：Exceptional intensity（原创且具变革性）\n",
    "\n",
    "输出要求（仅JSON，分数保留1位小数，无多余字符）：\n",
    "{{\n",
    "    \"creative_imagination\": 6.0,\n",
    "    \"unpredictability\": 4.0,\n",
    "    ...\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        # Qwen指令格式封装（修正特殊标记）\n",
    "        formatted_prompt = f\"<<|im_start|>user\\n{prompt}<<|im_end|>\\n<<|im_start|>assistant\\n\"\n",
    "        \n",
    "        try:\n",
    "            # 编码输入\n",
    "            inputs = self.tokenizer(\n",
    "                formatted_prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=2048\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            # 生成输出\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=512,\n",
    "                    temperature=0.1,\n",
    "                    top_k=50,\n",
    "                    top_p=0.9,\n",
    "                    repetition_penalty=1.05,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                    pad_token_id=self.tokenizer.pad_token_id,\n",
    "                    do_sample=True\n",
    "                )\n",
    "            \n",
    "            # 解码并提取JSON\n",
    "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            if \"<<|im_start|>assistant\\n\" in response:\n",
    "                json_str = response.split(\"<<|im_start|>assistant\\n\")[-1].strip()\n",
    "                json_str = json_str.replace(\"<<|im_end|>\", \"\").strip()\n",
    "            else:\n",
    "                json_str = response.strip()\n",
    "            \n",
    "            # 解析JSON分数\n",
    "            self.scores = json.loads(json_str)\n",
    "            print(\"✅ 打分完成！\")\n",
    "            return self._validate_scores()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 自动打分失败：{str(e)}\")\n",
    "            print(f\"⚠️  模型输出原始内容：{response if 'response' in locals() else '无'}\")\n",
    "            return False\n",
    "\n",
    "    def calculate_intensity(self) -> Optional[Dict]:\n",
    "        \"\"\"计算总得分和标准化得分\"\"\"\n",
    "        if not self._validate_scores():\n",
    "            return None\n",
    "        \n",
    "        dim_scores = np.array(list(self.scores.values()))\n",
    "        total_score = np.sqrt(np.sum(np.square(dim_scores)))\n",
    "        normalized_score = (total_score / MAX_TOTAL_SCORE) * 100\n",
    "        \n",
    "        return {\n",
    "            \"dimension_scores\": self.scores,\n",
    "            \"total_score\": round(total_score, 2),\n",
    "            \"normalized_score\": round(normalized_score, 2),\n",
    "            \"max_possible_score\": round(MAX_TOTAL_SCORE, 2)\n",
    "        }\n",
    "\n",
    "    def generate_report(self, poem_title: str = \"Unknown\") -> Optional[str]:\n",
    "        \"\"\"生成评分报告\"\"\"\n",
    "        result = self.calculate_intensity()\n",
    "        if not result:\n",
    "            return None\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"=\"*100)\n",
    "        report.append(f\"📊 PIMF诗歌强度评分报告（本地Qwen2.5-7B）\")\n",
    "        report.append(f\"诗歌标题：{poem_title}\")\n",
    "        report.append(\"=\"*100)\n",
    "        \n",
    "        # 15维度详情\n",
    "        report.append(\"\\n【15维度评分详情】\")\n",
    "        for dim in self.dimensions:\n",
    "            score = result[\"dimension_scores\"][dim[\"key\"]]\n",
    "            score_desc = SCORE_RUBRIC[int(np.ceil(score)) if score % 1 != 0 else int(score)]\n",
    "            report.append(f\"{dim['symbol']} {dim['name']}：{score}分 - {score_desc}\")\n",
    "        \n",
    "        # 总得分\n",
    "        report.append(\"\\n\" + \"-\"*60)\n",
    "        report.append(f\"总强度得分（I）：{result['total_score']}（理论最高分：{result['max_possible_score']}）\")\n",
    "        report.append(f\"标准化得分（I_norm）：{result['normalized_score']}%\")\n",
    "        report.append(\"-\"*60)\n",
    "        report.append(\"📌 参考标准：人类优秀诗歌≥90%，AI诗歌通常60-70%\")\n",
    "        \n",
    "        final_report = \"\\n\".join(report)\n",
    "        print(final_report)\n",
    "        return final_report\n",
    "\n",
    "# -------------------------\n",
    "# 4. 主流程：提取三首诗 + 逐一打分\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 步骤1：提取文件中的三首诗\n",
    "    three_poems = extract_three_poems(POEMS_FILE_PATH)\n",
    "    \n",
    "    # 步骤2：加载本地Qwen2.5-7B\n",
    "    tokenizer, model = load_local_qwen()\n",
    "    \n",
    "    # 步骤3：初始化打分器\n",
    "    scorer = PIMFScorer(tokenizer, model)\n",
    "    \n",
    "    # 步骤4：为每首诗逐一打分并生成报告\n",
    "    for model_type, poem_text in three_poems.items():\n",
    "        if not poem_text:\n",
    "            print(f\"\\n⚠️  跳过{model_type.upper()}模型（无诗歌内容）\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*100)\n",
    "        print(f\"🎯 正在评估 {model_type.upper()} 模型生成的诗歌\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # 自动打分\n",
    "        if scorer.local_llm_auto_scoring(poem_text=poem_text):\n",
    "            # 生成报告\n",
    "            scorer.generate_report(poem_title=f\"{model_type.upper()} Model Generated Poem\")\n",
    "        \n",
    "        # 重置打分器分数（为下一首诗做准备）\n",
    "        scorer.scores = {}\n",
    "    \n",
    "    # 释放显存\n",
    "    if DEVICE == \"cuda\":\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"✅ 所有诗歌评估完成！\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43447059-6481-4064-a5a4-c632e416f6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen_text)",
   "language": "python",
   "name": "qwen_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
