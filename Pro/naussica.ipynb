{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e097df-bdb8-4625-9960-2d05603e4a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from /root/autodl-tmp/Pro/qwen2.5-sft-full\n",
      "Tokenizer loaded.\n",
      "  eos_token: <|endoftext|>\n",
      "  bos_token: <|startoftext|>\n",
      "  pad_token: <|endoftext|>\n",
      "  pad_token_id: 151643\n",
      "  vocab_size: 151665\n",
      "Reading Ulysses txt: /root/autodl-tmp/Pro/Ulysseså°¤åˆ©è¥¿æ–¯.txt\n",
      "Found 7169 paragraphs; will pack paragraphs into chunks <= 1024 tokens.\n",
      "Total token chunks prepared: 459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built: 459 examples\n",
      "Loading base model from: /root/autodl-tmp/Pro/qwen2.5-sft-full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,261,568 || all params: 7,616,878,080 || trainable%: 0.0166\n",
      "Model device: cuda:0\n",
      "Training config -- epochs: 2 batches_per_epoch: 459 total_steps(approx): 229\n",
      "[Epoch 1] Step 20 | loss: 2.4292 | step_time: 00:00:04\n",
      "[Epoch 1] Step 40 | loss: 2.8493 | step_time: 00:00:07\n",
      "[Epoch 1] Step 60 | loss: 3.1239 | step_time: 00:00:11\n",
      "[Epoch 1] Step 80 | loss: 2.8827 | step_time: 00:00:15\n",
      "[Epoch 1] Step 100 | loss: 2.8391 | step_time: 00:00:19\n",
      "[Epoch 1] Step 120 | loss: 2.8489 | step_time: 00:00:22\n",
      "[Epoch 1] Step 140 | loss: 2.8245 | step_time: 00:00:26\n",
      "[Epoch 1] Step 160 | loss: 2.8936 | step_time: 00:00:30\n",
      "[Epoch 1] Step 180 | loss: 2.7989 | step_time: 00:00:34\n",
      "[Epoch 1] Step 200 | loss: 2.7810 | step_time: 00:00:37\n",
      "[Epoch 1] Step 220 | loss: 2.7274 | step_time: 00:00:41\n",
      "[Epoch 1] Step 240 | loss: 2.6937 | step_time: 00:00:45\n",
      "[Epoch 1] Step 260 | loss: 2.6742 | step_time: 00:00:48\n",
      "[Epoch 1] Step 280 | loss: 2.6603 | step_time: 00:00:52\n",
      "[Epoch 1] Step 300 | loss: 2.6799 | step_time: 00:00:56\n",
      "[Epoch 1] Step 320 | loss: 2.6282 | step_time: 00:00:59\n",
      "[Epoch 1] Step 340 | loss: 2.5726 | step_time: 00:01:03\n",
      "[Epoch 1] Step 360 | loss: 2.5276 | step_time: 00:01:07\n",
      "[Epoch 1] Step 380 | loss: 2.4986 | step_time: 00:01:11\n",
      "[Epoch 1] Step 400 | loss: 2.4473 | step_time: 00:01:14\n",
      "[Epoch 1] Step 420 | loss: 2.4162 | step_time: 00:01:18\n",
      "[Epoch 1] Step 440 | loss: 2.3848 | step_time: 00:01:22\n",
      "Epoch 1 finished in 00:01:25\n",
      "[Epoch 2] Step 460 | loss: 0.0085 | step_time: 00:00:00\n",
      "[Epoch 2] Step 480 | loss: 0.0791 | step_time: 00:00:03\n",
      "[Epoch 2] Step 500 | loss: 0.1484 | step_time: 00:00:07\n",
      "[Epoch 2] Step 520 | loss: 0.1840 | step_time: 00:00:11\n",
      "[Epoch 2] Step 540 | loss: 0.2568 | step_time: 00:00:15\n",
      "[Epoch 2] Step 560 | loss: 0.3102 | step_time: 00:00:18\n",
      "[Epoch 2] Step 580 | loss: 0.3674 | step_time: 00:00:22\n",
      "[Epoch 2] Step 600 | loss: 0.4173 | step_time: 00:00:26\n",
      "[Epoch 2] Step 620 | loss: 0.4538 | step_time: 00:00:29\n",
      "[Epoch 2] Step 640 | loss: 0.4886 | step_time: 00:00:33\n",
      "[Epoch 2] Step 660 | loss: 0.5320 | step_time: 00:00:37\n",
      "[Epoch 2] Step 680 | loss: 0.5606 | step_time: 00:00:41\n",
      "[Epoch 2] Step 700 | loss: 0.5922 | step_time: 00:00:44\n",
      "[Epoch 2] Step 720 | loss: 0.6334 | step_time: 00:00:48\n",
      "[Epoch 2] Step 740 | loss: 0.6604 | step_time: 00:00:52\n",
      "[Epoch 2] Step 760 | loss: 0.6994 | step_time: 00:00:56\n",
      "[Epoch 2] Step 780 | loss: 0.7172 | step_time: 00:00:59\n",
      "[Epoch 2] Step 800 | loss: 0.7253 | step_time: 00:01:03\n",
      "[Epoch 2] Step 820 | loss: 0.7569 | step_time: 00:01:07\n",
      "[Epoch 2] Step 840 | loss: 0.7746 | step_time: 00:01:11\n",
      "[Epoch 2] Step 860 | loss: 0.8025 | step_time: 00:01:14\n",
      "[Epoch 2] Step 880 | loss: 0.8290 | step_time: 00:01:18\n",
      "[Epoch 2] Step 900 | loss: 0.8403 | step_time: 00:01:22\n",
      "Epoch 2 finished in 00:01:25\n",
      "Saving finetuned model to: /root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# finetune_mindflow_ulysses.py\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, PreTrainedTokenizerFast\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch.nn as nn\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG - è¯·æŒ‰éœ€ä¿®æ”¹\n",
    "# -------------------------\n",
    "CONFIG = {\n",
    "    \"base_model_path\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",   # æ¨¡å‹ä¸€ï¼šå·²å¾®è°ƒçš„è¯—æ­Œæ¨¡å‹ï¼ˆåŸºåº§ï¼‰\n",
    "    \"ulysses_txt\": \"/root/autodl-tmp/Pro/Ulysseså°¤åˆ©è¥¿æ–¯.txt\",    # å°¤åˆ©è¥¿æ–¯åŸæ–‡ txtï¼ˆæœ¬åœ°ï¼‰\n",
    "    \"output_dir\": \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\",# è¾“å‡ºæ¨¡å‹ï¼ˆäºŒï¼‰\n",
    "    \"max_len\": 1024,      # å•ä¸ªæ ·æœ¬æœ€å¤§ token é•¿åº¦ï¼ˆå¯è°ƒï¼š1024/2048ï¼‰\n",
    "    \"stride\": 512,        # æ»‘åŠ¨çª—å£é‡å \n",
    "    \"batch_size\": 1,      # per device batch sizeï¼ˆé€šå¸¸ 1 æˆ– 2ï¼‰\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_train_epochs\": 2,\n",
    "    \"fp16\": True,\n",
    "    \"lora_r\": 4,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.01,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "    \"print_every_steps\": 20,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "random.seed(CONFIG[\"seed\"])\n",
    "\n",
    "# -------------------------\n",
    "# 1. åŠ è½½ tokenizerï¼ˆQwen2 æ­£ç¡®èŒƒå¼ï¼‰\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer from\", CONFIG[\"base_model_path\"])\n",
    "\n",
    "tokenizer_path = os.path.join(CONFIG[\"base_model_path\"], \"tokenizer.json\")\n",
    "if os.path.exists(tokenizer_path):\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"base_model_path\"], trust_remote_code=True)\n",
    "\n",
    "# ======ã€Qwen2 æ¨èæ ‡å‡†è®¾ç½®ã€‘======\n",
    "# 1) æ˜ç¡®è®¾ç½® eos / bosï¼ˆå¤§å¤šæ•° qwen2 tokenizer.json è‡ªå¸¦ï¼Œä½†ç¡®ä¿ä¸€è‡´ï¼‰\n",
    "tokenizer.eos_token = \"<|endoftext|>\"\n",
    "tokenizer.bos_token = \"<|startoftext|>\"\n",
    "\n",
    "# 2) æ·»åŠ  im_start / im_end\n",
    "# æ³¨æ„ï¼šè¿™ä¸€æ­¥ä¼šé‡å»º vocab â†’ pad_token ä¼šä¸¢å¤±\n",
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\"<|im_start|>\", \"<|im_end|>\"]\n",
    "})\n",
    "\n",
    "# 3) â˜… å…³é”®ï¼šadd_special_tokens åå¿…é¡»é‡æ–°è®¾ç½® pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Tokenizer loaded.\")\n",
    "print(\"  eos_token:\", tokenizer.eos_token)\n",
    "print(\"  bos_token:\", tokenizer.bos_token)\n",
    "print(\"  pad_token:\", tokenizer.pad_token)\n",
    "print(\"  pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"  vocab_size:\", len(tokenizer))\n",
    "# =================================\n",
    "\n",
    "# -------------------------\n",
    "# 2. ä» Ulysses txt ç”Ÿæˆ token chunksï¼ˆæ»‘åŠ¨çª—å£ï¼‰\n",
    "# -------------------------\n",
    "def load_and_tokenize_txt(txt_path, tokenizer, max_len, stride):\n",
    "    print(\"Reading Ulysses txt:\", txt_path)\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    # ç®€å•æŒ‰æ®µè½æ‹†åˆ†ï¼ˆä¿ç•™è¯­ä¹‰å®Œæ•´æ€§ï¼‰ï¼Œæ®µè½é—´ä¿ç•™æ¢è¡Œ\n",
    "    paragraphs = [p.strip() for p in raw.split(\"\\n\\n\") if p.strip()]\n",
    "    print(f\"Found {len(paragraphs)} paragraphs; will pack paragraphs into chunks <= {max_len} tokens.\")\n",
    "\n",
    "    all_chunks = []\n",
    "    cur_ids = []\n",
    "    cur_chars = []\n",
    "\n",
    "    for para in paragraphs:\n",
    "        para_ids = tokenizer(para, add_special_tokens=False)[\"input_ids\"]\n",
    "        if len(para_ids) > max_len:\n",
    "            # æ®µè½æœ¬èº«è¶…é•¿ï¼šæŒ‰ token çª—å£åˆ‡åˆ†\n",
    "            start = 0\n",
    "            while start < len(para_ids):\n",
    "                end = min(start + max_len, len(para_ids))\n",
    "                chunk_ids = para_ids[start:end]\n",
    "                chunk_text = tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "                all_chunks.append(chunk_text)\n",
    "                if end == len(para_ids):\n",
    "                    break\n",
    "                start += max_len - stride\n",
    "            continue\n",
    "\n",
    "        # è‹¥åŠ å…¥å½“å‰ chunk åä¸è¶…é•¿åˆ™åˆå¹¶\n",
    "        if len(cur_ids) + len(para_ids) <= max_len:\n",
    "            cur_ids.extend(para_ids)\n",
    "            cur_chars.append(para)\n",
    "        else:\n",
    "            # flush current\n",
    "            if cur_ids:\n",
    "                all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "            # start new\n",
    "            cur_ids = para_ids.copy()\n",
    "            cur_chars = [para]\n",
    "\n",
    "    # flush tail\n",
    "    if cur_ids:\n",
    "        all_chunks.append(tokenizer.decode(cur_ids, skip_special_tokens=True))\n",
    "\n",
    "    # è¿›ä¸€æ­¥åº”ç”¨æ»‘åŠ¨çª—å£ä»¥å¢åŠ å¤šæ ·æ€§ï¼ˆå¯é€‰ï¼‰\n",
    "    # è¿™é‡Œæˆ‘ä»¬å†æŠŠæ¯ chunk åš stride åˆ†å‰²ï¼Œé¿å…é—æ¼è·¨æ®µä¸Šä¸‹æ–‡\n",
    "    final_chunks = []\n",
    "    for chunk in all_chunks:\n",
    "        ids = tokenizer(chunk, add_special_tokens=False)[\"input_ids\"]\n",
    "        start = 0\n",
    "        while start < len(ids):\n",
    "            end = min(start + max_len, len(ids))\n",
    "            part = tokenizer.decode(ids[start:end], skip_special_tokens=True)\n",
    "            final_chunks.append(part)\n",
    "            if end == len(ids):\n",
    "                break\n",
    "            start += max_len - stride\n",
    "\n",
    "    print(f\"Total token chunks prepared: {len(final_chunks)}\")\n",
    "    return final_chunks\n",
    "\n",
    "chunks = load_and_tokenize_txt(CONFIG[\"ulysses_txt\"], tokenizer, CONFIG[\"max_len\"], CONFIG[\"stride\"])\n",
    "\n",
    "# -------------------------\n",
    "# 3. æ„é€  Datasetï¼ˆå¯¹è¯æ ¼å¼ + prefix-only maskï¼‰\n",
    "# -------------------------\n",
    "class UlyssesDataset(Dataset):\n",
    "    def __init__(self, chunks, tokenizer, max_len):\n",
    "        self.examples = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        for idx, chunk_text in enumerate(chunks):\n",
    "            # user instruction: è¦æ±‚ç”Ÿæˆæ„è¯†æµé£æ ¼çš„æ®µè½ï¼ˆä¸æŠ„è¢­åŸæ–‡ï¼‰\n",
    "            user_instr = (\n",
    "                \"Write an original paragraph in James Joyce's stream-of-consciousness style \"\n",
    "                \"that captures similar imagery and tone as the following excerpt. \"\n",
    "                \"Do not copy exact phrases; be original.\\n\\n\"\n",
    "                f\"Excerpt:\\n{chunk_text}\"\n",
    "            )\n",
    "\n",
    "            # We will teach the model to generate text in this style by using the chunk_text\n",
    "            # as the assistant target. (You can replace this by paraphrases if desired.)\n",
    "            assistant_target = chunk_text\n",
    "\n",
    "            full = f\"<|im_start|>user\\n{user_instr}<|im_end|>\\n<|im_start|>assistant\\n{assistant_target}<|im_end|>\"\n",
    "            enc = tokenizer(full, max_length=self.max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = enc[\"input_ids\"].squeeze(0)\n",
    "            attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
    "            labels = input_ids.clone()\n",
    "\n",
    "            # find assistant start token index to mask prefix\n",
    "            # We search for the tokenizer encoding of \"<|im_start|>assistant\\n\"\n",
    "            # Simpler: find the first occurrence of \"<|im_start|>\" after the user block.\n",
    "            special_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "            # locate positions\n",
    "            ids_list = input_ids.tolist()\n",
    "            assistant_pos = 0\n",
    "            try:\n",
    "                # find second occurrence of im_start (first is user)\n",
    "                first = ids_list.index(special_id)\n",
    "                second = ids_list.index(special_id, first + 1)\n",
    "                assistant_pos = second\n",
    "            except ValueError:\n",
    "                # fallback: try to find the textual marker\n",
    "                txt = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "                marker = \"<|im_start|>assistant\\n\"\n",
    "                if marker in txt:\n",
    "                    assistant_pos = tokenizer(marker, add_special_tokens=False)[\"input_ids\"][0]\n",
    "                    # not reliable; fallback to 0\n",
    "                else:\n",
    "                    assistant_pos = 0\n",
    "\n",
    "            # mask prefix (user + instruction) so loss is only computed on assistant part\n",
    "            labels[:assistant_pos] = -100\n",
    "\n",
    "            self.examples.append({\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "        print(f\"Dataset built: {len(self.examples)} examples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "dataset = UlyssesDataset(chunks, tokenizer, CONFIG[\"max_len\"])\n",
    "dataloader = DataLoader(dataset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4. åŠ è½½åŸºåº§æ¨¡å‹å¹¶è£…ä¸Š LoRA\n",
    "# -------------------------\n",
    "print(\"Loading base model from:\", CONFIG[\"base_model_path\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG[\"base_model_path\"],\n",
    "    torch_dtype=torch.float16 if CONFIG[\"fp16\"] else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    target_modules=CONFIG[\"target_modules\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()\n",
    "model.train()\n",
    "\n",
    "# device for inputs: model may be sharded; use next(model.parameters()).device\n",
    "model_device = next(model.parameters()).device\n",
    "print(\"Model device:\", model_device)\n",
    "\n",
    "# -------------------------\n",
    "# 5. optimizer & loss\n",
    "# -------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# -------------------------\n",
    "# 6. è®­ç»ƒå¾ªç¯\n",
    "# -------------------------\n",
    "def format_time(seconds):\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "total_steps = len(dataloader) * CONFIG[\"num_train_epochs\"] // CONFIG[\"gradient_accumulation_steps\"]\n",
    "print(\"Training config -- epochs:\", CONFIG[\"num_train_epochs\"], \"batches_per_epoch:\", len(dataloader), \"total_steps(approx):\", total_steps)\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(CONFIG[\"num_train_epochs\"]):\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        global_step += 1\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(model_device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model_device)\n",
    "        labels = batch[\"labels\"].to(model_device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / CONFIG[\"gradient_accumulation_steps\"]\n",
    "        loss.backward()\n",
    "\n",
    "        if global_step % CONFIG[\"gradient_accumulation_steps\"] == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.5)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item() * CONFIG[\"gradient_accumulation_steps\"]\n",
    "\n",
    "        if global_step % CONFIG[\"print_every_steps\"] == 0:\n",
    "            avg_loss = running_loss / (global_step if global_step>0 else 1)\n",
    "            print(f\"[Epoch {epoch+1}] Step {global_step} | loss: {avg_loss:.4f} | step_time: {format_time(time.time()-epoch_start)}\")\n",
    "\n",
    "    epoch_time = format_time(time.time() - epoch_start)\n",
    "    print(f\"Epoch {epoch+1} finished in {epoch_time}\")\n",
    "\n",
    "# -------------------------\n",
    "# 7. ä¿å­˜å¾®è°ƒåæ¨¡å‹ï¼ˆåŒ…å« LoRAï¼‰\n",
    "# -------------------------\n",
    "print(\"Saving finetuned model to:\", CONFIG[\"output_dir\"])\n",
    "model.save_pretrained(CONFIG[\"output_dir\"])\n",
    "tokenizer.save_pretrained(CONFIG[\"output_dir\"])\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0832566-8571-4c51-ab21-7f1b3c983d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.18it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter...\n",
      "\n",
      "=== Generated Poem ===\n",
      "\n",
      "In the heart of an old, forgotten glade,\n",
      "Where shadows dance and whispers play,\n",
      "Stands a willow, mighty and grand,\n",
      "With branches swaying to the land.\n",
      "\n",
      "The breeze that stirs beneath her boughs\n",
      "Is not just any gusty flow;\n",
      "It's wind itself, enchanted, turned,\n",
      "To softly caress what it has earned.\n",
      "\n",
      "Her leaves rustle in a lullaby,\n",
      "A symphony where fluffiness lies.\n",
      "Fluffy down from fields afar,\n",
      "Drifts into the air like a fairy car.\n",
      "\n",
      "She weaves them into dreams so pure,\n",
      "Charmed by the gentle touch of the lure.\n",
      "Each strand entwines as if she knows\n",
      "Of magic hidden, unseen and aglow.\n",
      "\n",
      "Thus, under her spell, the world bends,\n",
      "A tapestry of light and shades, friends.\n",
      "For in this place where willows sway,\n",
      "Life breathes easy, every day.\n"
     ]
    }
   ],
   "source": [
    "# inference_mindflow.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. é…ç½®è·¯å¾„\n",
    "# -------------------------\n",
    "BASE_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-sft-full\"               # åŸºåº§ï¼ˆæ¨¡å‹ä¸€ï¼‰\n",
    "LORA_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"      # å°¤åˆ©è¥¿æ–¯å¿ƒæµå¾®è°ƒï¼ˆæ¨¡å‹äºŒï¼‰\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.12,\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# 2. åŠ è½½ tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# å¿…é¡»è®¾ç½® pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 3. åŠ è½½æ¨¡å‹ + LoRA\n",
    "# -------------------------\n",
    "print(\"Loading base model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(model, LORA_MODEL)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 4. æ¨ç†å‡½æ•°\n",
    "# -------------------------\n",
    "def generate_with_mindflow(prompt: str):\n",
    "    # ä½ è®­ç»ƒæ—¶ä½¿ç”¨çš„å¯¹è¯æ ¼å¼\n",
    "    formatted = (\n",
    "        f\"<|im_start|>user\\n{prompt}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\"\n",
    "    )\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        formatted,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **GEN_CFG\n",
    "        )\n",
    "\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    # æ¸…ç†æ‰æ ¼å¼ token\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. æµ‹è¯•\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt = (\n",
    "        \"write a poem with keyword: willow, wind, fluffy, charmed. \"\n",
    "        \"With a mindflow of thoughts.\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Generated Poem ===\\n\")\n",
    "    print(generate_with_mindflow(test_prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd187bbd-dfb7-420e-820c-da9fa02283f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter...\n",
      "\n",
      "ğŸ§  Mindflow Poetry Generator\n",
      "è¾“å…¥ prompt å›è½¦ç”Ÿæˆ\n",
      "è¾“å…¥ reset æ¸…ç©ºè®°å¿†\n",
      "è¾“å…¥ exit é€€å‡ºå¹¶ä¿å­˜ç»ˆç‰ˆè¯—æ­Œ\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  write a poem in Walt whitman style, using the keyword: nature, chirping, farm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ===\n",
      "\n",
      "Oh Nature, vast and wondrous,\n",
      "In fields where grasses sigh and sway,\n",
      "A symphony of chirps and songs,\n",
      "From dawn's first light till night's last ray.\n",
      "\n",
      "The rooster crows upon my farm,\n",
      "His voice rings out with hearty cheer,\n",
      "And larks ascend to heavens' arm,\n",
      "Their melodies sweet, clear, and near.\n",
      "\n",
      "Prairie chickens strut and dance,\n",
      "As goldenrod and daisies bloom,\n",
      "While cornfields stretch to horizons chance,\n",
      "And bluebirds dart through open rooms.\n",
      "\n",
      "My heart swells wide as boundless skies,\n",
      "With joy that springs from every nook,\n",
      "For here among these verdant prizes,\n",
      "I find contentment, free from clutch.\n",
      "\n",
      "So let me wander on and on,\n",
      "Through woodlands deep and sunny glades,\n",
      "Where foxes run and wildflowers hon,\n",
      "Nature whispers truths untamed.\n",
      "\n",
      "This land, this life, is all I needâ€”\n",
      "No other wealth could e'er compare.\n",
      "Chirping thrushes, singing streams fed,\n",
      "Teach wisdom worth remembering.\n",
      ".Disclaimer: This response is generated text designed to emulate the style of Walt Whitman but may not capture all nuances or poetic devices used by the poet himself.\n",
      "\n",
      "=================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  delete the disclaimer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ===\n",
      "\n",
      "Oh Nature, vast and wondrous,\n",
      "In fields where grasses sigh and sway,\n",
      "A symphony of chirps and songs,\n",
      "From dawn's first light till night's last ray.\n",
      "\n",
      "The rooster crows upon my farm,\n",
      "His voice rings out with hearty cheer,\n",
      "And larks ascend to heavens' arm,\n",
      "Their melodies sweet, clear, and near.\n",
      "\n",
      "Prairie chickens strut and dance,\n",
      "As goldenrod and daisies bloom,\n",
      "While cornfields stretch to horizons chance,\n",
      "And bluebirds dart through open rooms.\n",
      "\n",
      "My heart swells wide as boundless skies,\n",
      "With joy that springs from every nook,\n",
      "For here among these verdant prizes,\n",
      "I find contentment, free from clutch.\n",
      "\n",
      "So let me wander on and on,\n",
      "Through woodlands deep and sunny glades,\n",
      "Where foxes run and wildflowers hon,\n",
      "Nature whispers truths untamed.\n",
      "\n",
      "This land, this life, is all I needâ€”\n",
      "No other wealth could e'er compare.\n",
      "Chirping thrushes, singing streams fed,\n",
      "Teach wisdom worth remembering.\n",
      "\n",
      "=================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç»ˆç‰ˆè¯—æ­Œå·²ä¿å­˜è‡³ï¼š./poetry_results/final_poem_20251213_172423.txt\n",
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. é…ç½®\n",
    "# -------------------------\n",
    "BASE_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-sft-full\"\n",
    "LORA_MODEL = \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 400,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.12,\n",
    "}\n",
    "\n",
    "# æ–°å¢ï¼šä¿å­˜é…ç½®\n",
    "SAVE_FOLDER = \"./poetry_results\"  # ä¿å­˜ç›®å½•\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆä¸å­˜åœ¨æ—¶ï¼‰\n",
    "\n",
    "# -------------------------\n",
    "# 2. åŠ è½½ tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 3. åŠ è½½æ¨¡å‹ + LoRA\n",
    "# -------------------------\n",
    "print(\"Loading base model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(model, LORA_MODEL)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 4. æ ¸å¿ƒï¼šå¸¦â€œè®°å¿†â€çš„ç”Ÿæˆ\n",
    "# -------------------------\n",
    "conversation_memory = \"\"   # â­ å­˜ä¸Šä¸€è½®ç”Ÿæˆç»“æœ\n",
    "\n",
    "\n",
    "def generate_with_memory(user_prompt: str):\n",
    "    global conversation_memory\n",
    "\n",
    "    if conversation_memory:\n",
    "        # åœ¨å·²æœ‰è¯—æ­ŒåŸºç¡€ä¸Š refinement\n",
    "        formatted = (\n",
    "            \"<|im_start|>user\\n\"\n",
    "            \"Here is the previous poem:\\n\"\n",
    "            f\"{conversation_memory}\\n\\n\"\n",
    "            \"Please revise or continue it according to the following instruction:\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # ç¬¬ä¸€è½®\n",
    "        formatted = (\n",
    "            f\"<|im_start|>user\\n{user_prompt}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    input_ids = tokenizer(formatted, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **GEN_CFG\n",
    "        )\n",
    "\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    # æ¸…ç†è¾“å‡º\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    # â­ æ›´æ–°è®°å¿†\n",
    "    conversation_memory = text\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. äº¤äº’å¼è¾“å…¥\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nğŸ§  Mindflow Poetry Generator\")\n",
    "    print(\"è¾“å…¥ prompt å›è½¦ç”Ÿæˆ\")\n",
    "    print(\"è¾“å…¥ reset æ¸…ç©ºè®°å¿†\")\n",
    "    print(\"è¾“å…¥ exit é€€å‡ºå¹¶ä¿å­˜ç»ˆç‰ˆè¯—æ­Œ\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\">>> \").strip()\n",
    "\n",
    "        if user_input.lower() == \"exit\":\n",
    "            # ä¿å­˜ç»ˆç‰ˆè¯—æ­Œåˆ°txtæ–‡ä»¶\n",
    "            if conversation_memory:\n",
    "                # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åï¼Œé¿å…è¦†ç›–\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "                file_path = os.path.join(SAVE_FOLDER, f\"final_poem_{timestamp}.txt\")\n",
    "                \n",
    "                # å†™å…¥æ–‡ä»¶ï¼ˆUTF-8ç¼–ç é˜²æ­¢ä¸­æ–‡ä¹±ç ï¼‰\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(\"=== Mindflow Poetry Final Version ===\\n\")\n",
    "                    f.write(f\"Generated Time: {time.ctime()}\\n\")\n",
    "                    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "                    f.write(conversation_memory)\n",
    "                \n",
    "                print(f\"\\nâœ… ç»ˆç‰ˆè¯—æ­Œå·²ä¿å­˜è‡³ï¼š{file_path}\")\n",
    "            else:\n",
    "                print(\"\\nâš ï¸  æš‚æ— ç”Ÿæˆçš„è¯—æ­Œå†…å®¹ï¼Œæœªä¿å­˜æ–‡ä»¶\")\n",
    "            \n",
    "            print(\"Bye.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() == \"reset\":\n",
    "            conversation_memory = \"\"\n",
    "            print(\"ğŸ”„ Memory cleared.\\n\")\n",
    "            continue\n",
    "\n",
    "        output = generate_with_memory(user_input)\n",
    "\n",
    "        print(\"\\n=== Generated ===\\n\")\n",
    "        print(output)\n",
    "        print(\"\\n=================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7349fb-842d-41aa-86e4-5ec97a2497ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "\n",
      "Loading BASE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SFT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MINDFLOW model (base + LoRA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.40it/s]\n",
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All models loaded successfully!\n",
      "\n",
      "\n",
      "ğŸ§  Mindflow Poetry Generator - Multi-Model Mode\n",
      "======================================================================\n",
      "æŒ‡ä»¤è¯´æ˜ï¼š\n",
      "  1. ç›´æ¥è¾“å…¥æ–‡æœ¬      - åŒæ—¶è°ƒç”¨BASE/SFT/MINDFLOWä¸‰ä¸ªæ¨¡å‹ç”Ÿæˆè¯—æ­Œ\n",
      "  2. reset             - æ¸…ç©ºæ‰€æœ‰æ¨¡å‹çš„å¯¹è¯è®°å¿†\n",
      "  3. exit              - é€€å‡ºå¹¶ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„ç»ˆç‰ˆè¯—æ­Œ\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  write a poem in Walt whitman style, using the keyword: nature, chirping, farm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ”„ Generating with BASE model...\n",
      "ğŸ”„ Generating with SFT model...\n",
      "ğŸ”„ Generating with MINDFLOW model...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ“ BASE MODEL OUTPUT:\n",
      "\n",
      "In fields where the sunâ€™s warm hands caress,\n",
      "And nature whispers to the whispering breeze,\n",
      "I hear the songs that fill this vast expanseâ€”\n",
      "Chirping crickets and larks ascending.\n",
      "\n",
      "Amidst rows of corn and wheat so green,\n",
      "Where cows graze tranquil as their breaths are seen,\n",
      "A farmer tills with slow, sure pace and might,\n",
      "His heart with every furrow taking flight.\n",
      "\n",
      "Beneath the big blue sky's expansive dome,\n",
      "He works the earth, the very essence of home.\n",
      "The soil rich with the promise of tomorrow,\n",
      "As seasons turn like leaves upon the floor.\n",
      "\n",
      "This land, so wild yet cultivated too,\n",
      "Sings with life in voices low and true.\n",
      "The chirping thrums through the air, light as thought,\n",
      "Natureâ€™s symphony, on and around the plot.\n",
      "\n",
      "So let me wander, hand in hand with time,\n",
      "Among these plots, among these rolling climbs.\n",
      "For here I find my spirit set at ease,\n",
      "By natureâ€™s chords, by laborâ€™s endless seas.\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ SFT MODEL OUTPUT:\n",
      "\n",
      "I too sing America! I am largeâ€”I contain multitudes.\n",
      "From every sound of life, from my own voice sounding,\n",
      "And that of others, even to the last far-off muted strain,\n",
      "Whateâ€™er it is must be significantâ€”every one of its phrases a word in mine;\n",
      "Each echo an affirmationâ€”each sound and shade has its correspondent in me.\n",
      "All sounds are significantâ€”the cricketâ€™s, the grasshopperâ€™s, or any insectâ€™s high-pitched note;\n",
      "The birdâ€™s song on the hill-tops morning and evening, as he perches on the hemlock or oak, or flutters about the field-birdâ€™s home;\n",
      "Or if in summerâ€™s still hour on the lawn I hear the bee humming through the air,\n",
      "So faintly, yet so confident, no matter which way turned,\n",
      "Sure as fateâ€™s hand whispers me to turn the page of my book,\n",
      "He says his say, with his tiny wings half-opened, flying lightly onâ€”tells all his news,\n",
      "Then settles by my side, and hums his song of love,\n",
      "Sings louder and clearer, for here he means to stay;\n",
      "It seems to me to have a deep meaning this little beingâ€™s talk;\n",
      "Somehow it penetrates my spirit, and takes root there.\n",
      "Natureâ€™s most secret thought seems whispering in each tone;\n",
      "She never stops to consider, nor thinks to teach or show,\n",
      "But goes her ways, and lets us find out what we can;\n",
      "Let them come from China or Europe, the newest arrivals, or those who have been many days in prison,\n",
      "They will hear the same tune, the same cry of joy, and wonder, and passion.\n",
      "The farmer, the mechanic, the laborer, all join their voices with mine,\n",
      "To praise and honor the land of our birthâ€”its rivers, mountains, lakes and plains;\n",
      "Where ever the sunset shines upon our land, it is blessed and praised.\n",
      "There is a sweet old-time melody, heard once only\n",
      "\n",
      "================================================================================\n",
      "ğŸ“ MINDFLOW MODEL OUTPUT:\n",
      "\n",
      "In fields where nature's breath doth sigh,\n",
      "And sunbeams kiss the waving hay,\n",
      "Where murmurs of sweet moisture fly,\n",
      "A song of life and toil they lay.\n",
      "\n",
      "Upon the farms the morning breaks,\n",
      "The roosters crow, and cows low soft.\n",
      "Young swains, with boots all laced and stakes,\n",
      "Begin their work at early not.\n",
      "\n",
      "Chirping thrushes fill the green lanesâ€”\n",
      "Sparrows sing in sprigged apple boughs.\n",
      "All creatures wake as Nature paints,\n",
      "Her canvas bright with dawnâ€™s blush now.\n",
      "\n",
      "The plowman, strong as oak trees' root,\n",
      "Draws furrows deep in soil dark brown.\n",
      "His spade, like arm of Atlas, fraught\n",
      "With power to lift the earth around.\n",
      "\n",
      "Here wheat is born from loam so rich,\n",
      "And cornfields stretch like golden seas.\n",
      "Natureâ€™s bounty here does teach us much:\n",
      "Toiled for by hands that will not cease.\n",
      "\n",
      "From morn till night, with steadfast mind,\n",
      "These farmers bend their willing will.\n",
      "Each task they know must be combined,\n",
      "To thrive and grow beneath the hill.\n",
      "\n",
      "Thus through the day they labor hard,\n",
      "Till stars come out, and darkness draws.\n",
      "Then grateful hearts to rest are charted,\n",
      "For toilsome days have wrought new straw.  \n",
      "\n",
      "So let it be when sunset comes,\n",
      "When fields lie still under the star.\n",
      "We thank these workers for our homes,\n",
      "And cherish all we get in bar.\n",
      "\n",
      "This poem uses elements inspired by Walt Whitman's style, including free verse, an emphasis on natural imagery and rural life, and a focus on the rhythms of daily existence on a farm. The repetition and use of dashes also echo some of Whitman's characteristic techniques.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ‰€æœ‰æ¨¡å‹çš„ç»ˆç‰ˆè¯—æ­Œå·²ä¿å­˜è‡³ï¼š./poetry_results/all_models_poem_20251213_180850.txt\n",
      "\n",
      "ğŸ‘‹ Bye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# -------------------------\n",
    "# 1. é…ç½®\n",
    "# -------------------------\n",
    "# æ¨¡å‹è·¯å¾„é…ç½®\n",
    "MODEL_PATHS = {\n",
    "    \"base\": \"/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\",\n",
    "    \"sft\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",\n",
    "    \"mindflow\": {\n",
    "        \"base\": \"/root/autodl-tmp/Pro/qwen2.5-sft-full\",\n",
    "        \"lora\": \"/root/autodl-tmp/Pro/qwen2.5-mindflow-ulysses\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "GEN_CFG = {\n",
    "    \"max_new_tokens\": 400,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.92,\n",
    "    \"repetition_penalty\": 1.12,\n",
    "}\n",
    "\n",
    "# æ–°å¢ï¼šä¿å­˜é…ç½®\n",
    "SAVE_FOLDER = \"./poetry_results\"  # ä¿å­˜ç›®å½•\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆä¸å­˜åœ¨æ—¶ï¼‰\n",
    "\n",
    "# -------------------------\n",
    "# 2. å…¨å±€å˜é‡ï¼šå¤šæ¨¡å‹è®°å¿†å­˜å‚¨\n",
    "# -------------------------\n",
    "# åˆ†åˆ«å­˜å‚¨ä¸‰ä¸ªæ¨¡å‹çš„å¯¹è¯è®°å¿†\n",
    "conversation_memory = {\n",
    "    \"base\": \"\",\n",
    "    \"sft\": \"\",\n",
    "    \"mindflow\": \"\"\n",
    "}\n",
    "tokenizer = None  # å…¨å±€tokenizer\n",
    "models = {}  # å­˜å‚¨åŠ è½½çš„æ¨¡å‹\n",
    "\n",
    "# -------------------------\n",
    "# 3. åŠ è½½ tokenizer\n",
    "# -------------------------\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATHS[\"base\"],\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# 4. åŠ è½½æ‰€æœ‰æ¨¡å‹\n",
    "# -------------------------\n",
    "def load_all_models():\n",
    "    \"\"\"åŠ è½½æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹\"\"\"\n",
    "    # åŠ è½½Baseæ¨¡å‹\n",
    "    print(\"\\nLoading BASE model...\")\n",
    "    models[\"base\"] = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"base\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    # åŠ è½½SFTæ¨¡å‹\n",
    "    print(\"Loading SFT model...\")\n",
    "    models[\"sft\"] = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"sft\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    # åŠ è½½Mindflowæ¨¡å‹ï¼ˆbase + LoRAï¼‰\n",
    "    print(\"Loading MINDFLOW model (base + LoRA)...\")\n",
    "    mindflow_base = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATHS[\"mindflow\"][\"base\"],\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    models[\"mindflow\"] = PeftModel.from_pretrained(\n",
    "        mindflow_base,\n",
    "        MODEL_PATHS[\"mindflow\"][\"lora\"]\n",
    "    ).eval()\n",
    "\n",
    "    print(\"\\nâœ… All models loaded successfully!\")\n",
    "    return models\n",
    "\n",
    "# -------------------------\n",
    "# 5. æ ¸å¿ƒï¼šå¸¦â€œè®°å¿†â€çš„å¤šæ¨¡å‹ç”Ÿæˆ\n",
    "# -------------------------\n",
    "def generate_with_memory(user_prompt: str, model_type: str):\n",
    "    \"\"\"å¸¦è®°å¿†çš„ç”Ÿæˆå‡½æ•°ï¼ˆæŒ‡å®šæ¨¡å‹ï¼‰\"\"\"\n",
    "    global conversation_memory, models, tokenizer\n",
    "\n",
    "    model = models[model_type]\n",
    "    memory = conversation_memory[model_type]\n",
    "\n",
    "    # æ„å»ºå¸¦è®°å¿†çš„prompt\n",
    "    if memory:\n",
    "        formatted = (\n",
    "            \"<|im_start|>user\\n\"\n",
    "            \"Here is the previous poem:\\n\"\n",
    "            f\"{memory}\\n\\n\"\n",
    "            \"Please revise or continue it according to the following instruction:\\n\"\n",
    "            f\"{user_prompt}\"\n",
    "            \"<|im_end|>\\n\"\n",
    "            \"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # ç¬¬ä¸€è½®ç”Ÿæˆ\n",
    "        formatted = (\n",
    "            f\"<|im_start|>user\\n{user_prompt}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\n\"\n",
    "        )\n",
    "\n",
    "    # ç¼–ç è¾“å…¥\n",
    "    input_ids = tokenizer(formatted, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡º\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **GEN_CFG\n",
    "        )\n",
    "\n",
    "    # è§£ç å¹¶æ¸…ç†è¾“å‡º\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    if \"<|im_start|>assistant\\n\" in text:\n",
    "        text = text.split(\"<|im_start|>assistant\\n\")[1]\n",
    "    text = text.replace(\"<|im_end|>\", \"\").replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    # æ›´æ–°å¯¹åº”æ¨¡å‹çš„è®°å¿†\n",
    "    conversation_memory[model_type] = text\n",
    "\n",
    "    return text\n",
    "\n",
    "def generate_all_models(user_prompt: str):\n",
    "    \"\"\"åŒæ—¶è°ƒç”¨ä¸‰ä¸ªæ¨¡å‹ç”Ÿæˆç»“æœ\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    # Baseæ¨¡å‹ç”Ÿæˆ\n",
    "    print(\"ğŸ”„ Generating with BASE model...\")\n",
    "    results[\"base\"] = generate_with_memory(user_prompt, \"base\")\n",
    "    \n",
    "    # SFTæ¨¡å‹ç”Ÿæˆ\n",
    "    print(\"ğŸ”„ Generating with SFT model...\")\n",
    "    results[\"sft\"] = generate_with_memory(user_prompt, \"sft\")\n",
    "    \n",
    "    # Mindflowæ¨¡å‹ç”Ÿæˆ\n",
    "    print(\"ğŸ”„ Generating with MINDFLOW model...\")\n",
    "    results[\"mindflow\"] = generate_with_memory(user_prompt, \"mindflow\")\n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# 6. ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„ç»ˆç‰ˆç»“æœ\n",
    "# -------------------------\n",
    "def save_all_results():\n",
    "    \"\"\"ä¿å­˜ä¸‰ä¸ªæ¨¡å‹çš„ç»ˆç‰ˆè¾“å‡º\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    file_path = os.path.join(SAVE_FOLDER, f\"all_models_poem_{timestamp}.txt\")\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        # å†™å…¥å…ƒä¿¡æ¯\n",
    "        f.write(\"=== Mindflow Poetry - All Models Final Results ===\\n\")\n",
    "        f.write(f\"Generated Time: {time.ctime()}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        # å†™å…¥Baseæ¨¡å‹ç»“æœ\n",
    "        f.write(\"ğŸ“Œ BASE MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"base\"] if conversation_memory[\"base\"] else \"No content generated\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # å†™å…¥SFTæ¨¡å‹ç»“æœ\n",
    "        f.write(\"ğŸ“Œ SFT MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"sft\"] if conversation_memory[\"sft\"] else \"No content generated\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # å†™å…¥Mindflowæ¨¡å‹ç»“æœ\n",
    "        f.write(\"ğŸ“Œ MINDFLOW MODEL OUTPUT:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(conversation_memory[\"mindflow\"] if conversation_memory[\"mindflow\"] else \"No content generated\\n\")\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# -------------------------\n",
    "# 7. äº¤äº’å¼è¾“å…¥\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # åŠ è½½æ‰€æœ‰æ¨¡å‹\n",
    "    models = load_all_models()\n",
    "    \n",
    "    # äº¤äº’å¼ç•Œé¢\n",
    "    print(\"\\n\\nğŸ§  Mindflow Poetry Generator - Multi-Model Mode\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"æŒ‡ä»¤è¯´æ˜ï¼š\")\n",
    "    print(\"  1. ç›´æ¥è¾“å…¥æ–‡æœ¬      - åŒæ—¶è°ƒç”¨BASE/SFT/MINDFLOWä¸‰ä¸ªæ¨¡å‹ç”Ÿæˆè¯—æ­Œ\")\n",
    "    print(\"  2. reset             - æ¸…ç©ºæ‰€æœ‰æ¨¡å‹çš„å¯¹è¯è®°å¿†\")\n",
    "    print(\"  3. exit              - é€€å‡ºå¹¶ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„ç»ˆç‰ˆè¯—æ­Œ\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\">>> \").strip()\n",
    "\n",
    "        if not user_input:\n",
    "            print(\"âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹ï¼\")\n",
    "            continue\n",
    "\n",
    "        # é€€å‡ºå¹¶ä¿å­˜æ‰€æœ‰ç»“æœ\n",
    "        if user_input.lower() == \"exit\":\n",
    "            # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆå†…å®¹\n",
    "            has_content = any(bool(v) for v in conversation_memory.values())\n",
    "            if has_content:\n",
    "                file_path = save_all_results()\n",
    "                print(f\"\\nâœ… æ‰€æœ‰æ¨¡å‹çš„ç»ˆç‰ˆè¯—æ­Œå·²ä¿å­˜è‡³ï¼š{file_path}\")\n",
    "            else:\n",
    "                print(\"\\nâš ï¸  æš‚æ— ç”Ÿæˆçš„è¯—æ­Œå†…å®¹ï¼Œæœªä¿å­˜æ–‡ä»¶\")\n",
    "            \n",
    "            print(\"\\nğŸ‘‹ Bye!\")\n",
    "            break\n",
    "\n",
    "        # æ¸…ç©ºæ‰€æœ‰è®°å¿†\n",
    "        elif user_input.lower() == \"reset\":\n",
    "            conversation_memory = {\n",
    "                \"base\": \"\",\n",
    "                \"sft\": \"\",\n",
    "                \"mindflow\": \"\"\n",
    "            }\n",
    "            print(\"âœ… å·²æ¸…ç©ºæ‰€æœ‰æ¨¡å‹çš„å¯¹è¯è®°å¿†ï¼\\n\")\n",
    "            continue\n",
    "\n",
    "        # æ­£å¸¸ç”Ÿæˆï¼šåŒæ—¶è°ƒç”¨ä¸‰ä¸ªæ¨¡å‹\n",
    "        else:\n",
    "            # ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„ç»“æœ\n",
    "            results = generate_all_models(user_input)\n",
    "            \n",
    "            # è¾“å‡ºç»“æœ\n",
    "            print(\"ğŸ“ BASE MODEL OUTPUT:\\n\")\n",
    "            print(results[\"base\"])\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            \n",
    "            print(\"ğŸ“ SFT MODEL OUTPUT:\\n\")\n",
    "            print(results[\"sft\"])\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            \n",
    "            print(\"ğŸ“ MINDFLOW MODEL OUTPUT:\\n\")\n",
    "            print(results[\"mindflow\"])\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca9ca32-56ed-41f8-a931-ffca28a565e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/qwen_text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Qwen2.5-7B æ¨¡å‹åŠ è½½å®Œæˆï¼\n",
      "ğŸš€ å¼€å§‹è°ƒç”¨æœ¬åœ° Qwen2.5-7B åˆ†æè¯—æ­Œ...\n",
      "================================================================================\n",
      "ğŸ“œ Poem Content:\n",
      "Oh Nature, vast and wondrous,\n",
      "In fields where grasses sigh and sway,\n",
      "A symphony of chirps and songs,\n",
      "From dawn's first light till night's last ray.\n",
      "The rooster crows upon my farm,\n",
      "His voice rings out with hearty cheer,\n",
      "And larks ascend to heavens' arm,\n",
      "Their melodies sweet, clear, and near.\n",
      "Prairie chickens strut and dance,\n",
      "As goldenrod and daisies bloom,\n",
      "While cornfields stretch to horizons chance,\n",
      "And bluebirds dart through open rooms.\n",
      "My heart swells wide as boundless skies,\n",
      "With joy that springs from every nook,\n",
      "For here among these verdant prizes,\n",
      "I find contentment, free from clutch.\n",
      "So let me wander on and on,\n",
      "Through woodlands deep and sunny glades,\n",
      "Where foxes run and wildflowers hon,\n",
      "Nature whispers truths untamed.\n",
      "This land, this life, is all I needâ€”\n",
      "No other wealth could e'er compare.\n",
      "Chirping thrushes, singing streams fed,\n",
      "Teach wisdom worth remembering.\n",
      "================================================================================\n",
      "\n",
      "ğŸ¯ LitBench Score Summary (0-10):\n",
      "  - Fluency: 8.5\n",
      "  - Emotional Resonance: 9.0\n",
      "  - Image Innovation: 7.5\n",
      "  - Theme Consistency: 8.0\n",
      "  - Human Preference: 8.8\n",
      "  - Total Score: 8.36\n",
      "\n",
      "ğŸ“ Detailed Dimension Analysis:\n",
      "\n",
      "ã€Fluencyã€‘\n",
      "  The poem flows smoothly with rhythmic lines like 'Oh Nature, vast and wondrous,' and 'Chirping thrushes, singing streams fed,' though some lines such as 'From dawn's first light till night's last ray' have slightly awkward phrasing.\n",
      "\n",
      "ã€Emotional Resonanceã€‘\n",
      "  The poem evokes strong feelings of joy and contentment through vivid descriptions ('My heart swells wide as boundless skies') and the use of positive imagery ('goldenrod and daisies bloom').\n",
      "\n",
      "ã€Image Innovationã€‘\n",
      "  The imagery is generally fresh and innovative, especially in the depiction of prairie scenes ('cornfields stretch to horizons chance'), but it occasionally leans towards common tropes like the sunrise and sunset.\n",
      "\n",
      "ã€Theme Consistencyã€‘\n",
      "  The theme of love and alienation is not directly addressed, instead focusing on personal contentment and connection with nature ('Nature whispers truths untamed'). The poem remains consistent with its own thematic focus.\n",
      "\n",
      "ã€Human Preferenceã€‘\n",
      "  The language feels distinctly human-written, with a natural flow and rich descriptive qualities that avoid the mechanical tone often associated with AI-generated poetry.\n",
      "================================================================================\n",
      "\n",
      "âœ… Analysis result saved to: poem_analysis_result_qwen.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Optional\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# -------------------------\n",
    "# 1. é…ç½®æœ¬åœ° Qwen2.5-7B è·¯å¾„ & æ–‡ä»¶è·¯å¾„\n",
    "# -------------------------\n",
    "# æœ¬åœ° Qwen2.5-7B æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰\n",
    "LOCAL_QWEN_PATH = \"/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\"  # ç¤ºä¾‹è·¯å¾„ï¼Œéœ€ä¿®æ”¹\n",
    "# è¯—æ­Œæ–‡ä»¶è·¯å¾„\n",
    "POEM_FILE_PATH = \"/root/autodl-tmp/Pro/poetry_results/final_poem_20251213_172423.txt\"\n",
    "\n",
    "# ç”Ÿæˆé…ç½®ï¼ˆé€‚é… 7B æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœï¼‰\n",
    "GEN_CONFIG = GenerationConfig(\n",
    "    temperature=0.0,  # å›ºå®šæ¸©åº¦ä¿è¯è¯„åˆ†ç¨³å®š\n",
    "    top_k=40,\n",
    "    top_p=0.92,\n",
    "    repetition_penalty=1.1,\n",
    "    max_new_tokens=1500,  # è¶³å¤Ÿå®¹çº³è¯„åˆ†+åˆ†æ\n",
    "    eos_token_id=151643,  # Qwen çš„ eos_token_id\n",
    "    pad_token_id=151643,  # Qwen çš„ pad_token_id\n",
    "    device_map=\"auto\",    # è‡ªåŠ¨åˆ†é…æ˜¾å­˜ï¼ˆGPU/CPUï¼‰\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 2. åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹ & Tokenizer\n",
    "# -------------------------\n",
    "print(\"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    LOCAL_QWEN_PATH,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LOCAL_QWEN_PATH,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,  # ç”¨ float16 èŠ‚çœæ˜¾å­˜\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # å¯é€‰ï¼š4bit é‡åŒ–ï¼Œè¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ï¼ˆéœ€å®‰è£… bitsandbytesï¼‰\n",
    ")\n",
    "model.eval()\n",
    "print(\"âœ… Qwen2.5-7B æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. è¯»å–æ–‡æœ¬æ–‡ä»¶ä¸­çš„è¯—æ­Œï¼ˆé€»è¾‘ä¸å˜ï¼‰\n",
    "# -------------------------\n",
    "def load_poem_from_file(file_path: str) -> str:\n",
    "    \"\"\"è¯»å–æŒ‡å®šè·¯å¾„çš„è¯—æ­Œæ–‡æœ¬ï¼Œæ¸…ç†æ— å…³å†…å®¹\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Poem file not found: {file_path}\")\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # æ¸…ç†æ–‡æœ¬ï¼ˆè¿‡æ»¤æ ‡é¢˜/æ³¨é‡Šè¡Œï¼Œä»…ä¿ç•™è¯—æ­Œæ­£æ–‡ï¼‰\n",
    "    poem_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # è¿‡æ»¤LitBenchç”Ÿæˆçš„æ³¨é‡Šè¡Œï¼ˆå¦‚===å¼€å¤´ã€Generated Timeç­‰ï¼‰\n",
    "        if not line or line.startswith(\"===\") or \"Generated Time\" in line:\n",
    "            continue\n",
    "        poem_lines.append(line)\n",
    "    \n",
    "    poem_text = \"\\n\".join(poem_lines)\n",
    "    if not poem_text:\n",
    "        raise ValueError(\"No valid poem content found in the file\")\n",
    "    \n",
    "    return poem_text\n",
    "\n",
    "# -------------------------\n",
    "# 4. æ„å»ºLitBenchè¯„åˆ†+è¯¦ç»†åˆ†æçš„Promptï¼ˆé€‚é…Qwenï¼‰\n",
    "# -------------------------\n",
    "def build_analysis_prompt(poem_text: str, theme: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    æ„å»ºPromptï¼šé€‚é…Qwenæ ¼å¼ï¼Œä¿ç•™LitBenchè¯„åˆ†ç»´åº¦\n",
    "    \"\"\"\n",
    "    theme = theme if theme else \"no specified theme\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional English poetry critic following the LitBench benchmark for creative writing evaluation.\n",
    "    Evaluate the following English poem with TWO parts, and output ONLY JSON format (no extra text, no explanation):\n",
    "    \n",
    "    ## PART 1: Scoring (0-10 scale, 10 = highest)\n",
    "    Score the poem on these dimensions:\n",
    "    1. Fluency: Line/rhythm smoothness, no semantic fragmentation/awkward phrasing.\n",
    "    2. Emotional Resonance: Ability to evoke genuine reader emotion (joy/sorrow/nostalgia etc.).\n",
    "    3. Image Innovation: Originality of imagery/rhetoric (metaphor/simile/personification) â€“ avoid clichÃ©s.\n",
    "    4. Theme Consistency: Alignment with the given theme ({theme}) â€“ no irrelevant content.\n",
    "    5. Human Preference: Fit with human poetic aesthetic (avoid AI-generated templated language).\n",
    "    \n",
    "    ## PART 2: Detailed Analysis\n",
    "    For each dimension, write a 50-100 word analysis explaining the score:\n",
    "    - For Fluency: Point out specific lines with good/bad rhythm, or semantic issues.\n",
    "    - For Emotional Resonance: Explain which emotions are evoked and how (word choice/tone).\n",
    "    - For Image Innovation: Identify specific imagery/rhetoric, comment on originality (clichÃ©s if any).\n",
    "    - For Theme Consistency: Link specific lines to the theme (or note deviations).\n",
    "    - For Human Preference: Comment on whether the language feels human-written vs AI-templated.\n",
    "    \n",
    "    ## Poem Text\n",
    "    {poem_text}\n",
    "    \n",
    "    ## Output Format (JSON ONLY, no extra text)\n",
    "    {{\n",
    "        \"scores\": {{\n",
    "            \"fluency\": 8.5,\n",
    "            \"emotional_resonance\": 9.0,\n",
    "            \"image_innovation\": 7.5,\n",
    "            \"theme_consistency\": 8.0,\n",
    "            \"human_preference\": 8.8,\n",
    "            \"total_score\": 8.36\n",
    "        }},\n",
    "        \"analysis\": {{\n",
    "            \"fluency\": \"Detailed analysis for fluency...\",\n",
    "            \"emotional_resonance\": \"Detailed analysis for emotional resonance...\",\n",
    "            \"image_innovation\": \"Detailed analysis for image innovation...\",\n",
    "            \"theme_consistency\": \"Detailed analysis for theme consistency...\",\n",
    "            \"human_preference\": \"Detailed analysis for human preference...\"\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    Calculate total_score as the average of the 5 dimensions (round to 2 decimal places).\n",
    "    Keep analysis concise (50-100 words per dimension) and specific (reference poem lines).\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# -------------------------\n",
    "# 5. è°ƒç”¨æœ¬åœ° Qwen2.5-7B åˆ†æè¯—æ­Œï¼ˆæ›¿ä»£GPT-4ï¼‰\n",
    "# -------------------------\n",
    "def analyze_english_poem(poem_text: str, theme: Optional[str] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    è°ƒç”¨æœ¬åœ° Qwen2.5-7Bï¼šè¾“å‡ºLitBenchè¯„åˆ† + å„ç»´åº¦è¯¦ç»†åˆ†æ\n",
    "    \"\"\"\n",
    "    prompt = build_analysis_prompt(poem_text, theme)\n",
    "    \n",
    "    try:\n",
    "        # æ„å»º Qwen æ ¼å¼çš„å¯¹è¯\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        # æ ¼å¼åŒ– promptï¼ˆQwen è¦æ±‚çš„æ ¼å¼ï¼‰\n",
    "        input_text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        # ç¼–ç è¾“å…¥\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # ç”Ÿæˆç»“æœ\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                generation_config=GEN_CONFIG\n",
    "            )\n",
    "        \n",
    "        # è§£ç è¾“å‡º\n",
    "        response = tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n",
    "        result_str = response.strip()\n",
    "        \n",
    "        # è§£æ JSON ç»“æœ\n",
    "        result_dict = json.loads(result_str)\n",
    "        \n",
    "        # æ‰‹åŠ¨æ ¡å‡†æ€»åˆ†ï¼ˆé˜²æ­¢æ¨¡å‹è®¡ç®—é”™è¯¯ï¼‰\n",
    "        dimensions = [\"fluency\", \"emotional_resonance\", \"image_innovation\", \"theme_consistency\", \"human_preference\"]\n",
    "        calculated_total = round(sum(result_dict[\"scores\"][d] for d in dimensions) / 5, 2)\n",
    "        result_dict[\"scores\"][\"total_score\"] = calculated_total\n",
    "        \n",
    "        return result_dict\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": f\"Failed to parse Qwen response (invalid JSON). Raw response: {result_str}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Qwen generation failed: {str(e)}\"}\n",
    "\n",
    "# -------------------------\n",
    "# 6. æ ¼å¼åŒ–è¾“å‡ºç»“æœï¼ˆé€»è¾‘ä¸å˜ï¼‰\n",
    "# -------------------------\n",
    "def print_analysis_result(result: Dict):\n",
    "    \"\"\"ç¾è§‚è¾“å‡ºè¯„åˆ†å’Œåˆ†æç»“æœ\"\"\"\n",
    "    if \"error\" in result:\n",
    "        print(f\"âŒ Analysis Failed: {result['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ“œ Poem Content:\")\n",
    "    print(load_poem_from_file(POEM_FILE_PATH))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nğŸ¯ LitBench Score Summary (0-10):\")\n",
    "    scores = result[\"scores\"]\n",
    "    for dim, score in scores.items():\n",
    "        print(f\"  - {dim.replace('_', ' ').title()}: {score}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ Detailed Dimension Analysis:\")\n",
    "    analysis = result[\"analysis\"]\n",
    "    for dim, text in analysis.items():\n",
    "        print(f\"\\nã€{dim.replace('_', ' ').title()}ã€‘\")\n",
    "        print(f\"  {text}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# -------------------------\n",
    "# 7. ä¸»å‡½æ•°ï¼šè¯»å–è¯—æ­Œ â†’ åˆ†æ â†’ è¾“å‡º\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 1. è¯»å–è¯—æ­Œæ–‡ä»¶\n",
    "        poem = load_poem_from_file(POEM_FILE_PATH)\n",
    "        \n",
    "        # 2. è°ƒç”¨æœ¬åœ° Qwen2.5-7B åˆ†æ\n",
    "        print(\"ğŸš€ å¼€å§‹è°ƒç”¨æœ¬åœ° Qwen2.5-7B åˆ†æè¯—æ­Œ...\")\n",
    "        analysis_result = analyze_english_poem(poem, theme=\"love and alienation\")\n",
    "        \n",
    "        # 3. è¾“å‡ºç»“æœ\n",
    "        print_analysis_result(analysis_result)\n",
    "        \n",
    "        # å¯é€‰ï¼šä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶\n",
    "        with open(\"poem_analysis_result_qwen.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(analysis_result, f, indent=2)\n",
    "        print(\"\\nâœ… Analysis result saved to: poem_analysis_result_qwen.json\")\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"âŒ {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb2bdf4-7f67-4d3b-aaed-cc1940d216c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Qwen2.5-7B æ¨¡å‹åŠ è½½å®Œæˆï¼\n",
      "ğŸ” æ­£åœ¨è§£æå¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶...\n",
      "âœ… å¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶è§£æå®Œæˆï¼\n",
      "\n",
      "ğŸš€ å¼€å§‹æ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹çš„è¯—æ­Œ...\n",
      "\n",
      "ğŸš€ å¼€å§‹åˆ†æ BASE æ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œ...\n",
      "âœ… BASE æ¨¡å‹è¯—æ­Œåˆ†æå®Œæˆï¼\n",
      "\n",
      "ğŸš€ å¼€å§‹åˆ†æ SFT æ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œ...\n",
      "âœ… SFT æ¨¡å‹è¯—æ­Œåˆ†æå®Œæˆï¼\n",
      "\n",
      "ğŸš€ å¼€å§‹åˆ†æ MINDFLOW æ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œ...\n",
      "âœ… MINDFLOW æ¨¡å‹è¯—æ­Œåˆ†æå®Œæˆï¼\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ“Š å¤šæ¨¡å‹è¯—æ­Œ LitBench è¯„åˆ†å¯¹æ¯”åˆ†æ\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ¯ å„æ¨¡å‹æ€»åˆ†å¯¹æ¯” (0-10):\n",
      "------------------------------------------------------------\n",
      "  â€¢ BASE: 8.36\n",
      "  â€¢ SFT: 8.36\n",
      "  â€¢ MINDFLOW: Error\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ“œ BASE MODEL POEM & ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ–‹ï¸ Poem Content:\n",
      "----------------------------------------\n",
      "In fields where the sunâ€™s warm hands caress,\n",
      "And nature whispers to the whispering breeze,\n",
      "I hear the songs that fill this vast expanseâ€”\n",
      "Chirping crickets and larks ascending.\n",
      "Amidst rows of corn and wheat so green,\n",
      "Where cows graze tranquil as their breaths are seen,\n",
      "A farmer tills with slow, sure pace and might,\n",
      "His heart with every furrow taking flight.\n",
      "Beneath the big blue sky's expansive dome,\n",
      "He works the earth, the very essence of home.\n",
      "The soil rich with the promise of tomorrow,\n",
      "As seasons turn like leaves upon the floor.\n",
      "This land, so wild yet cultivated too,\n",
      "Sings with life in voices low and true.\n",
      "The chirping thrums through the air, light as thought,\n",
      "Natureâ€™s symphony, on and around the plot.\n",
      "So let me wander, hand in hand with time,\n",
      "Among these plots, among these rolling climbs.\n",
      "For here I find my spirit set at ease,\n",
      "By natureâ€™s chords, by laborâ€™s endless seas.\n",
      "\n",
      "ğŸ¯ LitBench Score Summary (0-10):\n",
      "----------------------------------------\n",
      "  - Fluency: 8.5\n",
      "  - Emotional Resonance: 9.0\n",
      "  - Image Innovation: 7.5\n",
      "  - Theme Consistency: 8.0\n",
      "  - Human Preference: 8.8\n",
      "  - Total Score: 8.36\n",
      "\n",
      "ğŸ“ Detailed Dimension Analysis:\n",
      "----------------------------------------\n",
      "\n",
      "ã€Fluencyã€‘\n",
      "  Fluent with smooth rhythms, though 'sunâ€™s warm hands' is somewhat unusual. Lines like 'Chirping crickets and larks ascending' flow well.\n",
      "\n",
      "ã€Emotional Resonanceã€‘\n",
      "  Evokes tranquility and joy through vivid imagery ('big blue sky', 'soil rich with promise'). The tone is soothing and reflective.\n",
      "\n",
      "ã€Image Innovationã€‘\n",
      "  Imagery is generally fresh but some metaphors like 'sunâ€™s warm hands' feel slightly artificial. Overall, the imagery is effective and original.\n",
      "\n",
      "ã€Theme Consistencyã€‘\n",
      "  Consistent with themes of natural beauty and hard work. Lines like 'tills with slow, sure pace and might' align well.\n",
      "\n",
      "ã€Human Preferenceã€‘\n",
      "  Language feels natural and relatable, avoiding AI-like templates. The narrative voice is engaging.\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ“œ SFT MODEL POEM & ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ–‹ï¸ Poem Content:\n",
      "----------------------------------------\n",
      "I too sing America! I am largeâ€”I contain multitudes.\n",
      "From every sound of life, from my own voice sounding,\n",
      "And that of others, even to the last far-off muted strain,\n",
      "Whateâ€™er it is must be significantâ€”every one of its phrases a word in mine;\n",
      "Each echo an affirmationâ€”each sound and shade has its correspondent in me.\n",
      "All sounds are significantâ€”the cricketâ€™s, the grasshopperâ€™s, or any insectâ€™s high-pitched note;\n",
      "The birdâ€™s song on the hill-tops morning and evening, as he perches on the hemlock or oak, or flutters about the field-birdâ€™s home;\n",
      "Or if in summerâ€™s still hour on the lawn I hear the bee humming through the air,\n",
      "So faintly, yet so confident, no matter which way turned,\n",
      "Sure as fateâ€™s hand whispers me to turn the page of my book,\n",
      "He says his say, with his tiny wings half-opened, flying lightly onâ€”tells all his news,\n",
      "Then settles by my side, and hums his song of love,\n",
      "Sings louder and clearer, for here he means to stay;\n",
      "It seems to me to have a deep meaning this little beingâ€™s talk;\n",
      "Somehow it penetrates my spirit, and takes root there.\n",
      "Natureâ€™s most secret thought seems whispering in each tone;\n",
      "She never stops to consider, nor thinks to teach or show,\n",
      "But goes her ways, and lets us find out what we can;\n",
      "Let them come from China or Europe, the newest arrivals, or those who have been many days in prison,\n",
      "They will hear the same tune, the same cry of joy, and wonder, and passion.\n",
      "The farmer, the mechanic, the laborer, all join their voices with mine,\n",
      "To praise and honor the land of our birthâ€”its rivers, mountains, lakes and plains;\n",
      "Where ever the sunset shines upon our land, it is blessed and praised.\n",
      "There is a sweet old-time melody, heard once only\n",
      "\n",
      "ğŸ¯ LitBench Score Summary (0-10):\n",
      "----------------------------------------\n",
      "  - Fluency: 8.5\n",
      "  - Emotional Resonance: 9.0\n",
      "  - Image Innovation: 7.5\n",
      "  - Theme Consistency: 8.0\n",
      "  - Human Preference: 8.8\n",
      "  - Total Score: 8.36\n",
      "\n",
      "ğŸ“ Detailed Dimension Analysis:\n",
      "----------------------------------------\n",
      "\n",
      "ã€Fluencyã€‘\n",
      "  Fluency is generally smooth, though some lines like 'Even to the last far-off muted strain' could be smoother. The repetition of 'each sound and shade has its correspondent in me' adds rhythmic stability.\n",
      "\n",
      "ã€Emotional Resonanceã€‘\n",
      "  Emotional resonance is strong, particularly through the use of nature imagery and the collective voice praising America, evoking feelings of unity and pride.\n",
      "\n",
      "ã€Image Innovationã€‘\n",
      "  Image innovation is present but somewhat repetitive, such as the recurring description of insects singing. The metaphorical depth is appreciated, but it leans towards familiar tropes.\n",
      "\n",
      "ã€Theme Consistencyã€‘\n",
      "  Theme consistency is maintained well throughout, focusing on the idea of America's natural beauty and the shared experience of its inhabitants.\n",
      "\n",
      "ã€Human Preferenceã€‘\n",
      "  Language feels largely human-written, with a rich vocabulary and varied sentence structures that avoid the template-like quality often associated with AI.\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ“œ MINDFLOW MODEL POEM & ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ–‹ï¸ Poem Content:\n",
      "----------------------------------------\n",
      "In fields where nature's breath doth sigh,\n",
      "And sunbeams kiss the waving hay,\n",
      "Where murmurs of sweet moisture fly,\n",
      "A song of life and toil they lay.\n",
      "Upon the farms the morning breaks,\n",
      "The roosters crow, and cows low soft.\n",
      "Young swains, with boots all laced and stakes,\n",
      "Begin their work at early not.\n",
      "Chirping thrushes fill the green lanesâ€”\n",
      "Sparrows sing in sprigged apple boughs.\n",
      "All creatures wake as Nature paints,\n",
      "Her canvas bright with dawnâ€™s blush now.\n",
      "The plowman, strong as oak trees' root,\n",
      "Draws furrows deep in soil dark brown.\n",
      "His spade, like arm of Atlas, fraught\n",
      "With power to lift the earth around.\n",
      "Here wheat is born from loam so rich,\n",
      "And cornfields stretch like golden seas.\n",
      "Natureâ€™s bounty here does teach us much:\n",
      "Toiled for by hands that will not cease.\n",
      "From morn till night, with steadfast mind,\n",
      "These farmers bend their willing will.\n",
      "Each task they know must be combined,\n",
      "To thrive and grow beneath the hill.\n",
      "Thus through the day they labor hard,\n",
      "Till stars come out, and darkness draws.\n",
      "Then grateful hearts to rest are charted,\n",
      "For toilsome days have wrought new straw.\n",
      "So let it be when sunset comes,\n",
      "When fields lie still under the star.\n",
      "We thank these workers for our homes,\n",
      "And cherish all we get in bar.\n",
      "This poem uses elements inspired by Walt Whitman's style, including free verse, an emphasis on natural imagery and rural life, and a focus on the rhythms of daily existence on a farm. The repetition and use of dashes also echo some of Whitman's characteristic techniques.\n",
      "\n",
      "âŒ Analysis Failed: Failed to parse Qwen response (invalid JSON). Raw response: {\n",
      "    \"model_type\": \"mindflow\",\n",
      "    \"scores\": {\n",
      "        \"fluency\": 8.5,\n",
      "        \"emotional_resonance\": 9.0,\n",
      "        \"image_innovation\": 7.5,\n",
      "        \"theme_consistency\": 8.0,\n",
      "        \"human_preference\": 8.8,\n",
      "        \"total_score\": 8.36\n",
      "    },\n",
      "    \"analysis\": {\n",
      "        \"fluency\": \"Fluent with a rhythmic flow, though 'where sunbeams kiss the waving hay' could be smoother.\",\n",
      "        \"emotional_resonance\": \"Evokes a sense of tranquility and gratitude, particularly evident in 'grateful hearts to rest are charted'.\",\n",
      "        \"image_innovation\": \"Creative imagery like 'plowman, strong as oak trees\\' root', but relies heavily on traditional pastoral motifs.\",\n",
      "        \"theme_consistency\": \"Consistent with themes of rural life and hard work, though some lines like 'young swains, with boots all laced and stakes' feel slightly repetitive.\",\n",
      "        \"human_preference\": \"Language feels authentic and resonant, blending historical poetic styles with modern sensibilities.\"\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "âœ… æ‰¹é‡åˆ†æç»“æœå·²ä¿å­˜è‡³: multi_model_poem_analysis_20251213_181205.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Optional, List\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# -------------------------\n",
    "# 1. é…ç½®æœ¬åœ° Qwen2.5-7B è·¯å¾„ & æ–‡ä»¶è·¯å¾„\n",
    "# -------------------------\n",
    "# æœ¬åœ° Qwen2.5-7B æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰\n",
    "LOCAL_QWEN_PATH = \"/root/autodl-tmp/qwen2.5-7b/qwen2.5-7b\"  # ç¤ºä¾‹è·¯å¾„ï¼Œéœ€ä¿®æ”¹\n",
    "# åŒ…å«ä¸‰ä¸ªæ¨¡å‹è¯—æ­Œçš„æ–‡ä»¶è·¯å¾„ï¼ˆå¤šæ¨¡å‹ç”Ÿæˆçš„ç»“æœæ–‡ä»¶ï¼‰\n",
    "POEM_FILE_PATH = \"/root/autodl-tmp/Pro/poetry_results/all_models_poem_20251213_180850.txt\"\n",
    "\n",
    "# ç”Ÿæˆé…ç½®ï¼ˆé€‚é… 7B æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœï¼‰\n",
    "GEN_CONFIG = GenerationConfig(\n",
    "    temperature=0.0,  # å›ºå®šæ¸©åº¦ä¿è¯è¯„åˆ†ç¨³å®š\n",
    "    top_k=40,\n",
    "    top_p=0.92,\n",
    "    repetition_penalty=1.1,\n",
    "    max_new_tokens=1500,  # è¶³å¤Ÿå®¹çº³è¯„åˆ†+åˆ†æ\n",
    "    eos_token_id=151643,  # Qwen çš„ eos_token_id\n",
    "    pad_token_id=151643,  # Qwen çš„ pad_token_id\n",
    "    device_map=\"auto\",    # è‡ªåŠ¨åˆ†é…æ˜¾å­˜ï¼ˆGPU/CPUï¼‰\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 2. åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹ & Tokenizer\n",
    "# -------------------------\n",
    "print(\"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ° Qwen2.5-7B æ¨¡å‹...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    LOCAL_QWEN_PATH,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LOCAL_QWEN_PATH,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,  # ç”¨ float16 èŠ‚çœæ˜¾å­˜\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # å¯é€‰ï¼š4bit é‡åŒ–ï¼Œè¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨ï¼ˆéœ€å®‰è£… bitsandbytesï¼‰\n",
    ")\n",
    "model.eval()\n",
    "print(\"âœ… Qwen2.5-7B æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. è§£æå¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶ï¼ˆæ–°å¢æ ¸å¿ƒé€»è¾‘ï¼‰\n",
    "# -------------------------\n",
    "def parse_multi_model_poem_file(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    è§£æåŒ…å«ä¸‰ä¸ªæ¨¡å‹è¯—æ­Œçš„æ–‡ä»¶ï¼Œæå–æ¯ä¸ªæ¨¡å‹çš„è¯—æ­Œå†…å®¹\n",
    "    é€‚é…æ ¼å¼ï¼š\n",
    "    ğŸ“Œ BASE MODEL OUTPUT:\n",
    "    ------------------------\n",
    "    è¯—æ­Œå†…å®¹...\n",
    "    \n",
    "    ğŸ“Œ SFT MODEL OUTPUT:\n",
    "    ------------------------\n",
    "    è¯—æ­Œå†…å®¹...\n",
    "    \n",
    "    ğŸ“Œ MINDFLOW MODEL OUTPUT:\n",
    "    ------------------------\n",
    "    è¯—æ­Œå†…å®¹...\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Poem file not found: {file_path}\")\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # å®šä¹‰æ¨¡å‹æ ‡è®°å’Œå¯¹åº”çš„key\n",
    "    model_markers = {\n",
    "        \"ğŸ“Œ BASE MODEL OUTPUT:\": \"base\",\n",
    "        \"ğŸ“Œ SFT MODEL OUTPUT:\": \"sft\",\n",
    "        \"ğŸ“Œ MINDFLOW MODEL OUTPUT:\": \"mindflow\"\n",
    "    }\n",
    "    \n",
    "    # åˆå§‹åŒ–ç»“æœ\n",
    "    poem_dict = {\n",
    "        \"base\": \"\",\n",
    "        \"sft\": \"\",\n",
    "        \"mindflow\": \"\"\n",
    "    }\n",
    "    \n",
    "    # åˆ†å‰²å†…å®¹å¹¶æå–æ¯ä¸ªæ¨¡å‹çš„è¯—æ­Œ\n",
    "    content_parts = content.split(\"ğŸ“Œ\")\n",
    "    for part in content_parts:\n",
    "        if not part.strip():\n",
    "            continue\n",
    "        \n",
    "        # åŒ¹é…æ¨¡å‹ç±»å‹\n",
    "        for marker, model_key in model_markers.items():\n",
    "            if marker.replace(\"ğŸ“Œ \", \"\") in part:\n",
    "                # æå–è¯—æ­Œå†…å®¹ï¼ˆè¿‡æ»¤æ ‡è®°ã€åˆ†éš”çº¿ï¼‰\n",
    "                lines = part.split(\"\\n\")\n",
    "                poem_lines = []\n",
    "                in_poem = False\n",
    "                \n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    # è·³è¿‡æ ‡è®°è¡Œå’Œåˆ†éš”çº¿\n",
    "                    if line == marker.replace(\"ğŸ“Œ \", \"\") or line.startswith(\"---\"):\n",
    "                        in_poem = True\n",
    "                        continue\n",
    "                    # è·³è¿‡ç©ºè¡Œï¼ˆä½†ä¿ç•™è¯—æ­Œå†…çš„ç©ºè¡Œï¼‰\n",
    "                    if in_poem and line:\n",
    "                        poem_lines.append(line)\n",
    "                    # é‡åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹æ ‡è®°åˆ™åœæ­¢\n",
    "                    if any(marker.replace(\"ğŸ“Œ \", \"\") in line for marker in model_markers.keys()):\n",
    "                        break\n",
    "                \n",
    "                poem_dict[model_key] = \"\\n\".join(poem_lines)\n",
    "                break\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦æå–åˆ°æœ‰æ•ˆå†…å®¹\n",
    "    empty_models = [k for k, v in poem_dict.items() if not v.strip()]\n",
    "    if empty_models:\n",
    "        raise ValueError(f\"Failed to extract poem content for models: {', '.join(empty_models)}\")\n",
    "    \n",
    "    return poem_dict\n",
    "\n",
    "# -------------------------\n",
    "# 4. æ„å»ºLitBenchè¯„åˆ†+è¯¦ç»†åˆ†æçš„Promptï¼ˆé€‚é…Qwenï¼‰\n",
    "# -------------------------\n",
    "def build_analysis_prompt(poem_text: str, model_type: str, theme: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    æ„å»ºPromptï¼šé€‚é…Qwenæ ¼å¼ï¼Œä¿ç•™LitBenchè¯„åˆ†ç»´åº¦ï¼Œæ ‡æ³¨æ¨¡å‹ç±»å‹\n",
    "    \"\"\"\n",
    "    theme = theme if theme else \"no specified theme\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional English poetry critic following the LitBench benchmark for creative writing evaluation.\n",
    "    Evaluate the following English poem generated by {model_type.upper()} model with TWO parts, and output ONLY JSON format (no extra text, no explanation):\n",
    "    \n",
    "    ## PART 1: Scoring (0-10 scale, 10 = highest)\n",
    "    Score the poem on these dimensions:\n",
    "    1. Fluency: Line/rhythm smoothness, no semantic fragmentation/awkward phrasing.\n",
    "    2. Emotional Resonance: Ability to evoke genuine reader emotion (joy/sorrow/nostalgia etc.).\n",
    "    3. Image Innovation: Originality of imagery/rhetoric (metaphor/simile/personification) â€“ avoid clichÃ©s.\n",
    "    4. Theme Consistency: Alignment with the given theme ({theme}) â€“ no irrelevant content.\n",
    "    5. Human Preference: Fit with human poetic aesthetic (avoid AI-generated templated language).\n",
    "    \n",
    "    ## PART 2: Detailed Analysis\n",
    "    For each dimension, write a 50-100 word analysis explaining the score:\n",
    "    - For Fluency: Point out specific lines with good/bad rhythm, or semantic issues.\n",
    "    - For Emotional Resonance: Explain which emotions are evoked and how (word choice/tone).\n",
    "    - For Image Innovation: Identify specific imagery/rhetoric, comment on originality (clichÃ©s if any).\n",
    "    - For Theme Consistency: Link specific lines to the theme (or note deviations).\n",
    "    - For Human Preference: Comment on whether the language feels human-written vs AI-templated.\n",
    "    \n",
    "    ## Poem Text (from {model_type.upper()} model)\n",
    "    {poem_text}\n",
    "    \n",
    "    ## Output Format (JSON ONLY, no extra text)\n",
    "    {{\n",
    "        \"model_type\": \"{model_type}\",\n",
    "        \"scores\": {{\n",
    "            \"fluency\": 8.5,\n",
    "            \"emotional_resonance\": 9.0,\n",
    "            \"image_innovation\": 7.5,\n",
    "            \"theme_consistency\": 8.0,\n",
    "            \"human_preference\": 8.8,\n",
    "            \"total_score\": 8.36\n",
    "        }},\n",
    "        \"analysis\": {{\n",
    "            \"fluency\": \"Detailed analysis for fluency...\",\n",
    "            \"emotional_resonance\": \"Detailed analysis for emotional resonance...\",\n",
    "            \"image_innovation\": \"Detailed analysis for image innovation...\",\n",
    "            \"theme_consistency\": \"Detailed analysis for theme consistency...\",\n",
    "            \"human_preference\": \"Detailed analysis for human preference...\"\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    Calculate total_score as the average of the 5 dimensions (round to 2 decimal places).\n",
    "    Keep analysis concise (50-100 words per dimension) and specific (reference poem lines).\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# -------------------------\n",
    "# 5. è°ƒç”¨æœ¬åœ° Qwen2.5-7B åˆ†æå•é¦–è¯—æ­Œ\n",
    "# -------------------------\n",
    "def analyze_single_poem(poem_text: str, model_type: str, theme: Optional[str] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    è°ƒç”¨æœ¬åœ° Qwen2.5-7Bï¼šåˆ†æå•ä¸ªæ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œ\n",
    "    \"\"\"\n",
    "    prompt = build_analysis_prompt(poem_text, model_type, theme)\n",
    "    \n",
    "    try:\n",
    "        # æ„å»º Qwen æ ¼å¼çš„å¯¹è¯\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        # æ ¼å¼åŒ– promptï¼ˆQwen è¦æ±‚çš„æ ¼å¼ï¼‰\n",
    "        input_text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        # ç¼–ç è¾“å…¥\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # ç”Ÿæˆç»“æœ\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                generation_config=GEN_CONFIG\n",
    "            )\n",
    "        \n",
    "        # è§£ç è¾“å‡º\n",
    "        response = tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n",
    "        result_str = response.strip()\n",
    "        \n",
    "        # è§£æ JSON ç»“æœ\n",
    "        result_dict = json.loads(result_str)\n",
    "        \n",
    "        # æ‰‹åŠ¨æ ¡å‡†æ€»åˆ†ï¼ˆé˜²æ­¢æ¨¡å‹è®¡ç®—é”™è¯¯ï¼‰\n",
    "        dimensions = [\"fluency\", \"emotional_resonance\", \"image_innovation\", \"theme_consistency\", \"human_preference\"]\n",
    "        calculated_total = round(sum(result_dict[\"scores\"][d] for d in dimensions) / 5, 2)\n",
    "        result_dict[\"scores\"][\"total_score\"] = calculated_total\n",
    "        \n",
    "        return result_dict\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"model_type\": model_type,\n",
    "            \"error\": f\"Failed to parse Qwen response (invalid JSON). Raw response: {result_str}\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"model_type\": model_type,\n",
    "            \"error\": f\"Qwen generation failed: {str(e)}\"\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# 6. æ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹çš„è¯—æ­Œï¼ˆæ–°å¢æ ¸å¿ƒé€»è¾‘ï¼‰\n",
    "# -------------------------\n",
    "def batch_analyze_poems(poem_dict: Dict[str, str], theme: Optional[str] = None) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    æ‰¹é‡åˆ†æä¸‰ä¸ªæ¨¡å‹çš„è¯—æ­Œ\n",
    "    \"\"\"\n",
    "    analysis_results = {}\n",
    "    \n",
    "    # æŒ‰é¡ºåºåˆ†ææ¯ä¸ªæ¨¡å‹çš„è¯—æ­Œ\n",
    "    model_order = [\"base\", \"sft\", \"mindflow\"]\n",
    "    for model_type in model_order:\n",
    "        print(f\"\\nğŸš€ å¼€å§‹åˆ†æ {model_type.upper()} æ¨¡å‹ç”Ÿæˆçš„è¯—æ­Œ...\")\n",
    "        poem_text = poem_dict[model_type]\n",
    "        result = analyze_single_poem(poem_text, model_type, theme)\n",
    "        analysis_results[model_type] = result\n",
    "        print(f\"âœ… {model_type.upper()} æ¨¡å‹è¯—æ­Œåˆ†æå®Œæˆï¼\")\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# -------------------------\n",
    "# 7. æ ¼å¼åŒ–è¾“å‡ºæ‰€æœ‰åˆ†æç»“æœ\n",
    "# -------------------------\n",
    "def print_batch_analysis_result(analysis_results: Dict[str, Dict], poem_dict: Dict[str, str]):\n",
    "    \"\"\"ç¾è§‚è¾“å‡ºæ‰€æœ‰æ¨¡å‹çš„è¯„åˆ†å’Œåˆ†æç»“æœ\"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ğŸ“Š å¤šæ¨¡å‹è¯—æ­Œ LitBench è¯„åˆ†å¯¹æ¯”åˆ†æ\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # å…ˆè¾“å‡ºæ€»åˆ†å¯¹æ¯”\n",
    "    print(\"\\nğŸ¯ å„æ¨¡å‹æ€»åˆ†å¯¹æ¯” (0-10):\")\n",
    "    print(\"-\"*60)\n",
    "    for model_type, result in analysis_results.items():\n",
    "        if \"error\" in result:\n",
    "            score = \"Error\"\n",
    "        else:\n",
    "            score = result[\"scores\"][\"total_score\"]\n",
    "        print(f\"  â€¢ {model_type.upper()}: {score}\")\n",
    "    \n",
    "    # é€ä¸ªè¾“å‡ºè¯¦ç»†åˆ†æ\n",
    "    for model_type, result in analysis_results.items():\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"ğŸ“œ {model_type.upper()} MODEL POEM & ANALYSIS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # è¾“å‡ºè¯—æ­Œå†…å®¹\n",
    "        print(\"\\nğŸ–‹ï¸ Poem Content:\")\n",
    "        print(\"-\"*40)\n",
    "        print(poem_dict[model_type])\n",
    "        \n",
    "        # è¾“å‡ºåˆ†æç»“æœ\n",
    "        if \"error\" in result:\n",
    "            print(f\"\\nâŒ Analysis Failed: {result['error']}\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\nğŸ¯ LitBench Score Summary (0-10):\")\n",
    "        print(\"-\"*40)\n",
    "        scores = result[\"scores\"]\n",
    "        for dim, score in scores.items():\n",
    "            print(f\"  - {dim.replace('_', ' ').title()}: {score}\")\n",
    "        \n",
    "        print(\"\\nğŸ“ Detailed Dimension Analysis:\")\n",
    "        print(\"-\"*40)\n",
    "        analysis = result[\"analysis\"]\n",
    "        for dim, text in analysis.items():\n",
    "            print(f\"\\nã€{dim.replace('_', ' ').title()}ã€‘\")\n",
    "            print(f\"  {text}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# -------------------------\n",
    "# 8. ä¿å­˜æ‰¹é‡åˆ†æç»“æœ\n",
    "# -------------------------\n",
    "def save_batch_analysis_result(analysis_results: Dict[str, Dict]):\n",
    "    \"\"\"ä¿å­˜æ‰¹é‡åˆ†æç»“æœåˆ°JSONæ–‡ä»¶\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "    save_path = f\"multi_model_poem_analysis_{timestamp}.json\"\n",
    "    \n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(analysis_results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nâœ… æ‰¹é‡åˆ†æç»“æœå·²ä¿å­˜è‡³: {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "# -------------------------\n",
    "# 9. ä¸»å‡½æ•°ï¼šè§£ææ–‡ä»¶ â†’ æ‰¹é‡åˆ†æ â†’ è¾“å‡º â†’ ä¿å­˜\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import time  # ç”¨äºç”Ÿæˆæ—¶é—´æˆ³\n",
    "    \n",
    "    try:\n",
    "        # 1. è§£æå¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶\n",
    "        print(\"ğŸ” æ­£åœ¨è§£æå¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶...\")\n",
    "        poem_dict = parse_multi_model_poem_file(POEM_FILE_PATH)\n",
    "        print(\"âœ… å¤šæ¨¡å‹è¯—æ­Œæ–‡ä»¶è§£æå®Œæˆï¼\")\n",
    "        \n",
    "        # 2. æ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹çš„è¯—æ­Œ\n",
    "        print(\"\\nğŸš€ å¼€å§‹æ‰¹é‡åˆ†ææ‰€æœ‰æ¨¡å‹çš„è¯—æ­Œ...\")\n",
    "        analysis_results = batch_analyze_poems(poem_dict, theme=\"light through mist, drifting leaves, fading warmth\")\n",
    "        \n",
    "        # 3. è¾“å‡ºç»“æœ\n",
    "        print_batch_analysis_result(analysis_results, poem_dict)\n",
    "        \n",
    "        # 4. ä¿å­˜åˆ†æç»“æœ\n",
    "        save_batch_analysis_result(analysis_results)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"âŒ {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05172dfd-1ff1-4f7b-b018-4028774cabd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qwen_text)",
   "language": "python",
   "name": "qwen_text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
